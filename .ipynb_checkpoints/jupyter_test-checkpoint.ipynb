{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfde629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.build_dataset import build_dataset\n",
    "from readingcomprehension.models.luke import LukeForReadingComprehensionWithLoss\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947df52",
   "metadata": {},
   "source": [
    "# Squad 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d0bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FILE = \"./data/json_features.npy\"\n",
    "features = np.load(FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b71640",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = []\n",
    "for item in features:\n",
    "    dict_temp = json.loads(item)\n",
    "    list_dict.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822df36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSRStatus.SUCCESS"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQUAD_MINDRECORD_FILE = \"./data/squad_features.mindrecord\"\n",
    "\n",
    "if os.path.exists(SQUAD_MINDRECORD_FILE):\n",
    "    os.remove(SQUAD_MINDRECORD_FILE)\n",
    "    os.remove(SQUAD_MINDRECORD_FILE + \".db\")\n",
    "\n",
    "writer = FileWriter(file_name=SQUAD_MINDRECORD_FILE, shard_num=1)\n",
    "\n",
    "data_schema = {\n",
    "    \"word_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_position_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"start_positions\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"end_positions\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "}\n",
    "writer.add_schema(data_schema, \"it is a preprocessed squad dataset\")\n",
    "\n",
    "data = []\n",
    "i = 0\n",
    "for item in list_dict:\n",
    "    i += 1\n",
    "    sample = {\n",
    "        \"word_ids\": np.array(item[\"word_ids\"], dtype=np.int32),\n",
    "        \"word_segment_ids\": np.array(item[\"word_segment_ids\"], dtype=np.int32),\n",
    "        \"word_attention_mask\": np.array(item[\"word_attention_mask\"], dtype=np.int32),\n",
    "        \"entity_ids\": np.array(item[\"entity_ids\"], dtype=np.int32),\n",
    "        \"entity_position_ids\": np.array(item[\"entity_position_ids\"], dtype=np.int32),\n",
    "        \"entity_segment_ids\": np.array(item[\"entity_segment_ids\"], dtype=np.int32),\n",
    "        \"entity_attention_mask\": np.array(item[\"entity_attention_mask\"], dtype=np.int32),\n",
    "        \"start_positions\": np.array(item[\"start_positions\"], dtype=np.int32),\n",
    "        \"end_positions\": np.array(item[\"end_positions\"], dtype=np.int32),\n",
    "    }\n",
    "\n",
    "    data.append(sample)\n",
    "    #print(sample)\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee34fc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 269 samples\n"
     ]
    }
   ],
   "source": [
    "data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)\n",
    "count = 0\n",
    "for item in data_set.create_dict_iterator():\n",
    "    #print(item)\n",
    "    count += 1\n",
    "print(\"Got {} samples\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d955417",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e171d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context\n",
    "from model.luke import LukeModel\n",
    "import numpy as np\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069d55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "luke_net_cfg = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c398a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LukeForReadingComprehension(luke_net_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2cf0506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mindspore\n",
    "x = Tensor(np.ones([20, 5, 10, 10]), mindspore.float32)\n",
    "shape1 = x.shape[1:]\n",
    "shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b36bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_positions': Tensor(shape=[1], dtype=Int32, value= [48]),\n",
       " 'entity_attention_mask': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_position_ids': Tensor(shape=[60], dtype=Int32, value= [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       " 'entity_segment_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'start_positions': Tensor(shape=[1], dtype=Int32, value= [44]),\n",
       " 'word_attention_mask': Tensor(shape=[309], dtype=Int32, value= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'word_ids': Tensor(shape=[309], dtype=Int32, value= [    0, 13841,   566,   382,  6630,   473, 10579,  9038,  7938,   116,     2,     2, 41107,  2629, 12501, 39183,   179, 23267,     6,  7199,   241,   495,  4344,   354, \n",
       "  19726,   102, 11802,     6, 10231,    12,   180,     6, 29003, 27516,  2617,  6762, 29972,     6,   463,   354, 10998,   661,  7240,  8970, 31636,   627,  8766, 17137, \n",
       "  24997,   879, 10744,  2192,   179,   627, 20556, 39852,   463,   281,   102, 25430,  9424,   879, 31104,     4,   133,  5087, 30434, 46362,  1116,   627,   879, 31104, \n",
       "    354, 29835, 12473, 10231,  9119,  4308,   293,  1640,  8138,  1872,   463,  7939,  2696,     6, 36260,     6, 13929,  2961,     6, 18562,    43,   463,   627, 37848, \n",
       "  37471,  2407, 26751,     4,   133,   462,  7933,   354,  6421,  1990,   859, 13341,  4030, 21527,  3569, 37848, 37471,  2407,   463,  1990,  1584, 16014,   627,  7210, \n",
       "   2413,  2368,  2558,  4447,  2279,  5564,   495,  3636, 19493, 37848, 37471,  2407, 38817,  2158,     4,  7199,   241,   495,  4344,    18, 30434, 28644,  7333,  4321, \n",
       "   5652,  1096, 12974,    18,     6, 33841,   463, 23878,  5743, 28644,    29,  1529,  3215,  1409,   627,  9579,  8813,    29,     6,  5632,   627,  4917,  7469,  1116, \n",
       "    627,  7199,   241,   495,  4344, 22532, 26751,   463,   102, 12550,    12, 17297,   495, 28644,  1529,  3215,   179, 15302,  8111,  5632, 36452, 30885, 26751,     4, \n",
       "    243,   119, 12042,  5069,   102, 19675,  1116,   462, 47437,     6, 27952,  2987,  3663,     6,  2013,  5580,   463, 43723,   119,  3698,  8014,     6,  8529,   725, \n",
       "    293, 24035, 44855,   463,   627, 37790,  1459,   448, 31093,  1116, 23295,     4, 10777,  2940,   207,  1116,   627,   879, 31104,    18,   398,     6,   151,  5087, \n",
       "  18252, 24597, 16244,   261, 28135,   179,  1264,  1116,  2890, 25382,    12,  8821,  1535, 17444,   298, 12019,     6, 37782,  5632,  2629,  3355,  4328,   625,  8237, \n",
       "      6,  4308, 15668,     6, 28615,   463,  2544,  4040,  9799, 23267,   859,  7042,     4,   133,   879, 31104, 11432,    29, 39073, 10213,     6,   151,   337, 28709, \n",
       "      6, 10998, 21732, 31636,   627,  8355,   990,   337, 28709,  4135, 11655, 31636,   791,     4,   104,     4,  9119,  4308,   293,     4,     2]),\n",
       " 'word_segment_ids': Tensor(shape=[309], dtype=Int32, value= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = next(data_set.create_dict_iterator())\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835cfe2",
   "metadata": {},
   "source": [
    "# RobertaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40ddd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaEmbeddings(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(RobertaEmbeddings, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size,\n",
    "                                            config.hidden_size,\n",
    "                                            padding_idx=config.pad_token_id\n",
    "                                            )\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size,\n",
    "                                                  config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm([config.hidden_size],\n",
    "                                      epsilon=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        # self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        # self.register_buffer(\"position_ids\", nn.Range(config.max_position_embeddings).expand((1, -1)))\n",
    "        # self.register_buffer(\"token_type_ids\",\n",
    "        #                      ops.Zeros(self.position_ids.size(), dtype=mstype.int64),  # dtype used to torch.long\n",
    "        #                      persistent=False)\n",
    "        # End copy\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
    "                                                config.hidden_size,\n",
    "                                                padding_idx=self.padding_idx)\n",
    "\n",
    "    def construct(self,\n",
    "                  input_ids=None,\n",
    "                  token_type_ids=None,\n",
    "                  position_ids=None,\n",
    "                  inputs_embeds=None,\n",
    "                  past_key_values_length=0):\n",
    "        if position_ids is None:\n",
    "            if input_ids is not None:\n",
    "                position_ids = create_position_ids_from_input_ids(input_ids, self.padding_idx, past_key_values_length)\n",
    "            else:\n",
    "                position_ids = create_position_ids_from_input_ids(inputs_embeds)\n",
    "        #if input_ids is not None:\n",
    "        input_shape = input_ids.shape\n",
    "        seq_length = input_shape[1]\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = ops.Zeros(input_shape, dtype=mstype.int64)\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + token_type_embeddings\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        embeddings += position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "def create_position_ids_from_input_ids(input_ids, padding_idx, past_key_values_length=0):\n",
    "    \"\"\"\n",
    "    Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding symbols\n",
    "    are ignored. This is modified from fairseq's `utils.make_positions`.\n",
    "    Args:\n",
    "       x: torch.Tensor x:\n",
    "    Returns: torch.Tensor\n",
    "    \"\"\"\n",
    "    # The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.\n",
    "    pad_id = np.array(padding_idx)\n",
    "    mask = Tensor(1 * np.array(input_ids.asnumpy() != pad_id))\n",
    "    #mask = input_ids.ne(padding_idx).int()  # 可能有问题\n",
    "    cumsum = ops.CumSum()\n",
    "    incremental_indices = (cumsum(mask, 1) + past_key_values_length) * mask\n",
    "    return incremental_indices + padding_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd51fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 309, 768], dtype=Float32, value=\n",
       "[[[-2.32064888e-001, -1.75745404e+000, 8.01867902e-001 ... -8.07331145e-001, -5.34173608e-001, -5.00196517e-001],\n",
       "  [-4.06036109e-001, -1.10527205e+000, 3.34902287e-001 ... 2.24775463e-001, 1.04961407e+000, 4.50774103e-001],\n",
       "  [1.26334572e+000, -2.01488876e+000, 1.10330796e+000 ... 1.46480680e+000, 2.38117844e-001, 1.17235945e-003],\n",
       "  ...\n",
       "  [-5.23515195e-002, -1.31185919e-001, 9.94298160e-002 ... 6.94247425e-001, -1.05684564e-001, -1.13034435e-001],\n",
       "  [-1.06446281e-001, -5.20738661e-001, 3.52823734e-001 ... -7.26584852e-001, 1.75867572e-001, -2.12046310e-001],\n",
       "  [1.73092854e+000, -7.14502096e-001, 9.83837962e-001 ... 6.33667886e-001, -1.98341936e-001, 1.35750985e+000]],\n",
       " [[-2.32064888e-001, -1.75745404e+000, 8.01867902e-001 ... -8.07331145e-001, -5.34173608e-001, -5.00196517e-001],\n",
       "  [-4.06036109e-001, -1.10527205e+000, 3.34902287e-001 ... 2.24775463e-001, 1.04961407e+000, 4.50774103e-001],\n",
       "  [1.26334572e+000, -2.01488876e+000, 1.10330796e+000 ... 1.46480680e+000, 2.38117844e-001, 1.17235945e-003],\n",
       "  ...\n",
       "  [-5.23515195e-002, -1.31185919e-001, 9.94298160e-002 ... 6.94247425e-001, -1.05684564e-001, -1.13034435e-001],\n",
       "  [-1.06446281e-001, -5.20738661e-001, 3.52823734e-001 ... -7.26584852e-001, 1.75867572e-001, -2.12046310e-001],\n",
       "  [1.73092854e+000, -7.14502096e-001, 9.83837962e-001 ... 6.33667886e-001, -1.98341936e-001, 1.35750985e+000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_stack = ops.Stack()\n",
    "word_ids = op_stack([data_sample[\"word_ids\"], data_sample[\"word_ids\"]])\n",
    "word_segment_ids = op_stack([data_sample[\"word_segment_ids\"], data_sample[\"word_segment_ids\"]])\n",
    "embeddings = RobertaEmbeddings(luke_net_cfg)\n",
    "word_embeddings = embeddings.construct(word_ids, word_segment_ids)\n",
    "word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c801ac",
   "metadata": {},
   "source": [
    "# EntityEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9f5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityEmbeddings(nn.Cell):\n",
    "    \"\"\"entity embeddings for luke model\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(EntityEmbeddings, self).__init__()\n",
    "        self.config = config\n",
    "        #config.entity_vocab_size = 20\n",
    "        #config.entity_emb_size = config.hidden_size\n",
    "        #config.layer_norm_eps = 1e-6\n",
    "\n",
    "        self.entity_embeddings = nn.Embedding(config.entity_vocab_size, config.entity_emb_size, padding_idx=0)\n",
    "        \n",
    "        if config.entity_emb_size != config.hidden_size:\n",
    "            self.entity_embedding_dense = nn.Dense(config.entity_emb_size, config.hidden_size, has_bias=False)\n",
    "            \n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        \n",
    "        # TODO：[config.hidden_size] 和 torch有区别\n",
    "        self.layer_norm = nn.LayerNorm([config.hidden_size], epsilon=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.unsqueezee = ops.ExpandDims()\n",
    "\n",
    "    def construct(self, entity_ids, position_ids, token_type_ids=None):\n",
    "        \"\"\"EntityEmbeddings for luke\"\"\"\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = ops.zeros_like(entity_ids)\n",
    "\n",
    "        entity_embeddings = self.entity_embeddings(entity_ids)\n",
    "        print(entity_embeddings.shape)\n",
    "        if self.config.entity_emb_size != self.config.hidden_size:\n",
    "            entity_embeddings = self.entity_embedding_dense(entity_embeddings)\n",
    "        print(entity_embeddings.shape)   \n",
    "        entity_position_ids_int = clamp(position_ids)\n",
    "        entity_position_ids_int = Tensor(entity_position_ids_int.asnumpy().astype(np.int32))\n",
    "        position_embeddings = self.position_embeddings(entity_position_ids_int)\n",
    "        #position_embeddings = self.position_embeddings(position_ids)\n",
    "        position_embedding_mask = 1*self.unsqueezee((position_ids != -1), -1)\n",
    "        position_embeddings = position_embeddings * position_embedding_mask\n",
    "        position_embeddings = ops.reduce_sum(position_embeddings, -2)\n",
    "        position_embeddings = position_embeddings / clamp(ops.reduce_sum(position_embedding_mask, -2), minimum=1e-7)\n",
    "\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = entity_embeddings + position_embeddings + token_type_embeddings\n",
    "        #embeddings = self.layer_norm(embeddings)\n",
    "        #embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def clamp(x, minimum=0.0):\n",
    "    mask = x > minimum\n",
    "    x = x * mask + minimum\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4042e7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2, 2, 768], dtype=Float32, value=\n",
       "[[[-4.63429512e-003, -2.22483966e-002, 8.08674004e-003 ... 1.22992527e-002, -9.81160160e-003, 1.63783655e-002],\n",
       "  [-4.63429512e-003, -2.22483966e-002, 8.08674004e-003 ... 1.22992527e-002, -9.81160160e-003, 1.63783655e-002]],\n",
       " [[-4.63429512e-003, -2.22483966e-002, 8.08674004e-003 ... 1.22992527e-002, -9.81160160e-003, 1.63783655e-002],\n",
       "  [-4.63429512e-003, -2.22483966e-002, 8.08674004e-003 ... 1.22992527e-002, -9.81160160e-003, 1.63783655e-002]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_EntityEmbeddings = EntityEmbeddings(luke_net_cfg)\n",
    "entity_ids = op_stack([data_sample[\"entity_ids\"],data_sample[\"entity_ids\"]])\n",
    "entity_position_ids = op_stack([data_sample[\"entity_position_ids\"],data_sample[\"entity_position_ids\"]])\n",
    "entity_segment_ids = op_stack([data_sample[\"entity_segment_ids\"],data_sample[\"entity_segment_ids\"]])\n",
    "net_EntityEmbeddings.construct(entity_ids, entity_position_ids, entity_segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32ddb0",
   "metadata": {},
   "source": [
    "# attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_extended_attention_mask(word_attention_mask, entity_attention_mask):\n",
    "    attention_mask = word_attention_mask\n",
    "    if entity_attention_mask is not None:\n",
    "        op_Concat = ops.Concat(axis = 1)\n",
    "        attention_mask = op_Concat((attention_mask, entity_attention_mask))\n",
    "    unsqueezee = ops.ExpandDims()\n",
    "    extended_attention_mask = unsqueezee(unsqueezee(attention_mask, 1), 2)\n",
    "    extended_attention_mask = extended_attention_mask.astype(mstype.float32)\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "    return extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bafc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_attention_mask = op_stack([data_sample[\"word_attention_mask\"],data_sample[\"word_attention_mask\"]])\n",
    "entity_attention_mask = op_stack([data_sample[\"entity_attention_mask\"],data_sample[\"entity_attention_mask\"]])\n",
    "attention_mask = _compute_extended_attention_mask(word_attention_mask, entity_attention_mask)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9a497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(word_ids = word_ids,\n",
    "      word_segment_ids = word_segment_ids,\n",
    "      word_attention_mask = word_attention_mask,\n",
    "      entity_ids = entity_ids,\n",
    "      entity_position_ids = entity_position_ids,\n",
    "      entity_segment_ids = entity_segment_ids,\n",
    "      entity_attention_mask = entity_attention_mask\n",
    "      #start_positions = data_sample[\"start_positions\"],\n",
    "      #end_positions = data_sample[\"end_positions\"])\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
