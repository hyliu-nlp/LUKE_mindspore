{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfde629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.build_dataset import build_dataset\n",
    "from readingcomprehension.models.luke import LukeForReadingComprehensionWithLoss\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947df52",
   "metadata": {},
   "source": [
    "# Squad 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d0bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FILE = \"./data/json_features.npy\"\n",
    "features = np.load(FEATURES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b71640",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = []\n",
    "for item in features:\n",
    "    dict_temp = json.loads(item)\n",
    "    list_dict.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "822df36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSRStatus.SUCCESS"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQUAD_MINDRECORD_FILE = \"./data/squad_features.mindrecord\"\n",
    "\n",
    "if os.path.exists(SQUAD_MINDRECORD_FILE):\n",
    "    os.remove(SQUAD_MINDRECORD_FILE)\n",
    "    os.remove(SQUAD_MINDRECORD_FILE + \".db\")\n",
    "\n",
    "writer = FileWriter(file_name=SQUAD_MINDRECORD_FILE, shard_num=1)\n",
    "\n",
    "data_schema = {\n",
    "    \"word_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_position_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"start_positions\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"end_positions\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "}\n",
    "writer.add_schema(data_schema, \"it is a preprocessed squad dataset\")\n",
    "\n",
    "data = []\n",
    "i = 0\n",
    "for item in list_dict:\n",
    "    i += 1\n",
    "    sample = {\n",
    "        \"word_ids\": np.array(item[\"word_ids\"], dtype=np.int32),\n",
    "        \"word_segment_ids\": np.array(item[\"word_segment_ids\"], dtype=np.int32),\n",
    "        \"word_attention_mask\": np.array(item[\"word_attention_mask\"], dtype=np.int32),\n",
    "        \"entity_ids\": np.array(item[\"entity_ids\"], dtype=np.int32),\n",
    "        \"entity_position_ids\": np.array(item[\"entity_position_ids\"], dtype=np.int32),\n",
    "        \"entity_segment_ids\": np.array(item[\"entity_segment_ids\"], dtype=np.int32),\n",
    "        \"entity_attention_mask\": np.array(item[\"entity_attention_mask\"], dtype=np.int32),\n",
    "        \"start_positions\": np.array(item[\"start_positions\"], dtype=np.int32),\n",
    "        \"end_positions\": np.array(item[\"end_positions\"], dtype=np.int32),\n",
    "    }\n",
    "\n",
    "    data.append(sample)\n",
    "    #print(sample)\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee34fc82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 269 samples\n"
     ]
    }
   ],
   "source": [
    "data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)\n",
    "count = 0\n",
    "for item in data_set.create_dict_iterator():\n",
    "    #print(item)\n",
    "    count += 1\n",
    "print(\"Got {} samples\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d955417",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e171d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context\n",
    "from model.luke import LukeModel\n",
    "import numpy as np\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069d55f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke_net_cfg = BertConfig()\n",
    "luke_net_cfg.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c398a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10336:9612,MainProcess):2021-08-25-22:26:04.498.481 [mindspore\\common\\tensor.py:1295] WARN_DEPRECATED: The usage of to_tensor is deprecated. Please use init_data\n"
     ]
    }
   ],
   "source": [
    "model = LukeForReadingComprehension(luke_net_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b36bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_positions': Tensor(shape=[1], dtype=Int32, value= [177]),\n",
       " 'entity_attention_mask': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_position_ids': Tensor(shape=[60], dtype=Int32, value= [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       " 'entity_segment_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'start_positions': Tensor(shape=[1], dtype=Int32, value= [172]),\n",
       " 'word_attention_mask': Tensor(shape=[221], dtype=Int32, value= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1]),\n",
       " 'word_ids': Tensor(shape=[221], dtype=Int32, value= [    0,  1779,  6633,  2160,  1348,     5,   253,     9,    39,    86,    25,   394,   141,   203,  1013,    29,  1435,    13,   557,   222, 10579,  9038,    33,   116, \n",
       "      2,     2,  1121,   627,  1366, 12857,  5087,   627, 13529, 41059,  1116, 45014,   448,  1250,  2160,     6,   347,     4,   104,     4,   347,   482,  1640, 43587, \n",
       "   2383, 32857,   238,  8585,  7325,   102,  8645,   808, 14596,   179,   627,  8813,    18,   241,  9179,  1258,     6, 33492, 38431,     6,   463, 40897,     4,   894, \n",
       "  33008, 11835,   627, 33492, 38431,  1409,  4321,  5652,  1497, 22376, 43592,   131,   627,  1043, 41551,  8634,  1116,   627, 34935,  9773,  7333, 33491,  5202,   417, \n",
       "   4040, 23050,     6,  5632,   627, 20365,   104,  2571, 31673, 37592,  7761,  1092,  1749,   560,  1558,  2466,   131,   627, 30695,  1116,  4691, 30969, 26302,  4189, \n",
       "   4321,  5652,   417,  1438, 10288,   131,   627,  1397, 26217,   571, 10461,  7761,  1629, 10056,  4416,   560,  4321,  5652,  1629,   246,  9026,   131,   627,  2279, \n",
       "   5564,  8428,  1295, 26155, 14170,  7761,  1629, 28129,  4416,   560,  4321,  5652,  1629, 16316,  4416,   131,   463,  2279,  5564,  6762, 29843, 33491,  5202,  7761, \n",
       "   1629,   996,  4416,   560,  4321,  5652,  1629,  3083,  4416,     4,  7199,   241,   495,  4344,    18,  7877, 38696, 10975, 14746, 40862, 25539, 37532, 33161,  1629, \n",
       "    134,     4,   134,  9026,     6, 15476,  3463, 32326,   154,  2629, 12697,  1116,  1629, 38504,  4416,     6,   463,   354,   627,  8377,   179,   627, 37283,  1116, \n",
       "  42799, 40499, 30746,     4,     2]),\n",
       " 'word_segment_ids': Tensor(shape=[221], dtype=Int32, value= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = next(data_set.create_dict_iterator())\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e84207e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample[\"word_ids\"]\n",
    "arr = np.zeros((256-len(data_sample[\"word_ids\"])),dtype = np.int32)\n",
    "x_np = Tensor(arr)\n",
    "op = ops.Concat()\n",
    "word_ids = op((data_sample[\"word_ids\"], x_np))\n",
    "op = ops.Stack()\n",
    "word_ids = op([word_ids,word_ids])\n",
    "word_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9f5282",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mindspore\\core\\utils\\check_convert_utils.cc:491 CheckSubClass] For 'Gather', the type of `index_type` should be subclass of Int64,Int8,Int16,Int32, but got Float32.\nThe function call stack (See file 'analyze_fail_1.dat' for more details):\n# 0 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\readingcomprehension\\models\\luke.py(61)\n        return start_logits, end_logits\n    ^\n# 1 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\readingcomprehension\\models\\luke.py(45)\n        encoder_outputs = super(LukeForReadingComprehension, self).construct(\n# 2 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke.py(93)\n        entity_embeddings = self.entity_embeddings(entity_ids, entity_position_ids, entity_segment_ids)\n                        ^\n# 3 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke_embeddings.py(46)\n        if token_type_ids is None:\n# 4 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke_embeddings.py(51)\n        position_embeddings = self.position_embeddings(clamp(position_ids))\n                          ^\n# 5 In file C:\\Users\\DM\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\layer\\embedding.py(135)\n        if self.use_one_hot:\n# 6 In file C:\\Users\\DM\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\layer\\embedding.py(139)\n            output_for_reshape = self.gather(self.embedding_table, flat_ids, 0)\n                             ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b7a24d089c35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mentity_position_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"entity_position_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mentity_segment_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"entity_segment_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m       \u001b[0mentity_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"entity_attention_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m       \u001b[1;31m#start_positions = data_sample[\"start_positions\"],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[1;31m#end_positions = data_sample[\"end_positions\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_hook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The graph mode does not support hook function.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \"\"\"\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\cell.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCell\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \"\"\"\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[0m_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\common\\api.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"enable_ge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0muse_vm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0menable_ge\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0menable_debug_runtime\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPYNATIVE_MODE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_vm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mindspore\\core\\utils\\check_convert_utils.cc:491 CheckSubClass] For 'Gather', the type of `index_type` should be subclass of Int64,Int8,Int16,Int32, but got Float32.\nThe function call stack (See file 'analyze_fail_1.dat' for more details):\n# 0 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\readingcomprehension\\models\\luke.py(61)\n        return start_logits, end_logits\n    ^\n# 1 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\readingcomprehension\\models\\luke.py(45)\n        encoder_outputs = super(LukeForReadingComprehension, self).construct(\n# 2 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke.py(93)\n        entity_embeddings = self.entity_embeddings(entity_ids, entity_position_ids, entity_segment_ids)\n                        ^\n# 3 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke_embeddings.py(46)\n        if token_type_ids is None:\n# 4 In file C:\\Users\\DM\\Desktop\\Duda\\HUAWEI\\LUKE_mindspore\\model\\luke_embeddings.py(51)\n        position_embeddings = self.position_embeddings(clamp(position_ids))\n                          ^\n# 5 In file C:\\Users\\DM\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\layer\\embedding.py(135)\n        if self.use_one_hot:\n# 6 In file C:\\Users\\DM\\anaconda3\\envs\\MindSpore\\lib\\site-packages\\mindspore\\nn\\layer\\embedding.py(139)\n            output_for_reshape = self.gather(self.embedding_table, flat_ids, 0)\n                             ^\n"
     ]
    }
   ],
   "source": [
    "model(word_ids = word_ids,\n",
    "      word_segment_ids = data_sample[\"word_segment_ids\"],\n",
    "      word_attention_mask = data_sample[\"word_attention_mask\"],\n",
    "      entity_ids = data_sample[\"entity_ids\"],\n",
    "      entity_position_ids = data_sample[\"entity_position_ids\"],\n",
    "      entity_segment_ids = data_sample[\"entity_segment_ids\"],\n",
    "      entity_attention_mask = data_sample[\"entity_attention_mask\"]\n",
    "      #start_positions = data_sample[\"start_positions\"],\n",
    "      #end_positions = data_sample[\"end_positions\"])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa700cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaEmbeddings(nn.Cell):\n",
    "    \"\"\"\n",
    "    Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copied from transformers.models.bert.modeling_bert.BertEmbeddings.__init__\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        # position_ids (1, len position emb) is contiguous in memory and exported when serialized\n",
    "        self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n",
    "        self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):\n",
    "            self.register_buffer(\n",
    "                \"token_type_ids\",\n",
    "                torch.zeros(self.position_ids.size(), dtype=torch.long, device=self.position_ids.device),\n",
    "                persistent=False,\n",
    "            )\n",
    "\n",
    "        # End copy\n",
    "        self.padding_idx = config.pad_token_id\n",
    "        self.position_embeddings = nn.Embedding(\n",
    "            config.max_position_embeddings, config.hidden_size, padding_idx=self.padding_idx\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids=None, token_type_ids=None, position_ids=None, inputs_embeds=None, past_key_values_length=0\n",
    "    ):\n",
    "        if position_ids is None:\n",
    "            if input_ids is not None:\n",
    "                # Create the position ids from the input token ids. Any padded tokens remain padded.\n",
    "                position_ids = create_position_ids_from_input_ids(input_ids, self.padding_idx, past_key_values_length)\n",
    "            else:\n",
    "                position_ids = self.create_position_ids_from_inputs_embeds(inputs_embeds)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "\n",
    "        # Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs\n",
    "        # when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves\n",
    "        # issue #5664\n",
    "        if token_type_ids is None:\n",
    "            if hasattr(self, \"token_type_ids\"):\n",
    "                buffered_token_type_ids = self.token_type_ids[:, :seq_length]\n",
    "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(input_shape[0], seq_length)\n",
    "                token_type_ids = buffered_token_type_ids_expanded\n",
    "            else:\n",
    "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + token_type_embeddings\n",
    "        if self.position_embedding_type == \"absolute\":\n",
    "            position_embeddings = self.position_embeddings(position_ids)\n",
    "            embeddings += position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "    def create_position_ids_from_inputs_embeds(self, inputs_embeds):\n",
    "        \"\"\"\n",
    "        We are provided embeddings directly. We cannot infer which are padded so just generate sequential position ids.\n",
    "\n",
    "        Args:\n",
    "            inputs_embeds: torch.Tensor\n",
    "\n",
    "        Returns: torch.Tensor\n",
    "        \"\"\"\n",
    "        input_shape = inputs_embeds.size()[:-1]\n",
    "        sequence_length = input_shape[1]\n",
    "\n",
    "        position_ids = torch.arange(\n",
    "            self.padding_idx + 1, sequence_length + self.padding_idx + 1, dtype=torch.long, device=inputs_embeds.device\n",
    "        )\n",
    "        return position_ids.unsqueeze(0).expand(input_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
