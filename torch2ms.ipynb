{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.layer.0.attention.self.query.weight',\n",
       "              tensor([[-0.0034,  0.0348,  0.0006,  ...,  0.0017,  0.0590, -0.0426],\n",
       "                      [-0.0249,  0.0531, -0.0148,  ..., -0.0304, -0.0145,  0.0117],\n",
       "                      [ 0.0062,  0.0708, -0.0332,  ...,  0.0803,  0.0118, -0.0132],\n",
       "                      ...,\n",
       "                      [-0.0585,  0.0210, -0.0427,  ..., -0.0298,  0.0051,  0.0694],\n",
       "                      [ 0.0424,  0.0232, -0.0613,  ..., -0.0552, -0.0157,  0.0171],\n",
       "                      [-0.0183, -0.0454, -0.0102,  ...,  0.0471,  0.0229, -0.0177]])),\n",
       "             ('encoder.layer.0.attention.self.query.bias',\n",
       "              tensor([ 0.3127,  0.0561, -0.0748,  ..., -0.0707, -0.0500, -0.0668])),\n",
       "             ('encoder.layer.0.attention.self.key.weight',\n",
       "              tensor([[-0.0044, -0.0183, -0.0138,  ..., -0.0041,  0.0094, -0.0148],\n",
       "                      [-0.0240, -0.0002,  0.0252,  ...,  0.0400,  0.0435, -0.0201],\n",
       "                      [-0.0266, -0.0528, -0.0121,  ..., -0.0364,  0.0073,  0.0146],\n",
       "                      ...,\n",
       "                      [-0.0705, -0.0267, -0.0192,  ..., -0.0191,  0.0093,  0.1013],\n",
       "                      [ 0.0151,  0.0078, -0.0170,  ..., -0.0034, -0.0085,  0.0441],\n",
       "                      [-0.0091, -0.0636,  0.0413,  ...,  0.0467,  0.0148, -0.0465]])),\n",
       "             ('encoder.layer.0.attention.self.key.bias',\n",
       "              tensor([-0.0048, -0.0028, -0.0003,  ...,  0.0012,  0.0018,  0.0012])),\n",
       "             ('encoder.layer.0.attention.self.value.weight',\n",
       "              tensor([[ 0.0301, -0.0005, -0.0243,  ..., -0.0180,  0.0026,  0.0220],\n",
       "                      [ 0.0566,  0.0431,  0.0014,  ..., -0.0154,  0.0925, -0.0200],\n",
       "                      [-0.0149, -0.0425,  0.0127,  ..., -0.0516,  0.0016,  0.0677],\n",
       "                      ...,\n",
       "                      [-0.0108,  0.0077, -0.0119,  ...,  0.0364,  0.0257,  0.0107],\n",
       "                      [-0.0035, -0.0135, -0.0510,  ...,  0.0386, -0.0337,  0.0285],\n",
       "                      [ 0.0042, -0.0091, -0.0134,  ..., -0.0255,  0.0878, -0.0182]])),\n",
       "             ('encoder.layer.0.attention.self.value.bias',\n",
       "              tensor([-0.0007,  0.0023, -0.0086,  ..., -0.0223, -0.0205, -0.0341])),\n",
       "             ('encoder.layer.0.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0025,  0.0355,  0.0011,  ...,  0.0028,  0.0597, -0.0425],\n",
       "                      [-0.0250,  0.0536, -0.0150,  ..., -0.0302, -0.0146,  0.0121],\n",
       "                      [ 0.0056,  0.0714, -0.0337,  ...,  0.0806,  0.0113, -0.0127],\n",
       "                      ...,\n",
       "                      [-0.0588,  0.0207, -0.0424,  ..., -0.0300,  0.0048,  0.0693],\n",
       "                      [ 0.0420,  0.0227, -0.0608,  ..., -0.0547, -0.0157,  0.0174],\n",
       "                      [-0.0183, -0.0458, -0.0104,  ...,  0.0469,  0.0234, -0.0180]])),\n",
       "             ('encoder.layer.0.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.3123,  0.0552, -0.0756,  ..., -0.0703, -0.0498, -0.0665])),\n",
       "             ('encoder.layer.0.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0029,  0.0351,  0.0011,  ...,  0.0024,  0.0605, -0.0435],\n",
       "                      [-0.0250,  0.0529, -0.0153,  ..., -0.0301, -0.0158,  0.0125],\n",
       "                      [ 0.0065,  0.0714, -0.0331,  ...,  0.0804,  0.0121, -0.0136],\n",
       "                      ...,\n",
       "                      [-0.0590,  0.0209, -0.0425,  ..., -0.0299,  0.0044,  0.0692],\n",
       "                      [ 0.0425,  0.0222, -0.0609,  ..., -0.0552, -0.0153,  0.0175],\n",
       "                      [-0.0189, -0.0457, -0.0107,  ...,  0.0480,  0.0223, -0.0180]])),\n",
       "             ('encoder.layer.0.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.3110,  0.0566, -0.0762,  ..., -0.0710, -0.0497, -0.0660])),\n",
       "             ('encoder.layer.0.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0031,  0.0351,  0.0007,  ...,  0.0025,  0.0601, -0.0429],\n",
       "                      [-0.0260,  0.0528, -0.0150,  ..., -0.0300, -0.0140,  0.0110],\n",
       "                      [ 0.0056,  0.0701, -0.0349,  ...,  0.0812,  0.0117, -0.0133],\n",
       "                      ...,\n",
       "                      [-0.0592,  0.0200, -0.0431,  ..., -0.0291,  0.0038,  0.0703],\n",
       "                      [ 0.0410,  0.0216, -0.0610,  ..., -0.0552, -0.0164,  0.0182],\n",
       "                      [-0.0193, -0.0460, -0.0109,  ...,  0.0482,  0.0220, -0.0185]])),\n",
       "             ('encoder.layer.0.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.3115,  0.0549, -0.0754,  ..., -0.0703, -0.0497, -0.0674])),\n",
       "             ('encoder.layer.0.attention.output.dense.weight',\n",
       "              tensor([[ 0.0019,  0.0402, -0.0172,  ..., -0.0144, -0.0331, -0.0170],\n",
       "                      [-0.0336,  0.0139, -0.0164,  ...,  0.0311, -0.0093,  0.0270],\n",
       "                      [ 0.0274, -0.0739,  0.0189,  ..., -0.0320, -0.0066,  0.0995],\n",
       "                      ...,\n",
       "                      [ 0.0281,  0.0011,  0.0216,  ...,  0.0128, -0.0107, -0.0363],\n",
       "                      [-0.0084,  0.0514, -0.0469,  ...,  0.0426,  0.0258, -0.0160],\n",
       "                      [ 0.0475,  0.0229,  0.0917,  ...,  0.0277,  0.0091,  0.0070]])),\n",
       "             ('encoder.layer.0.attention.output.dense.bias',\n",
       "              tensor([-0.0132,  0.0293,  0.0859,  ...,  0.0731, -0.0068,  0.0102])),\n",
       "             ('encoder.layer.0.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9795, 0.9897, 0.9736,  ..., 0.9834, 0.9902, 0.9971])),\n",
       "             ('encoder.layer.0.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.4302,  0.2761, -0.0064,  ...,  0.0112,  0.3301, -0.2979])),\n",
       "             ('encoder.layer.0.intermediate.dense.weight',\n",
       "              tensor([[ 5.8624e-02, -6.4453e-02, -9.3750e-02,  ...,  5.2834e-03,\n",
       "                        2.0187e-02, -1.5182e-02],\n",
       "                      [ 1.5289e-02, -2.7527e-02,  2.0676e-02,  ...,  1.5396e-02,\n",
       "                       -3.7750e-02,  1.2140e-01],\n",
       "                      [ 3.7201e-02, -6.6833e-02,  1.1522e-04,  ...,  2.9068e-02,\n",
       "                       -2.6688e-02, -2.1790e-02],\n",
       "                      ...,\n",
       "                      [ 1.6068e-02, -8.9294e-02,  4.4250e-03,  ...,  3.3112e-02,\n",
       "                       -5.1758e-02, -6.7329e-04],\n",
       "                      [ 1.3416e-01,  5.1971e-02, -1.3000e-01,  ..., -1.4868e-01,\n",
       "                       -3.1769e-02,  2.1835e-02],\n",
       "                      [ 7.1350e-02, -2.8976e-02, -6.0455e-02,  ...,  9.5901e-03,\n",
       "                       -5.7434e-02, -2.9419e-02]])),\n",
       "             ('encoder.layer.0.intermediate.dense.bias',\n",
       "              tensor([-0.0939, -0.0759, -0.0845,  ..., -0.1089, -0.0693, -0.0941])),\n",
       "             ('encoder.layer.0.output.dense.weight',\n",
       "              tensor([[ 0.0437,  0.1018,  0.0296,  ..., -0.0551,  0.0595,  0.0657],\n",
       "                      [ 0.0180,  0.0113, -0.0093,  ..., -0.0071,  0.0183, -0.0112],\n",
       "                      [ 0.0273, -0.0742,  0.0529,  ..., -0.0428, -0.0107,  0.0005],\n",
       "                      ...,\n",
       "                      [-0.0137, -0.0032,  0.0535,  ...,  0.0096, -0.0574,  0.0152],\n",
       "                      [-0.0496,  0.0331, -0.0703,  ...,  0.0590, -0.0355, -0.0052],\n",
       "                      [-0.0953, -0.0449, -0.0946,  ..., -0.0533,  0.0520, -0.0291]])),\n",
       "             ('encoder.layer.0.output.dense.bias',\n",
       "              tensor([ 0.0645, -0.0406,  0.0408,  ...,  0.0072, -0.0952,  0.0554])),\n",
       "             ('encoder.layer.0.output.LayerNorm.weight',\n",
       "              tensor([0.9688, 0.9604, 0.9673,  ..., 0.9727, 0.9697, 0.9487])),\n",
       "             ('encoder.layer.0.output.LayerNorm.bias',\n",
       "              tensor([ 0.3977, -0.1886,  0.0430,  ..., -0.0484, -0.2737,  0.2000])),\n",
       "             ('encoder.layer.1.attention.self.query.weight',\n",
       "              tensor([[ 0.0242, -0.1104,  0.0185,  ..., -0.0665, -0.0303, -0.0332],\n",
       "                      [ 0.0284, -0.0107,  0.0971,  ..., -0.0237,  0.0275,  0.1658],\n",
       "                      [ 0.0098, -0.0415,  0.0324,  ...,  0.0082, -0.0009, -0.0033],\n",
       "                      ...,\n",
       "                      [ 0.0166,  0.0308,  0.0660,  ...,  0.0443, -0.0503,  0.1027],\n",
       "                      [-0.1144,  0.0697,  0.0682,  ..., -0.0142, -0.0743,  0.0615],\n",
       "                      [ 0.0299, -0.0684,  0.0246,  ...,  0.0627, -0.0016,  0.0035]])),\n",
       "             ('encoder.layer.1.attention.self.query.bias',\n",
       "              tensor([ 0.0731,  0.0507, -0.0681,  ...,  0.0828,  0.0448, -0.0767])),\n",
       "             ('encoder.layer.1.attention.self.key.weight',\n",
       "              tensor([[-0.0091,  0.0601, -0.0058,  ..., -0.0317,  0.0103, -0.0156],\n",
       "                      [-0.0205, -0.0876, -0.0567,  ...,  0.0548, -0.0381,  0.0180],\n",
       "                      [-0.0134,  0.0387,  0.0354,  ...,  0.0056,  0.0004, -0.0113],\n",
       "                      ...,\n",
       "                      [-0.0627, -0.0682,  0.0806,  ...,  0.0210,  0.0241,  0.0018],\n",
       "                      [ 0.0493, -0.0461,  0.0357,  ...,  0.0454,  0.0340, -0.0327],\n",
       "                      [ 0.0610,  0.0401,  0.0560,  ...,  0.0909,  0.0236, -0.0013]])),\n",
       "             ('encoder.layer.1.attention.self.key.bias',\n",
       "              tensor([ 1.8187e-03, -4.3774e-04, -1.1654e-03,  ...,  6.2823e-05,\n",
       "                       4.4751e-04,  2.1400e-03])),\n",
       "             ('encoder.layer.1.attention.self.value.weight',\n",
       "              tensor([[-0.0641,  0.0059, -0.0252,  ..., -0.0038,  0.0523,  0.0277],\n",
       "                      [-0.0176,  0.0365, -0.0351,  ..., -0.0132,  0.0315, -0.0209],\n",
       "                      [ 0.0033,  0.0356,  0.0023,  ...,  0.0255,  0.0857, -0.0169],\n",
       "                      ...,\n",
       "                      [-0.0051, -0.0835, -0.0303,  ..., -0.0220,  0.0368,  0.0246],\n",
       "                      [-0.0627,  0.0671, -0.0165,  ..., -0.0047,  0.0230, -0.0128],\n",
       "                      [ 0.0364,  0.0345,  0.0161,  ...,  0.0105,  0.0321, -0.0162]])),\n",
       "             ('encoder.layer.1.attention.self.value.bias',\n",
       "              tensor([ 0.0092,  0.0018,  0.0062,  ...,  0.0006, -0.0553, -0.0010])),\n",
       "             ('encoder.layer.1.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0244, -0.1104,  0.0182,  ..., -0.0667, -0.0310, -0.0332],\n",
       "                      [ 0.0290, -0.0110,  0.0972,  ..., -0.0223,  0.0279,  0.1655],\n",
       "                      [ 0.0110, -0.0412,  0.0322,  ...,  0.0071, -0.0015, -0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0175,  0.0304,  0.0660,  ...,  0.0444, -0.0501,  0.1025],\n",
       "                      [-0.1144,  0.0698,  0.0684,  ..., -0.0138, -0.0736,  0.0622],\n",
       "                      [ 0.0283, -0.0679,  0.0246,  ...,  0.0617, -0.0032,  0.0034]])),\n",
       "             ('encoder.layer.1.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0729,  0.0513, -0.0684,  ...,  0.0828,  0.0457, -0.0776])),\n",
       "             ('encoder.layer.1.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0252, -0.1111,  0.0186,  ..., -0.0667, -0.0309, -0.0335],\n",
       "                      [ 0.0295, -0.0111,  0.0970,  ..., -0.0231,  0.0260,  0.1663],\n",
       "                      [ 0.0099, -0.0415,  0.0315,  ...,  0.0077, -0.0009, -0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0171,  0.0314,  0.0657,  ...,  0.0442, -0.0500,  0.1033],\n",
       "                      [-0.1144,  0.0695,  0.0677,  ..., -0.0135, -0.0742,  0.0630],\n",
       "                      [ 0.0287, -0.0681,  0.0242,  ...,  0.0623, -0.0018,  0.0030]])),\n",
       "             ('encoder.layer.1.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0740,  0.0512, -0.0679,  ...,  0.0833,  0.0459, -0.0778])),\n",
       "             ('encoder.layer.1.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0251, -0.1100,  0.0191,  ..., -0.0665, -0.0299, -0.0339],\n",
       "                      [ 0.0288, -0.0110,  0.0966,  ..., -0.0225,  0.0267,  0.1661],\n",
       "                      [ 0.0100, -0.0417,  0.0317,  ...,  0.0079, -0.0011, -0.0034],\n",
       "                      ...,\n",
       "                      [ 0.0179,  0.0316,  0.0666,  ...,  0.0433, -0.0503,  0.1039],\n",
       "                      [-0.1141,  0.0702,  0.0680,  ..., -0.0132, -0.0740,  0.0627],\n",
       "                      [ 0.0287, -0.0687,  0.0240,  ...,  0.0619, -0.0021,  0.0033]])),\n",
       "             ('encoder.layer.1.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0734,  0.0510, -0.0681,  ...,  0.0840,  0.0453, -0.0772])),\n",
       "             ('encoder.layer.1.attention.output.dense.weight',\n",
       "              tensor([[-0.0353, -0.0124,  0.0090,  ..., -0.0709, -0.0297,  0.0190],\n",
       "                      [ 0.0014, -0.0534, -0.0028,  ..., -0.0754, -0.0400,  0.0075],\n",
       "                      [ 0.0417,  0.0133, -0.0243,  ..., -0.0331,  0.0178,  0.0327],\n",
       "                      ...,\n",
       "                      [-0.0061, -0.0166,  0.0351,  ...,  0.0248, -0.0249,  0.0453],\n",
       "                      [-0.0220,  0.0094,  0.0079,  ..., -0.0481, -0.0392, -0.0514],\n",
       "                      [ 0.0071, -0.0232,  0.0421,  ...,  0.0062, -0.0463,  0.0251]])),\n",
       "             ('encoder.layer.1.attention.output.dense.bias',\n",
       "              tensor([-0.2164,  0.0367, -0.0811,  ..., -0.0743,  0.2334,  0.0737])),\n",
       "             ('encoder.layer.1.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9849, 1.0000, 0.9570,  ..., 0.9790, 0.9893, 0.9712])),\n",
       "             ('encoder.layer.1.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.3284,  0.1815, -0.0329,  ..., -0.0721,  0.2505, -0.2284])),\n",
       "             ('encoder.layer.1.intermediate.dense.weight',\n",
       "              tensor([[ 0.0296, -0.0338,  0.0008,  ..., -0.0232,  0.0985,  0.0493],\n",
       "                      [-0.0059, -0.0673, -0.0325,  ...,  0.0357,  0.0019, -0.0533],\n",
       "                      [-0.0043,  0.0828,  0.0750,  ...,  0.0156,  0.0189, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0363, -0.0446,  0.1230,  ...,  0.0003,  0.0127, -0.0324],\n",
       "                      [ 0.0737, -0.0580, -0.1039,  ..., -0.0316,  0.0239, -0.0826],\n",
       "                      [ 0.0016,  0.0746,  0.0951,  ..., -0.0185, -0.0258,  0.0307]])),\n",
       "             ('encoder.layer.1.intermediate.dense.bias',\n",
       "              tensor([ 0.0947, -0.0511, -0.0545,  ..., -0.0864, -0.0854, -0.0851])),\n",
       "             ('encoder.layer.1.output.dense.weight',\n",
       "              tensor([[-0.0241, -0.0183,  0.0625,  ..., -0.0208, -0.0900,  0.0511],\n",
       "                      [ 0.0460, -0.0169, -0.0151,  ..., -0.0326, -0.0058, -0.0449],\n",
       "                      [ 0.0416,  0.0345,  0.0654,  ..., -0.0248, -0.0519,  0.0959],\n",
       "                      ...,\n",
       "                      [ 0.0425, -0.0576, -0.0737,  ..., -0.0384,  0.0234,  0.0344],\n",
       "                      [ 0.0103,  0.0833,  0.1078,  ...,  0.0645, -0.0420, -0.0219],\n",
       "                      [-0.0614,  0.0723,  0.0041,  ..., -0.0343,  0.0688,  0.0394]])),\n",
       "             ('encoder.layer.1.output.dense.bias',\n",
       "              tensor([ 0.0109,  0.0053,  0.0674,  ...,  0.0117, -0.0476,  0.0147])),\n",
       "             ('encoder.layer.1.output.LayerNorm.weight',\n",
       "              tensor([0.9609, 0.9941, 0.9404,  ..., 0.9702, 0.9683, 0.9365])),\n",
       "             ('encoder.layer.1.output.LayerNorm.bias',\n",
       "              tensor([ 0.1897, -0.1934, -0.0495,  ..., -0.0138, -0.2725,  0.1589])),\n",
       "             ('encoder.layer.2.attention.self.query.weight',\n",
       "              tensor([[ 0.0003, -0.0479,  0.0431,  ..., -0.0289, -0.0676, -0.0153],\n",
       "                      [-0.0823, -0.0898,  0.0355,  ..., -0.0230,  0.0029,  0.0134],\n",
       "                      [-0.0204, -0.0079, -0.0393,  ..., -0.0351, -0.0155, -0.0209],\n",
       "                      ...,\n",
       "                      [ 0.0219, -0.0164, -0.0113,  ..., -0.0356,  0.0807, -0.0701],\n",
       "                      [ 0.0315, -0.0955, -0.0500,  ..., -0.0432,  0.0002,  0.0130],\n",
       "                      [ 0.0215, -0.0232, -0.0687,  ...,  0.0747, -0.0058,  0.0457]])),\n",
       "             ('encoder.layer.2.attention.self.query.bias',\n",
       "              tensor([-0.0603,  0.1272,  0.1134,  ..., -0.1527,  0.0651, -0.1649])),\n",
       "             ('encoder.layer.2.attention.self.key.weight',\n",
       "              tensor([[ 0.0131,  0.1378,  0.0401,  ...,  0.0347,  0.0183, -0.0546],\n",
       "                      [ 0.0003,  0.0158, -0.0177,  ..., -0.0315, -0.0373,  0.0424],\n",
       "                      [ 0.0665, -0.0095,  0.0058,  ..., -0.0528,  0.0259, -0.0447],\n",
       "                      ...,\n",
       "                      [-0.0025, -0.0355, -0.0331,  ..., -0.0019, -0.0529, -0.0663],\n",
       "                      [-0.0566, -0.0352,  0.0327,  ...,  0.0011, -0.0503,  0.0195],\n",
       "                      [ 0.0336,  0.0129, -0.0254,  ...,  0.0652,  0.0098,  0.0503]])),\n",
       "             ('encoder.layer.2.attention.self.key.bias',\n",
       "              tensor([-0.0006, -0.0032, -0.0015,  ...,  0.0025, -0.0006, -0.0003])),\n",
       "             ('encoder.layer.2.attention.self.value.weight',\n",
       "              tensor([[-3.4370e-03,  4.9164e-02,  2.2186e-02,  ...,  2.5101e-02,\n",
       "                        2.7756e-02, -1.3781e-03],\n",
       "                      [-3.8624e-05,  8.9844e-02, -2.1042e-02,  ..., -4.3488e-03,\n",
       "                       -3.1525e-02, -6.6528e-03],\n",
       "                      [ 1.9547e-02,  4.7272e-02,  3.5248e-03,  ...,  3.5004e-02,\n",
       "                        2.9114e-02, -2.3575e-02],\n",
       "                      ...,\n",
       "                      [-1.2527e-02,  2.6398e-02, -1.1475e-02,  ..., -3.8879e-02,\n",
       "                       -2.4734e-02,  4.0863e-02],\n",
       "                      [ 6.2347e-02,  3.8513e-02, -4.0588e-02,  ..., -2.2827e-02,\n",
       "                        6.5613e-02,  2.9358e-02],\n",
       "                      [-2.3438e-02, -1.0963e-02,  1.7681e-03,  ..., -1.1505e-02,\n",
       "                        1.5343e-02,  5.3467e-02]])),\n",
       "             ('encoder.layer.2.attention.self.value.bias',\n",
       "              tensor([-0.0293,  0.0149,  0.0089,  ..., -0.0026,  0.0108, -0.0052])),\n",
       "             ('encoder.layer.2.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0005, -0.0482,  0.0431,  ..., -0.0290, -0.0692, -0.0151],\n",
       "                      [-0.0825, -0.0906,  0.0361,  ..., -0.0227,  0.0041,  0.0145],\n",
       "                      [-0.0208, -0.0072, -0.0388,  ..., -0.0344, -0.0140, -0.0209],\n",
       "                      ...,\n",
       "                      [ 0.0211, -0.0169, -0.0120,  ..., -0.0348,  0.0814, -0.0695],\n",
       "                      [ 0.0319, -0.0948, -0.0502,  ..., -0.0431, -0.0003,  0.0119],\n",
       "                      [ 0.0211, -0.0241, -0.0688,  ...,  0.0755, -0.0056,  0.0462]])),\n",
       "             ('encoder.layer.2.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0599,  0.1266,  0.1125,  ..., -0.1526,  0.0652, -0.1647])),\n",
       "             ('encoder.layer.2.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0009, -0.0472,  0.0435,  ..., -0.0284, -0.0676, -0.0151],\n",
       "                      [-0.0815, -0.0903,  0.0362,  ..., -0.0241,  0.0045,  0.0135],\n",
       "                      [-0.0208, -0.0076, -0.0380,  ..., -0.0348, -0.0153, -0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0223, -0.0159, -0.0119,  ..., -0.0353,  0.0815, -0.0695],\n",
       "                      [ 0.0318, -0.0950, -0.0498,  ..., -0.0430,  0.0009,  0.0121],\n",
       "                      [ 0.0218, -0.0240, -0.0690,  ...,  0.0752, -0.0059,  0.0461]])),\n",
       "             ('encoder.layer.2.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0608,  0.1270,  0.1131,  ..., -0.1528,  0.0649, -0.1647])),\n",
       "             ('encoder.layer.2.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0004, -0.0480,  0.0432,  ..., -0.0277, -0.0678, -0.0151],\n",
       "                      [-0.0819, -0.0909,  0.0357,  ..., -0.0236,  0.0036,  0.0141],\n",
       "                      [-0.0198, -0.0079, -0.0386,  ..., -0.0352, -0.0154, -0.0207],\n",
       "                      ...,\n",
       "                      [ 0.0224, -0.0163, -0.0113,  ..., -0.0359,  0.0810, -0.0691],\n",
       "                      [ 0.0317, -0.0945, -0.0504,  ..., -0.0425,  0.0005,  0.0116],\n",
       "                      [ 0.0216, -0.0240, -0.0682,  ...,  0.0743, -0.0058,  0.0463]])),\n",
       "             ('encoder.layer.2.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0608,  0.1270,  0.1135,  ..., -0.1521,  0.0647, -0.1643])),\n",
       "             ('encoder.layer.2.attention.output.dense.weight',\n",
       "              tensor([[-0.0134, -0.0185,  0.0227,  ..., -0.0042, -0.0105,  0.0215],\n",
       "                      [ 0.0053,  0.0161, -0.0151,  ..., -0.0476, -0.0120, -0.0026],\n",
       "                      [ 0.0063,  0.0410, -0.0690,  ..., -0.0133, -0.0132, -0.0135],\n",
       "                      ...,\n",
       "                      [-0.0316, -0.0073,  0.0503,  ..., -0.0046,  0.0113, -0.0107],\n",
       "                      [-0.0788,  0.0022,  0.0044,  ...,  0.0443,  0.0207, -0.0086],\n",
       "                      [ 0.0565,  0.0484,  0.0016,  ...,  0.0045,  0.0565,  0.0270]])),\n",
       "             ('encoder.layer.2.attention.output.dense.bias',\n",
       "              tensor([ 0.0612, -0.0575,  0.0323,  ...,  0.0818, -0.0381,  0.0750])),\n",
       "             ('encoder.layer.2.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9844, 0.9844, 0.9839,  ..., 0.9639, 0.9561, 0.9717])),\n",
       "             ('encoder.layer.2.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0937, -0.0035, -0.3413,  ..., -0.0270, -0.0707,  0.2170])),\n",
       "             ('encoder.layer.2.intermediate.dense.weight',\n",
       "              tensor([[ 2.1637e-02,  8.6243e-02,  6.9214e-02,  ..., -4.6906e-02,\n",
       "                       -1.3237e-02, -4.2328e-02],\n",
       "                      [-2.5146e-02, -6.8176e-02,  9.2712e-02,  ..., -7.4585e-02,\n",
       "                        5.3528e-02, -2.3117e-03],\n",
       "                      [-7.1655e-02,  4.0398e-03,  9.1797e-02,  ...,  1.4557e-02,\n",
       "                        2.1866e-02,  2.6855e-03],\n",
       "                      ...,\n",
       "                      [-3.8422e-02, -1.5549e-02,  5.8327e-03,  ...,  9.1858e-03,\n",
       "                       -1.1559e-03,  1.9073e-02],\n",
       "                      [-6.4209e-02,  1.2459e-02, -1.4587e-02,  ..., -1.8072e-03,\n",
       "                        3.4302e-02, -9.1980e-02],\n",
       "                      [-1.7285e-05,  1.8631e-02,  1.5747e-02,  ..., -1.3870e-02,\n",
       "                       -5.0537e-02, -1.0089e-01]])),\n",
       "             ('encoder.layer.2.intermediate.dense.bias',\n",
       "              tensor([-0.0231, -0.0798, -0.0697,  ...,  0.0595, -0.0860, -0.0901])),\n",
       "             ('encoder.layer.2.output.dense.weight',\n",
       "              tensor([[-0.0228,  0.0848,  0.0173,  ..., -0.0385, -0.1061,  0.0026],\n",
       "                      [-0.0032,  0.0186, -0.0611,  ...,  0.0482, -0.0289, -0.0113],\n",
       "                      [ 0.0523, -0.0566,  0.0584,  ...,  0.0111, -0.0482, -0.0760],\n",
       "                      ...,\n",
       "                      [ 0.0022, -0.0454,  0.0661,  ...,  0.0137,  0.1047, -0.0017],\n",
       "                      [ 0.0481, -0.0090, -0.0307,  ...,  0.0111, -0.0938, -0.0097],\n",
       "                      [ 0.0302, -0.0505, -0.0229,  ..., -0.0407,  0.0136,  0.0024]])),\n",
       "             ('encoder.layer.2.output.dense.bias',\n",
       "              tensor([-0.0081, -0.0427,  0.0117,  ...,  0.0311,  0.0149,  0.0456])),\n",
       "             ('encoder.layer.2.output.LayerNorm.weight',\n",
       "              tensor([0.9658, 0.9678, 0.9517,  ..., 0.9761, 0.9775, 0.9585])),\n",
       "             ('encoder.layer.2.output.LayerNorm.bias',\n",
       "              tensor([-0.0324, -0.1088,  0.2081,  ..., -0.0497, -0.0271, -0.2030])),\n",
       "             ('encoder.layer.3.attention.self.query.weight',\n",
       "              tensor([[-0.0692,  0.0113,  0.0363,  ...,  0.0251,  0.0511, -0.0131],\n",
       "                      [-0.0192, -0.0787, -0.0413,  ...,  0.0364, -0.0144,  0.0318],\n",
       "                      [-0.0204, -0.0166,  0.0804,  ...,  0.0341, -0.0174,  0.0057],\n",
       "                      ...,\n",
       "                      [-0.0573, -0.0114, -0.0103,  ...,  0.0396,  0.0895, -0.0156],\n",
       "                      [ 0.0670, -0.0320,  0.0414,  ..., -0.0896,  0.0230, -0.0345],\n",
       "                      [ 0.0327,  0.0645, -0.0220,  ..., -0.0438, -0.0320,  0.0217]])),\n",
       "             ('encoder.layer.3.attention.self.query.bias',\n",
       "              tensor([-0.0252, -0.0515,  0.0316,  ...,  0.0130,  0.1174, -0.0814])),\n",
       "             ('encoder.layer.3.attention.self.key.weight',\n",
       "              tensor([[-0.1348, -0.0401, -0.0014,  ...,  0.0218,  0.0508, -0.0275],\n",
       "                      [ 0.0268,  0.0994,  0.0907,  ..., -0.0239,  0.0826, -0.0440],\n",
       "                      [ 0.0050, -0.0410,  0.0916,  ..., -0.0214,  0.0171, -0.0213],\n",
       "                      ...,\n",
       "                      [-0.0250, -0.0044, -0.0051,  ...,  0.0714, -0.0627, -0.0399],\n",
       "                      [ 0.0044, -0.0239, -0.0045,  ...,  0.0388, -0.0312,  0.0059],\n",
       "                      [ 0.0296,  0.0116,  0.0230,  ...,  0.0174, -0.0285, -0.0182]])),\n",
       "             ('encoder.layer.3.attention.self.key.bias',\n",
       "              tensor([-0.0005,  0.0015,  0.0006,  ...,  0.0003, -0.0021,  0.0001])),\n",
       "             ('encoder.layer.3.attention.self.value.weight',\n",
       "              tensor([[ 0.0106, -0.0296, -0.0731,  ...,  0.0305,  0.0952,  0.0224],\n",
       "                      [-0.0164,  0.0392,  0.0460,  ..., -0.0300,  0.0101, -0.0068],\n",
       "                      [ 0.0403,  0.0391, -0.0698,  ..., -0.0504,  0.0274,  0.0202],\n",
       "                      ...,\n",
       "                      [ 0.0709,  0.0027,  0.0122,  ...,  0.0197,  0.0324,  0.0446],\n",
       "                      [-0.0240,  0.0493, -0.0339,  ..., -0.0035, -0.1051, -0.0111],\n",
       "                      [ 0.0273, -0.0094, -0.0410,  ..., -0.0299, -0.0014, -0.0493]])),\n",
       "             ('encoder.layer.3.attention.self.value.bias',\n",
       "              tensor([-0.0189, -0.0092, -0.0087,  ...,  0.0056,  0.0059, -0.0009])),\n",
       "             ('encoder.layer.3.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0703,  0.0098,  0.0364,  ...,  0.0260,  0.0518, -0.0126],\n",
       "                      [-0.0194, -0.0788, -0.0412,  ...,  0.0366, -0.0142,  0.0311],\n",
       "                      [-0.0192, -0.0169,  0.0803,  ...,  0.0333, -0.0176,  0.0063],\n",
       "                      ...,\n",
       "                      [-0.0580, -0.0111, -0.0101,  ...,  0.0396,  0.0898, -0.0157],\n",
       "                      [ 0.0663, -0.0331,  0.0411,  ..., -0.0894,  0.0228, -0.0347],\n",
       "                      [ 0.0323,  0.0638, -0.0221,  ..., -0.0440, -0.0322,  0.0216]])),\n",
       "             ('encoder.layer.3.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0252, -0.0518,  0.0317,  ...,  0.0138,  0.1171, -0.0805])),\n",
       "             ('encoder.layer.3.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0699,  0.0112,  0.0369,  ...,  0.0258,  0.0514, -0.0131],\n",
       "                      [-0.0192, -0.0793, -0.0417,  ...,  0.0370, -0.0143,  0.0318],\n",
       "                      [-0.0200, -0.0164,  0.0809,  ...,  0.0338, -0.0174,  0.0055],\n",
       "                      ...,\n",
       "                      [-0.0570, -0.0107, -0.0104,  ...,  0.0396,  0.0901, -0.0163],\n",
       "                      [ 0.0662, -0.0330,  0.0413,  ..., -0.0895,  0.0231, -0.0351],\n",
       "                      [ 0.0325,  0.0639, -0.0229,  ..., -0.0439, -0.0329,  0.0218]])),\n",
       "             ('encoder.layer.3.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0255, -0.0517,  0.0313,  ...,  0.0121,  0.1171, -0.0812])),\n",
       "             ('encoder.layer.3.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0692,  0.0112,  0.0373,  ...,  0.0253,  0.0515, -0.0131],\n",
       "                      [-0.0185, -0.0792, -0.0412,  ...,  0.0368, -0.0144,  0.0317],\n",
       "                      [-0.0198, -0.0167,  0.0807,  ...,  0.0334, -0.0174,  0.0056],\n",
       "                      ...,\n",
       "                      [-0.0574, -0.0109, -0.0101,  ...,  0.0394,  0.0898, -0.0153],\n",
       "                      [ 0.0667, -0.0328,  0.0418,  ..., -0.0901,  0.0233, -0.0348],\n",
       "                      [ 0.0317,  0.0633, -0.0221,  ..., -0.0433, -0.0322,  0.0220]])),\n",
       "             ('encoder.layer.3.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0257, -0.0520,  0.0314,  ...,  0.0132,  0.1173, -0.0809])),\n",
       "             ('encoder.layer.3.attention.output.dense.weight',\n",
       "              tensor([[-0.0011,  0.0025,  0.0338,  ...,  0.0006, -0.0271, -0.0290],\n",
       "                      [ 0.0108, -0.0077,  0.0414,  ...,  0.0160, -0.0203,  0.0140],\n",
       "                      [-0.0812,  0.0118, -0.0060,  ..., -0.0130,  0.0566, -0.0046],\n",
       "                      ...,\n",
       "                      [ 0.0232, -0.0010, -0.0213,  ...,  0.0211, -0.0293,  0.0163],\n",
       "                      [ 0.0115,  0.0443, -0.0003,  ..., -0.0078, -0.0108, -0.0085],\n",
       "                      [-0.0278, -0.0149,  0.0179,  ..., -0.0085,  0.0174,  0.0353]])),\n",
       "             ('encoder.layer.3.attention.output.dense.bias',\n",
       "              tensor([ 0.0416, -0.0173, -0.0270,  ..., -0.0223,  0.0339, -0.0195])),\n",
       "             ('encoder.layer.3.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9902, 0.9795, 0.9771,  ..., 0.9888, 0.9780, 0.9644])),\n",
       "             ('encoder.layer.3.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1794, -0.1175, -0.3018,  ..., -0.0448,  0.1127,  0.0366])),\n",
       "             ('encoder.layer.3.intermediate.dense.weight',\n",
       "              tensor([[ 0.0111,  0.0399, -0.0327,  ..., -0.0500, -0.0241, -0.0334],\n",
       "                      [ 0.0363,  0.0330,  0.0163,  ...,  0.0264, -0.0450, -0.0160],\n",
       "                      [ 0.0340, -0.0640, -0.0149,  ...,  0.0647, -0.1825,  0.0071],\n",
       "                      ...,\n",
       "                      [-0.0294, -0.0330, -0.0367,  ...,  0.0329, -0.0259, -0.0535],\n",
       "                      [ 0.0302, -0.0571, -0.0364,  ..., -0.0058,  0.0171, -0.0274],\n",
       "                      [ 0.0004,  0.0036, -0.0480,  ...,  0.0114, -0.0651, -0.0437]])),\n",
       "             ('encoder.layer.3.intermediate.dense.bias',\n",
       "              tensor([-0.0912, -0.1099, -0.0568,  ..., -0.1026, -0.0178, -0.0859])),\n",
       "             ('encoder.layer.3.output.dense.weight',\n",
       "              tensor([[-0.0192, -0.0285, -0.0228,  ...,  0.0220, -0.0685, -0.0088],\n",
       "                      [ 0.0233, -0.0093, -0.0246,  ..., -0.0055, -0.0484, -0.0692],\n",
       "                      [-0.0765, -0.0780,  0.0205,  ...,  0.0548, -0.0286, -0.0031],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0266,  0.0748,  ..., -0.0541, -0.0733,  0.0016],\n",
       "                      [-0.0949, -0.0780, -0.0582,  ..., -0.0207, -0.0069, -0.1099],\n",
       "                      [ 0.1377,  0.0521, -0.0617,  ...,  0.0497, -0.0419,  0.0295]])),\n",
       "             ('encoder.layer.3.output.dense.bias',\n",
       "              tensor([-0.0872,  0.0336,  0.0646,  ...,  0.0421, -0.0818,  0.2703])),\n",
       "             ('encoder.layer.3.output.LayerNorm.weight',\n",
       "              tensor([0.9751, 0.9888, 0.9673,  ..., 0.9712, 0.9663, 0.9473])),\n",
       "             ('encoder.layer.3.output.LayerNorm.bias',\n",
       "              tensor([ 0.0133, -0.0067,  0.1970,  ..., -0.0244, -0.1177, -0.0815])),\n",
       "             ('encoder.layer.4.attention.self.query.weight',\n",
       "              tensor([[-0.0048, -0.0116, -0.0579,  ..., -0.0100, -0.0352, -0.0083],\n",
       "                      [-0.0043,  0.0023,  0.0457,  ..., -0.0598, -0.0140,  0.0690],\n",
       "                      [-0.0833,  0.0049,  0.0118,  ..., -0.0637, -0.0124,  0.0270],\n",
       "                      ...,\n",
       "                      [ 0.0159,  0.0046, -0.0128,  ...,  0.0219,  0.0028,  0.0016],\n",
       "                      [ 0.0182, -0.0273,  0.0395,  ..., -0.0105, -0.0259,  0.0172],\n",
       "                      [ 0.0342, -0.1028, -0.0173,  ..., -0.0395, -0.0361, -0.1447]])),\n",
       "             ('encoder.layer.4.attention.self.query.bias',\n",
       "              tensor([ 0.2111,  0.0043,  0.2280,  ..., -0.2534, -0.1899,  0.2002])),\n",
       "             ('encoder.layer.4.attention.self.key.weight',\n",
       "              tensor([[-0.0172, -0.0750, -0.0478,  ..., -0.0066, -0.0432,  0.0080],\n",
       "                      [-0.0535, -0.0123,  0.0208,  ...,  0.0051, -0.0211,  0.0093],\n",
       "                      [ 0.0136,  0.0290,  0.0385,  ...,  0.0328,  0.0643, -0.0066],\n",
       "                      ...,\n",
       "                      [ 0.0373,  0.0782,  0.0371,  ...,  0.0547,  0.0094,  0.0895],\n",
       "                      [-0.0156, -0.0241, -0.0285,  ..., -0.0204, -0.0425,  0.0641],\n",
       "                      [ 0.0037,  0.0272, -0.0062,  ...,  0.0233, -0.0327,  0.0215]])),\n",
       "             ('encoder.layer.4.attention.self.key.bias',\n",
       "              tensor([-0.0004, -0.0006,  0.0002,  ..., -0.0005,  0.0003, -0.0001])),\n",
       "             ('encoder.layer.4.attention.self.value.weight',\n",
       "              tensor([[-0.0097, -0.0005,  0.0115,  ...,  0.0188,  0.0033,  0.0482],\n",
       "                      [ 0.0213,  0.0596, -0.0212,  ...,  0.0630, -0.0178, -0.0739],\n",
       "                      [ 0.0363,  0.0133,  0.0228,  ...,  0.0497, -0.0365,  0.0641],\n",
       "                      ...,\n",
       "                      [ 0.0101,  0.0669,  0.0218,  ...,  0.0451, -0.0022,  0.0248],\n",
       "                      [ 0.0252,  0.0064,  0.0164,  ...,  0.0272, -0.0034,  0.0626],\n",
       "                      [ 0.0095, -0.1021, -0.0005,  ..., -0.0421,  0.0341,  0.0093]])),\n",
       "             ('encoder.layer.4.attention.self.value.bias',\n",
       "              tensor([-0.0099, -0.0035,  0.0078,  ..., -0.0069,  0.0027, -0.0015])),\n",
       "             ('encoder.layer.4.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0046, -0.0114, -0.0574,  ..., -0.0105, -0.0349, -0.0074],\n",
       "                      [-0.0037,  0.0028,  0.0458,  ..., -0.0598, -0.0141,  0.0685],\n",
       "                      [-0.0831,  0.0045,  0.0123,  ..., -0.0638, -0.0127,  0.0271],\n",
       "                      ...,\n",
       "                      [ 0.0158,  0.0051, -0.0132,  ...,  0.0220,  0.0034,  0.0025],\n",
       "                      [ 0.0187, -0.0276,  0.0391,  ..., -0.0100, -0.0264,  0.0174],\n",
       "                      [ 0.0352, -0.1023, -0.0165,  ..., -0.0395, -0.0354, -0.1445]])),\n",
       "             ('encoder.layer.4.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.2120,  0.0037,  0.2285,  ..., -0.2539, -0.1892,  0.2001])),\n",
       "             ('encoder.layer.4.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0049, -0.0119, -0.0577,  ..., -0.0100, -0.0351, -0.0086],\n",
       "                      [-0.0031,  0.0035,  0.0457,  ..., -0.0600, -0.0143,  0.0695],\n",
       "                      [-0.0836,  0.0054,  0.0124,  ..., -0.0640, -0.0126,  0.0263],\n",
       "                      ...,\n",
       "                      [ 0.0156,  0.0045, -0.0125,  ...,  0.0225,  0.0034,  0.0020],\n",
       "                      [ 0.0185, -0.0269,  0.0385,  ..., -0.0101, -0.0267,  0.0173],\n",
       "                      [ 0.0345, -0.1022, -0.0175,  ..., -0.0390, -0.0352, -0.1449]])),\n",
       "             ('encoder.layer.4.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.2107,  0.0043,  0.2275,  ..., -0.2539, -0.1892,  0.2004])),\n",
       "             ('encoder.layer.4.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0046, -0.0117, -0.0580,  ..., -0.0105, -0.0351, -0.0084],\n",
       "                      [-0.0035,  0.0028,  0.0461,  ..., -0.0598, -0.0145,  0.0692],\n",
       "                      [-0.0834,  0.0047,  0.0119,  ..., -0.0635, -0.0125,  0.0263],\n",
       "                      ...,\n",
       "                      [ 0.0154,  0.0047, -0.0130,  ...,  0.0220,  0.0033,  0.0020],\n",
       "                      [ 0.0184, -0.0277,  0.0391,  ..., -0.0100, -0.0261,  0.0172],\n",
       "                      [ 0.0345, -0.1024, -0.0173,  ..., -0.0391, -0.0355, -0.1445]])),\n",
       "             ('encoder.layer.4.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.2107,  0.0046,  0.2273,  ..., -0.2542, -0.1895,  0.2004])),\n",
       "             ('encoder.layer.4.attention.output.dense.weight',\n",
       "              tensor([[-0.0355, -0.0723, -0.0189,  ..., -0.0075, -0.0106,  0.0657],\n",
       "                      [-0.0439, -0.0138, -0.0081,  ...,  0.0479,  0.0296,  0.0063],\n",
       "                      [ 0.0077,  0.0093, -0.0097,  ..., -0.0410,  0.0453, -0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0056,  0.0078,  0.0048,  ...,  0.0102,  0.0030, -0.0156],\n",
       "                      [-0.0010,  0.0143, -0.0287,  ...,  0.0525,  0.0054, -0.0255],\n",
       "                      [ 0.0171,  0.0429, -0.0140,  ..., -0.0104, -0.0246,  0.0065]])),\n",
       "             ('encoder.layer.4.attention.output.dense.bias',\n",
       "              tensor([-0.0068, -0.0116, -0.0084,  ...,  0.0171, -0.0643, -0.0034])),\n",
       "             ('encoder.layer.4.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9912, 0.9941, 0.9873,  ..., 0.9858, 0.9966, 0.9575])),\n",
       "             ('encoder.layer.4.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1671,  0.0793, -0.2969,  ...,  0.0615,  0.0174,  0.2063])),\n",
       "             ('encoder.layer.4.intermediate.dense.weight',\n",
       "              tensor([[ 0.0023,  0.0547, -0.0293,  ..., -0.0751,  0.0538,  0.0414],\n",
       "                      [-0.0141, -0.0166, -0.0067,  ..., -0.0164, -0.0176, -0.0872],\n",
       "                      [-0.0312,  0.0116,  0.0497,  ..., -0.0912,  0.0204, -0.0461],\n",
       "                      ...,\n",
       "                      [-0.0573, -0.0226,  0.0654,  ...,  0.1235,  0.0429, -0.0715],\n",
       "                      [-0.0049, -0.0798, -0.0870,  ..., -0.0537, -0.0265,  0.0606],\n",
       "                      [-0.0364, -0.0251,  0.0061,  ...,  0.0237,  0.0355, -0.0443]])),\n",
       "             ('encoder.layer.4.intermediate.dense.bias',\n",
       "              tensor([-0.0908, -0.0793, -0.0723,  ..., -0.0704, -0.0524, -0.0552])),\n",
       "             ('encoder.layer.4.output.dense.weight',\n",
       "              tensor([[-0.0193,  0.0604,  0.0076,  ...,  0.0364, -0.0123, -0.0303],\n",
       "                      [-0.0456, -0.0289, -0.0543,  ...,  0.0342, -0.0569,  0.0027],\n",
       "                      [ 0.0162,  0.0829,  0.1042,  ...,  0.0024,  0.0531, -0.0298],\n",
       "                      ...,\n",
       "                      [-0.0370, -0.0462, -0.0655,  ...,  0.1377, -0.0663,  0.0141],\n",
       "                      [ 0.0360, -0.0242,  0.0308,  ...,  0.1028, -0.0171,  0.0116],\n",
       "                      [ 0.0049, -0.0453, -0.0970,  ..., -0.0390,  0.0637, -0.0401]])),\n",
       "             ('encoder.layer.4.output.dense.bias',\n",
       "              tensor([-0.0836, -0.0169,  0.1398,  ...,  0.0107, -0.0988,  0.1644])),\n",
       "             ('encoder.layer.4.output.LayerNorm.weight',\n",
       "              tensor([0.9722, 0.9922, 0.9746,  ..., 0.9766, 0.9956, 0.9648])),\n",
       "             ('encoder.layer.4.output.LayerNorm.bias',\n",
       "              tensor([ 0.0117, -0.1006,  0.2795,  ..., -0.1052, -0.1005, -0.1656])),\n",
       "             ('encoder.layer.5.attention.self.query.weight',\n",
       "              tensor([[ 6.9336e-02, -1.7319e-02,  2.5299e-02,  ..., -1.4160e-02,\n",
       "                        2.2125e-02,  3.6163e-02],\n",
       "                      [ 5.4535e-02, -1.0048e-02,  6.8130e-03,  ...,  1.9932e-03,\n",
       "                        4.3854e-02, -1.3782e-01],\n",
       "                      [-5.3284e-02, -6.5002e-03, -1.8433e-02,  ...,  2.3331e-02,\n",
       "                       -4.6936e-02, -5.9175e-04],\n",
       "                      ...,\n",
       "                      [-1.6708e-02, -1.9165e-02, -7.5195e-02,  ..., -3.3081e-02,\n",
       "                        1.2833e-02,  9.7930e-05],\n",
       "                      [ 4.6753e-02, -8.4045e-02,  2.2797e-02,  ...,  3.2623e-02,\n",
       "                        2.3682e-02, -3.1311e-02],\n",
       "                      [-1.1513e-02,  2.3529e-02,  5.9814e-02,  ...,  1.0101e-02,\n",
       "                        6.6162e-02,  5.5450e-02]])),\n",
       "             ('encoder.layer.5.attention.self.query.bias',\n",
       "              tensor([ 0.0316, -0.0279, -0.0237,  ...,  0.0286,  0.1267, -0.1344])),\n",
       "             ('encoder.layer.5.attention.self.key.weight',\n",
       "              tensor([[ 1.6451e-03,  6.4026e-02, -7.0534e-03,  ..., -3.9032e-02,\n",
       "                        4.5166e-03, -1.3634e-02],\n",
       "                      [ 3.9093e-02, -1.9409e-02, -3.4882e-02,  ...,  3.9185e-02,\n",
       "                        2.8961e-02, -3.7811e-02],\n",
       "                      [ 3.3539e-02, -1.5053e-02, -3.2196e-02,  ..., -1.0950e-01,\n",
       "                        4.4159e-02,  3.1494e-02],\n",
       "                      ...,\n",
       "                      [ 2.9617e-02, -5.1641e-04, -5.7983e-03,  ...,  2.4765e-02,\n",
       "                        6.5552e-02,  4.0741e-02],\n",
       "                      [ 1.7715e-02,  5.5847e-03, -1.2016e-02,  ...,  1.3283e-02,\n",
       "                       -1.6815e-02,  8.7204e-03],\n",
       "                      [-7.2510e-02,  3.5763e-07,  5.9723e-02,  ..., -5.2887e-02,\n",
       "                        1.7258e-02,  3.1490e-03]])),\n",
       "             ('encoder.layer.5.attention.self.key.bias',\n",
       "              tensor([ 0.0017, -0.0008,  0.0012,  ...,  0.0007,  0.0037, -0.0018])),\n",
       "             ('encoder.layer.5.attention.self.value.weight',\n",
       "              tensor([[-0.0194,  0.0536,  0.0140,  ..., -0.0014, -0.0059,  0.0480],\n",
       "                      [-0.0663, -0.0649, -0.0117,  ...,  0.0232, -0.0415, -0.0605],\n",
       "                      [ 0.0382, -0.0432, -0.0295,  ..., -0.0011, -0.0129,  0.0322],\n",
       "                      ...,\n",
       "                      [ 0.0306, -0.0235, -0.0108,  ..., -0.0295, -0.0084, -0.0315],\n",
       "                      [ 0.0569,  0.0293, -0.0966,  ...,  0.0110, -0.0084,  0.0479],\n",
       "                      [-0.0338,  0.0692, -0.0239,  ..., -0.0207, -0.0203,  0.0236]])),\n",
       "             ('encoder.layer.5.attention.self.value.bias',\n",
       "              tensor([ 0.0026, -0.0055, -0.0020,  ...,  0.0086, -0.0052, -0.0094])),\n",
       "             ('encoder.layer.5.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0698, -0.0164,  0.0256,  ..., -0.0146,  0.0225,  0.0367],\n",
       "                      [ 0.0541, -0.0096,  0.0067,  ...,  0.0008,  0.0434, -0.1379],\n",
       "                      [-0.0540, -0.0060, -0.0182,  ...,  0.0228, -0.0476, -0.0009],\n",
       "                      ...,\n",
       "                      [-0.0161, -0.0184, -0.0744,  ..., -0.0338,  0.0129,  0.0002],\n",
       "                      [ 0.0460, -0.0852,  0.0220,  ...,  0.0331,  0.0237, -0.0324],\n",
       "                      [-0.0123,  0.0236,  0.0591,  ...,  0.0096,  0.0658,  0.0553]])),\n",
       "             ('encoder.layer.5.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0321, -0.0285, -0.0243,  ...,  0.0287,  0.1265, -0.1344])),\n",
       "             ('encoder.layer.5.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0698, -0.0167,  0.0247,  ..., -0.0140,  0.0228,  0.0353],\n",
       "                      [ 0.0543, -0.0093,  0.0080,  ...,  0.0004,  0.0429, -0.1367],\n",
       "                      [-0.0536, -0.0062, -0.0196,  ...,  0.0234, -0.0473, -0.0024],\n",
       "                      ...,\n",
       "                      [-0.0169, -0.0192, -0.0752,  ..., -0.0327,  0.0127, -0.0007],\n",
       "                      [ 0.0470, -0.0844,  0.0227,  ...,  0.0327,  0.0240, -0.0320],\n",
       "                      [-0.0116,  0.0242,  0.0592,  ...,  0.0096,  0.0667,  0.0551]])),\n",
       "             ('encoder.layer.5.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0303, -0.0265, -0.0259,  ...,  0.0283,  0.1266, -0.1342])),\n",
       "             ('encoder.layer.5.attention.self.e2e_query.weight',\n",
       "              tensor([[ 6.9214e-02, -1.5823e-02,  2.6535e-02,  ..., -1.5587e-02,\n",
       "                        2.2232e-02,  3.7933e-02],\n",
       "                      [ 5.5023e-02, -9.9258e-03,  6.1760e-03,  ...,  2.0332e-03,\n",
       "                        4.3732e-02, -1.3892e-01],\n",
       "                      [-5.4260e-02, -5.6839e-03, -1.7563e-02,  ...,  2.1820e-02,\n",
       "                       -4.8035e-02, -4.6909e-05],\n",
       "                      ...,\n",
       "                      [-1.6327e-02, -1.8692e-02, -7.4951e-02,  ..., -3.2776e-02,\n",
       "                        1.3390e-02, -1.2636e-03],\n",
       "                      [ 4.6265e-02, -8.5083e-02,  2.1912e-02,  ...,  3.2837e-02,\n",
       "                        2.3361e-02, -3.1342e-02],\n",
       "                      [-1.2390e-02,  2.3590e-02,  5.8899e-02,  ...,  9.2926e-03,\n",
       "                        6.6223e-02,  5.5603e-02]])),\n",
       "             ('encoder.layer.5.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0330, -0.0289, -0.0235,  ...,  0.0284,  0.1261, -0.1342])),\n",
       "             ('encoder.layer.5.attention.output.dense.weight',\n",
       "              tensor([[ 0.0294, -0.0096, -0.0186,  ...,  0.0224,  0.0250, -0.0238],\n",
       "                      [-0.0995,  0.0264,  0.0084,  ..., -0.0531, -0.0200,  0.0451],\n",
       "                      [ 0.0625, -0.0075,  0.0410,  ..., -0.0177, -0.0416, -0.0313],\n",
       "                      ...,\n",
       "                      [-0.0086, -0.0521, -0.0145,  ..., -0.0068,  0.0221, -0.0332],\n",
       "                      [ 0.0024,  0.0141,  0.0371,  ...,  0.0058, -0.0707, -0.0075],\n",
       "                      [ 0.0035,  0.0249,  0.0193,  ...,  0.0319, -0.0072, -0.0026]])),\n",
       "             ('encoder.layer.5.attention.output.dense.bias',\n",
       "              tensor([ 0.0069,  0.0101, -0.0751,  ..., -0.0281, -0.0622, -0.0142])),\n",
       "             ('encoder.layer.5.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9907, 0.9985, 0.9985,  ..., 0.9795, 0.9922, 0.9692])),\n",
       "             ('encoder.layer.5.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1210,  0.0566, -0.2688,  ...,  0.0004, -0.0929,  0.0938])),\n",
       "             ('encoder.layer.5.intermediate.dense.weight',\n",
       "              tensor([[-0.0039, -0.0371, -0.0339,  ..., -0.0102, -0.0074, -0.0216],\n",
       "                      [-0.0056, -0.0417, -0.0221,  ..., -0.0152,  0.0682, -0.0400],\n",
       "                      [ 0.0634,  0.0468,  0.0047,  ..., -0.0110, -0.0377,  0.0522],\n",
       "                      ...,\n",
       "                      [-0.0170, -0.0531, -0.0112,  ...,  0.0620, -0.0022, -0.0717],\n",
       "                      [-0.0215, -0.1219, -0.0007,  ...,  0.0276,  0.0666, -0.0353],\n",
       "                      [-0.0626,  0.0396,  0.0501,  ...,  0.0248,  0.0035,  0.0488]])),\n",
       "             ('encoder.layer.5.intermediate.dense.bias',\n",
       "              tensor([-0.0723, -0.1092, -0.1085,  ..., -0.0520, -0.1166, -0.1045])),\n",
       "             ('encoder.layer.5.output.dense.weight',\n",
       "              tensor([[-0.0298,  0.0577, -0.0004,  ..., -0.0181, -0.0363,  0.0270],\n",
       "                      [ 0.0432, -0.0573,  0.0622,  ..., -0.0422, -0.0212, -0.0703],\n",
       "                      [ 0.0057,  0.0140, -0.0124,  ..., -0.0307, -0.0123, -0.0762],\n",
       "                      ...,\n",
       "                      [-0.0681, -0.0643, -0.0325,  ...,  0.0006,  0.0983, -0.0229],\n",
       "                      [-0.0088,  0.0202, -0.0761,  ..., -0.0248, -0.0096,  0.0071],\n",
       "                      [ 0.0018, -0.0226,  0.0839,  ..., -0.0544,  0.0298, -0.0390]])),\n",
       "             ('encoder.layer.5.output.dense.bias',\n",
       "              tensor([-0.1064,  0.0096,  0.1367,  ..., -0.0008, -0.0582,  0.1449])),\n",
       "             ('encoder.layer.5.output.LayerNorm.weight',\n",
       "              tensor([0.9736, 0.9941, 0.9902,  ..., 0.9771, 0.9893, 0.9561])),\n",
       "             ('encoder.layer.5.output.LayerNorm.bias',\n",
       "              tensor([-0.0168, -0.1134,  0.2703,  ..., -0.1185, -0.0455, -0.1478])),\n",
       "             ('encoder.layer.6.attention.self.query.weight',\n",
       "              tensor([[ 0.0191, -0.0274,  0.0555,  ...,  0.0440,  0.0507,  0.0070],\n",
       "                      [-0.0064, -0.0346, -0.0075,  ..., -0.0074, -0.0504, -0.0337],\n",
       "                      [ 0.0385,  0.1499,  0.0865,  ...,  0.0527,  0.0464,  0.0359],\n",
       "                      ...,\n",
       "                      [ 0.0106, -0.0030, -0.1033,  ...,  0.0304,  0.0675,  0.0625],\n",
       "                      [ 0.0259,  0.0175,  0.0193,  ...,  0.0042,  0.0257,  0.0856],\n",
       "                      [-0.0403, -0.0035,  0.0387,  ..., -0.0431,  0.0334, -0.0291]])),\n",
       "             ('encoder.layer.6.attention.self.query.bias',\n",
       "              tensor([-0.3086,  0.0538, -0.3079,  ..., -0.0919,  0.0284,  0.0072])),\n",
       "             ('encoder.layer.6.attention.self.key.weight',\n",
       "              tensor([[ 0.0276, -0.0291,  0.0681,  ..., -0.0124, -0.0306, -0.0020],\n",
       "                      [-0.0172,  0.0290,  0.0191,  ...,  0.0995,  0.0760,  0.0158],\n",
       "                      [ 0.0530,  0.0023,  0.0164,  ..., -0.0137, -0.0324, -0.0408],\n",
       "                      ...,\n",
       "                      [-0.0184,  0.0137,  0.0039,  ..., -0.0318,  0.0146, -0.0016],\n",
       "                      [-0.0743, -0.0652,  0.0002,  ...,  0.0444,  0.0355, -0.0076],\n",
       "                      [ 0.0126,  0.0371,  0.0011,  ...,  0.0569,  0.0309, -0.0071]])),\n",
       "             ('encoder.layer.6.attention.self.key.bias',\n",
       "              tensor([-0.0023,  0.0019,  0.0023,  ...,  0.0041, -0.0017,  0.0008])),\n",
       "             ('encoder.layer.6.attention.self.value.weight',\n",
       "              tensor([[ 0.0092,  0.0158, -0.0072,  ..., -0.0324, -0.0140, -0.0007],\n",
       "                      [-0.0025,  0.0403,  0.0201,  ..., -0.0583,  0.0352,  0.0144],\n",
       "                      [-0.0168, -0.0579,  0.0550,  ...,  0.0447, -0.0038,  0.0248],\n",
       "                      ...,\n",
       "                      [ 0.0170,  0.0394,  0.0008,  ...,  0.0479, -0.0569, -0.0010],\n",
       "                      [ 0.0117, -0.0156, -0.0036,  ..., -0.0306,  0.0201, -0.0155],\n",
       "                      [ 0.0127,  0.0234,  0.0216,  ..., -0.0321,  0.1088,  0.0267]])),\n",
       "             ('encoder.layer.6.attention.self.value.bias',\n",
       "              tensor([-0.0066, -0.0081, -0.0019,  ..., -0.0177, -0.0101, -0.0023])),\n",
       "             ('encoder.layer.6.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0187, -0.0283,  0.0552,  ...,  0.0433,  0.0501,  0.0066],\n",
       "                      [-0.0063, -0.0342, -0.0072,  ..., -0.0065, -0.0499, -0.0332],\n",
       "                      [ 0.0383,  0.1493,  0.0866,  ...,  0.0523,  0.0459,  0.0362],\n",
       "                      ...,\n",
       "                      [ 0.0102, -0.0024, -0.1021,  ...,  0.0304,  0.0673,  0.0632],\n",
       "                      [ 0.0265,  0.0177,  0.0188,  ...,  0.0048,  0.0254,  0.0850],\n",
       "                      [-0.0403, -0.0042,  0.0378,  ..., -0.0421,  0.0338, -0.0295]])),\n",
       "             ('encoder.layer.6.attention.self.w2e_query.bias',\n",
       "              tensor([-0.3079,  0.0541, -0.3071,  ..., -0.0925,  0.0281,  0.0066])),\n",
       "             ('encoder.layer.6.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0200, -0.0279,  0.0560,  ...,  0.0439,  0.0508,  0.0067],\n",
       "                      [-0.0070, -0.0348, -0.0069,  ..., -0.0075, -0.0508, -0.0339],\n",
       "                      [ 0.0385,  0.1497,  0.0869,  ...,  0.0523,  0.0457,  0.0362],\n",
       "                      ...,\n",
       "                      [ 0.0104, -0.0024, -0.1028,  ...,  0.0312,  0.0673,  0.0628],\n",
       "                      [ 0.0265,  0.0187,  0.0196,  ...,  0.0038,  0.0251,  0.0859],\n",
       "                      [-0.0408, -0.0044,  0.0373,  ..., -0.0422,  0.0334, -0.0291]])),\n",
       "             ('encoder.layer.6.attention.self.e2w_query.bias',\n",
       "              tensor([-0.3076,  0.0539, -0.3076,  ..., -0.0927,  0.0282,  0.0061])),\n",
       "             ('encoder.layer.6.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0187, -0.0281,  0.0553,  ...,  0.0435,  0.0511,  0.0070],\n",
       "                      [-0.0067, -0.0346, -0.0072,  ..., -0.0069, -0.0507, -0.0339],\n",
       "                      [ 0.0381,  0.1495,  0.0863,  ...,  0.0523,  0.0461,  0.0363],\n",
       "                      ...,\n",
       "                      [ 0.0111, -0.0024, -0.1033,  ...,  0.0308,  0.0671,  0.0633],\n",
       "                      [ 0.0267,  0.0179,  0.0181,  ...,  0.0049,  0.0250,  0.0853],\n",
       "                      [-0.0414, -0.0045,  0.0383,  ..., -0.0421,  0.0331, -0.0298]])),\n",
       "             ('encoder.layer.6.attention.self.e2e_query.bias',\n",
       "              tensor([-0.3079,  0.0538, -0.3076,  ..., -0.0924,  0.0275,  0.0057])),\n",
       "             ('encoder.layer.6.attention.output.dense.weight',\n",
       "              tensor([[-0.0381,  0.0060, -0.0181,  ...,  0.0412, -0.0340, -0.0060],\n",
       "                      [ 0.0182, -0.0333, -0.0387,  ...,  0.0184,  0.0386, -0.0211],\n",
       "                      [ 0.0490, -0.0558, -0.0347,  ...,  0.0259,  0.0654, -0.0326],\n",
       "                      ...,\n",
       "                      [-0.0152,  0.0487,  0.0014,  ..., -0.0396,  0.0066,  0.0203],\n",
       "                      [-0.0274,  0.0246,  0.0402,  ...,  0.0244, -0.0206, -0.0407],\n",
       "                      [-0.0220,  0.0468,  0.0235,  ...,  0.0573,  0.0059,  0.0195]])),\n",
       "             ('encoder.layer.6.attention.output.dense.bias',\n",
       "              tensor([ 0.0074, -0.0103,  0.0320,  ..., -0.0007, -0.0668,  0.0093])),\n",
       "             ('encoder.layer.6.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9863, 1.0010, 1.0000,  ..., 0.9839, 0.9785, 0.9507])),\n",
       "             ('encoder.layer.6.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1212,  0.0573, -0.2832,  ..., -0.0249, -0.1036,  0.1007])),\n",
       "             ('encoder.layer.6.intermediate.dense.weight',\n",
       "              tensor([[-0.0072, -0.0098, -0.0129,  ..., -0.0032,  0.0383,  0.0657],\n",
       "                      [ 0.0070,  0.0061,  0.0020,  ..., -0.0295,  0.0241, -0.0394],\n",
       "                      [-0.0615, -0.0760, -0.0501,  ...,  0.0775, -0.0170, -0.0793],\n",
       "                      ...,\n",
       "                      [-0.0487, -0.0450,  0.0055,  ..., -0.0157,  0.0779, -0.0472],\n",
       "                      [ 0.0014, -0.0007,  0.0093,  ...,  0.0117,  0.0122,  0.0071],\n",
       "                      [-0.0139, -0.0630,  0.0478,  ..., -0.0173,  0.0205, -0.1285]])),\n",
       "             ('encoder.layer.6.intermediate.dense.bias',\n",
       "              tensor([-0.0801, -0.0938, -0.1008,  ..., -0.0772, -0.0706, -0.1740])),\n",
       "             ('encoder.layer.6.output.dense.weight',\n",
       "              tensor([[ 0.0255, -0.0316, -0.0169,  ...,  0.0354,  0.0260, -0.0037],\n",
       "                      [ 0.0099, -0.0424, -0.0053,  ..., -0.0090,  0.0345,  0.0071],\n",
       "                      [ 0.0258, -0.0111, -0.0872,  ...,  0.0444, -0.0430,  0.0403],\n",
       "                      ...,\n",
       "                      [ 0.0117, -0.0619,  0.0111,  ..., -0.0165,  0.0546, -0.0435],\n",
       "                      [ 0.0295, -0.0011, -0.1118,  ..., -0.0197, -0.0283,  0.0630],\n",
       "                      [ 0.0385,  0.0103,  0.0164,  ..., -0.0274,  0.0252, -0.0165]])),\n",
       "             ('encoder.layer.6.output.dense.bias',\n",
       "              tensor([-0.0682,  0.0310,  0.0649,  ..., -0.0076, -0.0544,  0.0703])),\n",
       "             ('encoder.layer.6.output.LayerNorm.weight',\n",
       "              tensor([0.9810, 0.9917, 1.0010,  ..., 0.9829, 0.9756, 0.9580])),\n",
       "             ('encoder.layer.6.output.LayerNorm.bias',\n",
       "              tensor([-0.0244, -0.1123,  0.1108,  ..., -0.0813, -0.0277, -0.1342])),\n",
       "             ('encoder.layer.7.attention.self.query.weight',\n",
       "              tensor([[ 0.0180, -0.0184,  0.0033,  ...,  0.0238, -0.0409, -0.1068],\n",
       "                      [ 0.0537, -0.0863, -0.0176,  ...,  0.0195, -0.0401,  0.0211],\n",
       "                      [-0.1298,  0.0182,  0.0236,  ...,  0.0137,  0.0829,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.1951,  0.0442,  ...,  0.0558,  0.0096,  0.1268],\n",
       "                      [ 0.0082,  0.0291, -0.0292,  ...,  0.0123,  0.0730,  0.1010],\n",
       "                      [ 0.0155,  0.0116,  0.0266,  ...,  0.0961,  0.1191,  0.0444]])),\n",
       "             ('encoder.layer.7.attention.self.query.bias',\n",
       "              tensor([ 0.0167,  0.0146, -0.0549,  ..., -0.2546,  0.1248, -0.2620])),\n",
       "             ('encoder.layer.7.attention.self.key.weight',\n",
       "              tensor([[ 0.0047, -0.0028, -0.0563,  ..., -0.0108, -0.0041,  0.0657],\n",
       "                      [ 0.0112,  0.0036,  0.0254,  ...,  0.0251, -0.0430,  0.0037],\n",
       "                      [-0.0118, -0.0464, -0.0176,  ...,  0.0202, -0.0370,  0.0291],\n",
       "                      ...,\n",
       "                      [-0.0215,  0.0020,  0.0296,  ..., -0.0529, -0.0782, -0.0426],\n",
       "                      [-0.0684,  0.0409,  0.0163,  ..., -0.0070, -0.0227,  0.0784],\n",
       "                      [ 0.0212,  0.0218,  0.0275,  ...,  0.0087, -0.0120, -0.0377]])),\n",
       "             ('encoder.layer.7.attention.self.key.bias',\n",
       "              tensor([ 0.0003,  0.0002,  0.0002,  ..., -0.0026, -0.0019, -0.0017])),\n",
       "             ('encoder.layer.7.attention.self.value.weight',\n",
       "              tensor([[ 0.0063, -0.0164,  0.0039,  ...,  0.0194, -0.0032, -0.0408],\n",
       "                      [-0.0115, -0.0283, -0.0230,  ..., -0.0106, -0.0347, -0.0465],\n",
       "                      [ 0.0265, -0.0222,  0.0264,  ..., -0.0151,  0.0234,  0.0066],\n",
       "                      ...,\n",
       "                      [-0.0027, -0.0408,  0.0154,  ...,  0.0225,  0.0395,  0.0111],\n",
       "                      [-0.0538, -0.0531, -0.0034,  ...,  0.0465,  0.0203,  0.0214],\n",
       "                      [ 0.0334,  0.0006, -0.0258,  ...,  0.0323, -0.0358, -0.0147]])),\n",
       "             ('encoder.layer.7.attention.self.value.bias',\n",
       "              tensor([ 0.0009,  0.0338, -0.0517,  ...,  0.0139,  0.0031,  0.0053])),\n",
       "             ('encoder.layer.7.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0179, -0.0180,  0.0035,  ...,  0.0231, -0.0400, -0.1065],\n",
       "                      [ 0.0537, -0.0859, -0.0164,  ...,  0.0199, -0.0406,  0.0197],\n",
       "                      [-0.1305,  0.0170,  0.0233,  ...,  0.0154,  0.0837,  0.0026],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.1953,  0.0440,  ...,  0.0560,  0.0093,  0.1260],\n",
       "                      [ 0.0084,  0.0286, -0.0303,  ...,  0.0115,  0.0728,  0.0999],\n",
       "                      [ 0.0158,  0.0118,  0.0263,  ...,  0.0967,  0.1193,  0.0443]])),\n",
       "             ('encoder.layer.7.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0170,  0.0140, -0.0550,  ..., -0.2544,  0.1249, -0.2620])),\n",
       "             ('encoder.layer.7.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0188, -0.0178,  0.0029,  ...,  0.0226, -0.0392, -0.1075],\n",
       "                      [ 0.0550, -0.0868, -0.0160,  ...,  0.0200, -0.0403,  0.0206],\n",
       "                      [-0.1294,  0.0161,  0.0234,  ...,  0.0143,  0.0825,  0.0041],\n",
       "                      ...,\n",
       "                      [-0.0287,  0.1959,  0.0454,  ...,  0.0556,  0.0086,  0.1277],\n",
       "                      [ 0.0082,  0.0293, -0.0297,  ...,  0.0117,  0.0729,  0.1014],\n",
       "                      [ 0.0154,  0.0123,  0.0269,  ...,  0.0966,  0.1184,  0.0452]])),\n",
       "             ('encoder.layer.7.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0174,  0.0142, -0.0547,  ..., -0.2537,  0.1254, -0.2617])),\n",
       "             ('encoder.layer.7.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0184, -0.0181,  0.0037,  ...,  0.0231, -0.0403, -0.1058],\n",
       "                      [ 0.0539, -0.0854, -0.0169,  ...,  0.0185, -0.0410,  0.0210],\n",
       "                      [-0.1307,  0.0161,  0.0227,  ...,  0.0145,  0.0834,  0.0034],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.1947,  0.0442,  ...,  0.0558,  0.0093,  0.1274],\n",
       "                      [ 0.0081,  0.0287, -0.0302,  ...,  0.0118,  0.0726,  0.1011],\n",
       "                      [ 0.0153,  0.0117,  0.0261,  ...,  0.0967,  0.1193,  0.0449]])),\n",
       "             ('encoder.layer.7.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0172,  0.0154, -0.0546,  ..., -0.2542,  0.1249, -0.2622])),\n",
       "             ('encoder.layer.7.attention.output.dense.weight',\n",
       "              tensor([[ 0.0017, -0.0088,  0.0260,  ...,  0.0087,  0.0618, -0.0324],\n",
       "                      [-0.0372,  0.0020,  0.0134,  ...,  0.0394, -0.0769,  0.0254],\n",
       "                      [-0.0338, -0.0224,  0.0125,  ...,  0.0452,  0.0380,  0.0360],\n",
       "                      ...,\n",
       "                      [ 0.0468,  0.0038,  0.0503,  ...,  0.0088, -0.0650, -0.0061],\n",
       "                      [ 0.0116,  0.0146,  0.0085,  ..., -0.0078,  0.0175,  0.0344],\n",
       "                      [-0.0111, -0.0271, -0.0085,  ..., -0.0511, -0.0149,  0.0452]])),\n",
       "             ('encoder.layer.7.attention.output.dense.bias',\n",
       "              tensor([-0.0160,  0.0177, -0.0382,  ..., -0.0472, -0.0036,  0.0279])),\n",
       "             ('encoder.layer.7.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9893, 0.9858, 1.0000,  ..., 0.9824, 0.9600, 0.9736])),\n",
       "             ('encoder.layer.7.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0914,  0.0115, -0.4255,  ..., -0.0746, -0.1012, -0.0005])),\n",
       "             ('encoder.layer.7.intermediate.dense.weight',\n",
       "              tensor([[-0.0624,  0.0346,  0.0146,  ...,  0.0605,  0.0029,  0.0340],\n",
       "                      [ 0.0616,  0.0391, -0.0108,  ...,  0.0022, -0.0381, -0.0384],\n",
       "                      [-0.0389, -0.0217, -0.0027,  ...,  0.0152,  0.0168,  0.0369],\n",
       "                      ...,\n",
       "                      [ 0.0085,  0.0289,  0.0034,  ..., -0.0396, -0.0216,  0.0088],\n",
       "                      [-0.0290, -0.1046,  0.0171,  ..., -0.0875, -0.0072, -0.0133],\n",
       "                      [-0.0510, -0.0491,  0.0022,  ...,  0.0431, -0.0265,  0.0333]])),\n",
       "             ('encoder.layer.7.intermediate.dense.bias',\n",
       "              tensor([-0.0927, -0.0911, -0.0093,  ...,  0.0066, -0.0867, -0.0317])),\n",
       "             ('encoder.layer.7.output.dense.weight',\n",
       "              tensor([[-0.0152,  0.0691, -0.0159,  ...,  0.0145, -0.1045, -0.0387],\n",
       "                      [ 0.0349,  0.0783,  0.0063,  ..., -0.0378, -0.0623,  0.0322],\n",
       "                      [-0.0170, -0.0065, -0.0098,  ...,  0.0288,  0.0146,  0.0065],\n",
       "                      ...,\n",
       "                      [-0.0588,  0.0388, -0.0263,  ...,  0.0265, -0.0131,  0.0303],\n",
       "                      [-0.0053, -0.0009, -0.0233,  ...,  0.0274,  0.0177,  0.0128],\n",
       "                      [ 0.0675, -0.0200,  0.0125,  ..., -0.0291,  0.0172, -0.0451]])),\n",
       "             ('encoder.layer.7.output.dense.bias',\n",
       "              tensor([-0.1936,  0.0498,  0.1147,  ..., -0.0159, -0.0419,  0.0591])),\n",
       "             ('encoder.layer.7.output.LayerNorm.weight',\n",
       "              tensor([0.9858, 0.9907, 1.0010,  ..., 0.9839, 0.9771, 0.9512])),\n",
       "             ('encoder.layer.7.output.LayerNorm.bias',\n",
       "              tensor([-0.0314, -0.0963, -0.0043,  ..., -0.0470, -0.0411, -0.1100])),\n",
       "             ('encoder.layer.8.attention.self.query.weight',\n",
       "              tensor([[ 0.0361,  0.0367,  0.0308,  ...,  0.0186,  0.0145,  0.0127],\n",
       "                      [-0.0941, -0.0731,  0.0662,  ..., -0.0357,  0.0025,  0.0132],\n",
       "                      [-0.0665,  0.1041, -0.0329,  ...,  0.0449,  0.0667, -0.0020],\n",
       "                      ...,\n",
       "                      [ 0.0604,  0.0410, -0.0004,  ..., -0.0049,  0.0847, -0.0043],\n",
       "                      [ 0.0089,  0.0823, -0.0327,  ..., -0.1254,  0.0414,  0.0260],\n",
       "                      [-0.0284, -0.0781,  0.0005,  ...,  0.0033, -0.0180, -0.0443]])),\n",
       "             ('encoder.layer.8.attention.self.query.bias',\n",
       "              tensor([-0.0941,  0.1290,  0.0201,  ..., -0.1393, -0.0542,  0.0567])),\n",
       "             ('encoder.layer.8.attention.self.key.weight',\n",
       "              tensor([[-0.0735,  0.0458,  0.0021,  ..., -0.1582,  0.0519, -0.0136],\n",
       "                      [-0.0551, -0.0018,  0.1166,  ...,  0.0133,  0.0207, -0.0320],\n",
       "                      [ 0.0406, -0.0359, -0.0614,  ..., -0.0282,  0.1107, -0.0296],\n",
       "                      ...,\n",
       "                      [-0.0065,  0.0531, -0.0414,  ...,  0.0585, -0.0011,  0.0284],\n",
       "                      [-0.0804,  0.0314, -0.0479,  ...,  0.0148,  0.0390, -0.0273],\n",
       "                      [-0.0110, -0.0840,  0.0368,  ...,  0.0139,  0.0094, -0.0631]])),\n",
       "             ('encoder.layer.8.attention.self.key.bias',\n",
       "              tensor([-0.0003,  0.0035,  0.0031,  ...,  0.0004,  0.0002,  0.0007])),\n",
       "             ('encoder.layer.8.attention.self.value.weight',\n",
       "              tensor([[ 4.3335e-02, -8.9598e-04, -1.5854e-02,  ..., -4.4830e-02,\n",
       "                        3.0090e-02,  3.4088e-02],\n",
       "                      [-5.0110e-02, -3.3875e-02,  1.3647e-03,  ...,  6.5857e-02,\n",
       "                       -8.3399e-04,  4.9255e-02],\n",
       "                      [ 3.1769e-05, -5.4359e-03,  5.1460e-03,  ...,  2.6245e-03,\n",
       "                       -6.6719e-03, -6.8848e-02],\n",
       "                      ...,\n",
       "                      [ 3.9177e-03,  3.1143e-02,  1.5732e-02,  ..., -2.3788e-02,\n",
       "                       -3.9886e-02, -3.3875e-02],\n",
       "                      [ 5.3619e-02, -5.0323e-02,  1.0042e-03,  ..., -2.3956e-03,\n",
       "                       -1.7090e-02, -1.4877e-02],\n",
       "                      [-2.6505e-02, -1.7395e-02,  2.9469e-03,  ...,  3.9978e-02,\n",
       "                       -1.6434e-02, -4.2999e-02]])),\n",
       "             ('encoder.layer.8.attention.self.value.bias',\n",
       "              tensor([-0.0063, -0.0156,  0.0096,  ..., -0.0151, -0.0058, -0.0037])),\n",
       "             ('encoder.layer.8.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0349,  0.0369,  0.0303,  ...,  0.0185,  0.0151,  0.0129],\n",
       "                      [-0.0925, -0.0733,  0.0660,  ..., -0.0357,  0.0026,  0.0125],\n",
       "                      [-0.0667,  0.1038, -0.0334,  ...,  0.0461,  0.0682, -0.0016],\n",
       "                      ...,\n",
       "                      [ 0.0608,  0.0403, -0.0012,  ..., -0.0059,  0.0852, -0.0041],\n",
       "                      [ 0.0090,  0.0820, -0.0321,  ..., -0.1252,  0.0417,  0.0261],\n",
       "                      [-0.0283, -0.0793,  0.0004,  ...,  0.0032, -0.0191, -0.0436]])),\n",
       "             ('encoder.layer.8.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0931,  0.1290,  0.0206,  ..., -0.1388, -0.0547,  0.0562])),\n",
       "             ('encoder.layer.8.attention.self.e2w_query.weight',\n",
       "              tensor([[ 3.4790e-02,  3.7354e-02,  3.0487e-02,  ...,  1.8051e-02,\n",
       "                        1.4717e-02,  1.2337e-02],\n",
       "                      [-9.3262e-02, -7.2876e-02,  6.6711e-02,  ..., -3.5675e-02,\n",
       "                        2.2869e-03,  1.3359e-02],\n",
       "                      [-6.7200e-02,  1.0388e-01, -3.1891e-02,  ...,  4.6021e-02,\n",
       "                        6.7017e-02, -2.1420e-03],\n",
       "                      ...,\n",
       "                      [ 6.0760e-02,  4.0100e-02, -7.1430e-04,  ..., -4.8409e-03,\n",
       "                        8.5510e-02, -4.3182e-03],\n",
       "                      [ 9.1553e-03,  8.1848e-02, -3.2440e-02,  ..., -1.2549e-01,\n",
       "                        4.2175e-02,  2.6062e-02],\n",
       "                      [-2.8427e-02, -7.9163e-02,  5.0545e-05,  ...,  4.5433e-03,\n",
       "                       -1.9073e-02, -4.3976e-02]])),\n",
       "             ('encoder.layer.8.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0938,  0.1283,  0.0197,  ..., -0.1394, -0.0540,  0.0552])),\n",
       "             ('encoder.layer.8.attention.self.e2e_query.weight',\n",
       "              tensor([[ 3.5217e-02,  3.7323e-02,  3.1204e-02,  ...,  1.7212e-02,\n",
       "                        1.5091e-02,  1.2726e-02],\n",
       "                      [-9.3201e-02, -7.2754e-02,  6.6345e-02,  ..., -3.6377e-02,\n",
       "                        2.1038e-03,  1.2650e-02],\n",
       "                      [-6.6284e-02,  1.0449e-01, -3.2288e-02,  ...,  4.4647e-02,\n",
       "                        6.7871e-02, -2.3384e-03],\n",
       "                      ...,\n",
       "                      [ 6.1554e-02,  4.1412e-02,  8.6606e-05,  ..., -6.2523e-03,\n",
       "                        8.5266e-02, -3.9482e-03],\n",
       "                      [ 9.3842e-03,  8.0994e-02, -3.3417e-02,  ..., -1.2512e-01,\n",
       "                        4.2206e-02,  2.6840e-02],\n",
       "                      [-2.7847e-02, -7.8064e-02,  1.8768e-03,  ...,  3.0098e-03,\n",
       "                       -1.9272e-02, -4.3823e-02]])),\n",
       "             ('encoder.layer.8.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0930,  0.1287,  0.0204,  ..., -0.1381, -0.0539,  0.0567])),\n",
       "             ('encoder.layer.8.attention.output.dense.weight',\n",
       "              tensor([[ 0.0301, -0.0038, -0.0123,  ..., -0.0034,  0.0063, -0.0015],\n",
       "                      [ 0.0007, -0.0154,  0.0310,  ..., -0.0021,  0.0381,  0.0576],\n",
       "                      [ 0.0495, -0.0363,  0.0229,  ...,  0.0416, -0.0346,  0.0092],\n",
       "                      ...,\n",
       "                      [-0.0308,  0.0274, -0.0140,  ...,  0.0361, -0.0330, -0.0280],\n",
       "                      [-0.0482,  0.0053, -0.0289,  ...,  0.0051,  0.0046,  0.0027],\n",
       "                      [ 0.0277, -0.0154,  0.0312,  ...,  0.0210,  0.0024,  0.0466]])),\n",
       "             ('encoder.layer.8.attention.output.dense.bias',\n",
       "              tensor([-0.0499,  0.0063,  0.0057,  ...,  0.0091, -0.0970,  0.0553])),\n",
       "             ('encoder.layer.8.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9834, 0.9985, 1.0029,  ..., 0.9917, 0.9951, 0.9751])),\n",
       "             ('encoder.layer.8.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1709,  0.0128, -0.5000,  ..., -0.0110, -0.1101, -0.0140])),\n",
       "             ('encoder.layer.8.intermediate.dense.weight',\n",
       "              tensor([[-0.0096, -0.0001,  0.0202,  ..., -0.0604,  0.0108, -0.0806],\n",
       "                      [ 0.0285, -0.0735,  0.0402,  ..., -0.1035,  0.0449, -0.0235],\n",
       "                      [ 0.0339,  0.0986,  0.0405,  ...,  0.0236,  0.0101,  0.0095],\n",
       "                      ...,\n",
       "                      [ 0.0440, -0.0218,  0.0360,  ..., -0.0203, -0.0192,  0.0359],\n",
       "                      [ 0.0903,  0.0180,  0.0093,  ...,  0.0139,  0.0549, -0.0726],\n",
       "                      [ 0.0332,  0.0066,  0.0176,  ..., -0.0273, -0.0696, -0.0132]])),\n",
       "             ('encoder.layer.8.intermediate.dense.bias',\n",
       "              tensor([-0.0611, -0.0988, -0.0522,  ..., -0.0769, -0.0559, -0.0340])),\n",
       "             ('encoder.layer.8.output.dense.weight',\n",
       "              tensor([[ 0.0076,  0.0093,  0.0085,  ..., -0.0269,  0.0693,  0.0105],\n",
       "                      [-0.0330,  0.0174,  0.0649,  ...,  0.0183,  0.0104,  0.0277],\n",
       "                      [ 0.0359, -0.0177,  0.0201,  ...,  0.0377, -0.0028, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0735, -0.0575,  0.0309,  ...,  0.0532, -0.0142,  0.0227],\n",
       "                      [-0.0140, -0.0083,  0.0144,  ..., -0.0607, -0.0089, -0.0031],\n",
       "                      [ 0.0225,  0.0212,  0.0240,  ...,  0.0245,  0.0058,  0.0251]])),\n",
       "             ('encoder.layer.8.output.dense.bias',\n",
       "              tensor([-1.6809e-01, -6.2525e-05,  6.0669e-02,  ..., -4.1077e-02,\n",
       "                      -5.0415e-02, -5.7251e-02])),\n",
       "             ('encoder.layer.8.output.LayerNorm.weight',\n",
       "              tensor([0.9722, 0.9976, 1.0029,  ..., 0.9771, 0.9775, 0.9531])),\n",
       "             ('encoder.layer.8.output.LayerNorm.bias',\n",
       "              tensor([ 0.0209, -0.1112, -0.0228,  ..., -0.0834, -0.0246, -0.0840])),\n",
       "             ('encoder.layer.9.attention.self.query.weight',\n",
       "              tensor([[ 0.0047, -0.0861, -0.0393,  ..., -0.0264,  0.0690, -0.0676],\n",
       "                      [ 0.0204, -0.0374, -0.0083,  ..., -0.0327,  0.0463,  0.0606],\n",
       "                      [ 0.0182,  0.0224,  0.0157,  ..., -0.0356,  0.0154, -0.0265],\n",
       "                      ...,\n",
       "                      [ 0.0576, -0.0253, -0.0017,  ..., -0.0114, -0.0648, -0.0132],\n",
       "                      [ 0.0480,  0.0103, -0.0787,  ...,  0.0330,  0.0260,  0.0237],\n",
       "                      [-0.0188, -0.0179, -0.0397,  ..., -0.0514, -0.0354, -0.0428]])),\n",
       "             ('encoder.layer.9.attention.self.query.bias',\n",
       "              tensor([-0.0111, -0.0300, -0.0628,  ...,  0.0026, -0.0579,  0.0747])),\n",
       "             ('encoder.layer.9.attention.self.key.weight',\n",
       "              tensor([[-0.0364,  0.0486,  0.0022,  ..., -0.0111, -0.0300, -0.0414],\n",
       "                      [ 0.0354, -0.0101, -0.0049,  ..., -0.0300, -0.0209, -0.0419],\n",
       "                      [ 0.0357, -0.0505,  0.0702,  ..., -0.0667, -0.0244,  0.0155],\n",
       "                      ...,\n",
       "                      [-0.0154,  0.0128,  0.0031,  ...,  0.0080,  0.0555,  0.0066],\n",
       "                      [ 0.0428,  0.0311, -0.0116,  ...,  0.0165,  0.0322,  0.0061],\n",
       "                      [-0.0377,  0.0069, -0.0308,  ...,  0.0875, -0.0026,  0.0983]])),\n",
       "             ('encoder.layer.9.attention.self.key.bias',\n",
       "              tensor([-0.0005, -0.0013, -0.0023,  ..., -0.0035, -0.0022,  0.0011])),\n",
       "             ('encoder.layer.9.attention.self.value.weight',\n",
       "              tensor([[-2.4017e-02,  1.8806e-03,  1.0345e-02,  ..., -2.1011e-02,\n",
       "                       -5.4016e-02,  2.7237e-02],\n",
       "                      [-2.2629e-02, -3.0624e-02, -8.0299e-04,  ..., -5.2979e-02,\n",
       "                       -6.3438e-03,  5.5695e-02],\n",
       "                      [ 7.9870e-06,  5.6213e-02,  1.1536e-02,  ...,  2.3621e-02,\n",
       "                        2.5482e-02,  1.1681e-02],\n",
       "                      ...,\n",
       "                      [-5.1910e-02,  3.4698e-02,  1.3283e-02,  ...,  5.7434e-02,\n",
       "                        5.5298e-02, -7.7133e-03],\n",
       "                      [ 5.4138e-02,  1.6342e-02, -1.1238e-02,  ..., -3.4210e-02,\n",
       "                       -3.8757e-02, -3.1525e-02],\n",
       "                      [-3.3844e-02,  1.5198e-02,  8.9569e-03,  ...,  2.3193e-02,\n",
       "                        5.0964e-03, -2.0767e-02]])),\n",
       "             ('encoder.layer.9.attention.self.value.bias',\n",
       "              tensor([ 0.0007, -0.0072,  0.0018,  ...,  0.0329, -0.0018,  0.0011])),\n",
       "             ('encoder.layer.9.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0045, -0.0848, -0.0388,  ..., -0.0278,  0.0671, -0.0679],\n",
       "                      [ 0.0199, -0.0372, -0.0087,  ..., -0.0325,  0.0450,  0.0597],\n",
       "                      [ 0.0174,  0.0214,  0.0147,  ..., -0.0370,  0.0122, -0.0272],\n",
       "                      ...,\n",
       "                      [ 0.0580, -0.0251, -0.0015,  ..., -0.0116, -0.0648, -0.0137],\n",
       "                      [ 0.0475,  0.0108, -0.0788,  ...,  0.0320,  0.0252,  0.0227],\n",
       "                      [-0.0195, -0.0175, -0.0387,  ..., -0.0520, -0.0356, -0.0430]])),\n",
       "             ('encoder.layer.9.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0121, -0.0300, -0.0616,  ...,  0.0025, -0.0583,  0.0737])),\n",
       "             ('encoder.layer.9.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0052, -0.0845, -0.0396,  ..., -0.0283,  0.0671, -0.0679],\n",
       "                      [ 0.0202, -0.0378, -0.0086,  ..., -0.0321,  0.0452,  0.0594],\n",
       "                      [ 0.0189,  0.0217,  0.0151,  ..., -0.0365,  0.0130, -0.0270],\n",
       "                      ...,\n",
       "                      [ 0.0579, -0.0245, -0.0014,  ..., -0.0116, -0.0649, -0.0139],\n",
       "                      [ 0.0478,  0.0097, -0.0780,  ...,  0.0320,  0.0245,  0.0234],\n",
       "                      [-0.0189, -0.0184, -0.0388,  ..., -0.0521, -0.0356, -0.0436]])),\n",
       "             ('encoder.layer.9.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0106, -0.0292, -0.0615,  ...,  0.0026, -0.0576,  0.0732])),\n",
       "             ('encoder.layer.9.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0046, -0.0849, -0.0386,  ..., -0.0268,  0.0687, -0.0682],\n",
       "                      [ 0.0202, -0.0375, -0.0084,  ..., -0.0314,  0.0467,  0.0596],\n",
       "                      [ 0.0174,  0.0221,  0.0153,  ..., -0.0359,  0.0133, -0.0269],\n",
       "                      ...,\n",
       "                      [ 0.0572, -0.0249, -0.0010,  ..., -0.0111, -0.0641, -0.0143],\n",
       "                      [ 0.0482,  0.0104, -0.0789,  ...,  0.0316,  0.0247,  0.0224],\n",
       "                      [-0.0185, -0.0171, -0.0389,  ..., -0.0527, -0.0363, -0.0433]])),\n",
       "             ('encoder.layer.9.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0122, -0.0296, -0.0621,  ...,  0.0024, -0.0570,  0.0737])),\n",
       "             ('encoder.layer.9.attention.output.dense.weight',\n",
       "              tensor([[-0.0206, -0.0256,  0.0105,  ...,  0.0207, -0.0112, -0.0178],\n",
       "                      [ 0.0020, -0.0390,  0.0025,  ..., -0.0450,  0.0156,  0.0210],\n",
       "                      [ 0.0354, -0.0695, -0.0001,  ..., -0.0131,  0.0377, -0.0039],\n",
       "                      ...,\n",
       "                      [ 0.0089,  0.0145,  0.0290,  ..., -0.0184,  0.0031,  0.0006],\n",
       "                      [-0.0133, -0.0091, -0.0081,  ..., -0.0784, -0.0182,  0.0555],\n",
       "                      [ 0.0278,  0.0114,  0.0279,  ..., -0.0142, -0.0116,  0.0005]])),\n",
       "             ('encoder.layer.9.attention.output.dense.bias',\n",
       "              tensor([ 0.0467,  0.0035, -0.1740,  ...,  0.0528, -0.0490,  0.0050])),\n",
       "             ('encoder.layer.9.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9824, 0.9932, 1.0029,  ..., 0.9824, 0.9902, 0.9868])),\n",
       "             ('encoder.layer.9.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1801, -0.0290, -0.4668,  ..., -0.0483, -0.1160, -0.0282])),\n",
       "             ('encoder.layer.9.intermediate.dense.weight',\n",
       "              tensor([[ 0.0259,  0.0051, -0.0152,  ...,  0.0247,  0.0222,  0.0019],\n",
       "                      [ 0.0083, -0.0007,  0.0180,  ...,  0.0797,  0.0246,  0.0166],\n",
       "                      [ 0.0482, -0.0523,  0.0129,  ...,  0.0628, -0.0767,  0.0656],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0344,  0.0137,  ...,  0.0684,  0.0027, -0.0212],\n",
       "                      [ 0.0132, -0.0570,  0.0078,  ...,  0.0019, -0.0058, -0.0106],\n",
       "                      [-0.0213, -0.0305,  0.0117,  ...,  0.0126,  0.0490,  0.0235]])),\n",
       "             ('encoder.layer.9.intermediate.dense.bias',\n",
       "              tensor([-0.0534, -0.0788, -0.0242,  ..., -0.0482, -0.0435, -0.1004])),\n",
       "             ('encoder.layer.9.output.dense.weight',\n",
       "              tensor([[-0.0023,  0.0223, -0.0161,  ..., -0.0073,  0.0211,  0.0042],\n",
       "                      [ 0.0326,  0.0782, -0.0155,  ..., -0.0213, -0.0086, -0.0095],\n",
       "                      [ 0.0139,  0.0043,  0.0180,  ...,  0.0142, -0.0035, -0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0117,  0.0909, -0.0475,  ..., -0.0516,  0.0205,  0.0145],\n",
       "                      [ 0.0332,  0.0456, -0.0470,  ...,  0.0441,  0.0305, -0.0034],\n",
       "                      [-0.0382, -0.0254, -0.0489,  ..., -0.0116,  0.0197,  0.0037]])),\n",
       "             ('encoder.layer.9.output.dense.bias',\n",
       "              tensor([-0.1371,  0.0667, -0.0892,  ..., -0.0439, -0.0769, -0.0242])),\n",
       "             ('encoder.layer.9.output.LayerNorm.weight',\n",
       "              tensor([0.9731, 0.9897, 1.0029,  ..., 0.9692, 0.9814, 0.9736])),\n",
       "             ('encoder.layer.9.output.LayerNorm.bias',\n",
       "              tensor([ 0.0326, -0.0622, -0.2124,  ..., -0.0582, -0.0128, -0.0451])),\n",
       "             ('encoder.layer.10.attention.self.query.weight',\n",
       "              tensor([[ 0.0644,  0.0335, -0.0018,  ..., -0.1428,  0.0443,  0.0173],\n",
       "                      [ 0.0671, -0.1069, -0.0096,  ...,  0.0784,  0.0021, -0.0284],\n",
       "                      [-0.0356, -0.0140, -0.0359,  ...,  0.0768,  0.0930, -0.0367],\n",
       "                      ...,\n",
       "                      [ 0.0334,  0.0389,  0.2369,  ...,  0.0899, -0.0646,  0.0598],\n",
       "                      [ 0.0208,  0.0157,  0.0611,  ...,  0.1124,  0.0530, -0.0475],\n",
       "                      [ 0.0268, -0.0213,  0.0464,  ...,  0.0500,  0.0579, -0.0198]])),\n",
       "             ('encoder.layer.10.attention.self.query.bias',\n",
       "              tensor([ 0.0239,  0.0311, -0.0158,  ...,  0.0281,  0.0562,  0.0006])),\n",
       "             ('encoder.layer.10.attention.self.key.weight',\n",
       "              tensor([[-0.0143,  0.0388,  0.0549,  ..., -0.0165, -0.0266, -0.0473],\n",
       "                      [-0.0984, -0.0994,  0.0235,  ..., -0.0699,  0.0006, -0.0057],\n",
       "                      [-0.0342,  0.0716, -0.0076,  ..., -0.1048, -0.0014, -0.0561],\n",
       "                      ...,\n",
       "                      [ 0.0174, -0.0100,  0.2573,  ..., -0.0773, -0.0313,  0.0265],\n",
       "                      [ 0.0088, -0.0074,  0.0808,  ..., -0.0076,  0.0013, -0.0124],\n",
       "                      [-0.0298, -0.0457,  0.0265,  ...,  0.0643, -0.0070, -0.0244]])),\n",
       "             ('encoder.layer.10.attention.self.key.bias',\n",
       "              tensor([-0.0005, -0.0061, -0.0002,  ...,  0.0015,  0.0097,  0.0025])),\n",
       "             ('encoder.layer.10.attention.self.value.weight',\n",
       "              tensor([[ 0.0090,  0.0418,  0.0110,  ..., -0.0018, -0.0263, -0.0288],\n",
       "                      [ 0.0221, -0.0057, -0.0106,  ..., -0.0128, -0.0042, -0.0188],\n",
       "                      [ 0.0357,  0.0496,  0.0039,  ..., -0.0046,  0.0283, -0.0185],\n",
       "                      ...,\n",
       "                      [-0.0145,  0.0077, -0.0007,  ..., -0.0036,  0.0077, -0.0378],\n",
       "                      [ 0.0142,  0.0152, -0.0091,  ...,  0.0172, -0.0399,  0.0161],\n",
       "                      [-0.0256, -0.0177, -0.0148,  ..., -0.0241,  0.0066, -0.0161]])),\n",
       "             ('encoder.layer.10.attention.self.value.bias',\n",
       "              tensor([ 0.0215,  0.0107, -0.0329,  ...,  0.0200, -0.0135,  0.0496])),\n",
       "             ('encoder.layer.10.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0638,  0.0338, -0.0017,  ..., -0.1443,  0.0432,  0.0177],\n",
       "                      [ 0.0681, -0.1075, -0.0097,  ...,  0.0785,  0.0022, -0.0283],\n",
       "                      [-0.0346, -0.0132, -0.0355,  ...,  0.0769,  0.0928, -0.0376],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.0385,  0.2368,  ...,  0.0893, -0.0630,  0.0597],\n",
       "                      [ 0.0210,  0.0160,  0.0619,  ...,  0.1121,  0.0530, -0.0469],\n",
       "                      [ 0.0266, -0.0204,  0.0468,  ...,  0.0490,  0.0565, -0.0208]])),\n",
       "             ('encoder.layer.10.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0237,  0.0307, -0.0164,  ...,  0.0283,  0.0554,  0.0008])),\n",
       "             ('encoder.layer.10.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0642,  0.0331, -0.0017,  ..., -0.1437,  0.0441,  0.0170],\n",
       "                      [ 0.0676, -0.1065, -0.0102,  ...,  0.0773,  0.0013, -0.0279],\n",
       "                      [-0.0352, -0.0128, -0.0363,  ...,  0.0768,  0.0924, -0.0371],\n",
       "                      ...,\n",
       "                      [ 0.0329,  0.0383,  0.2355,  ...,  0.0895, -0.0639,  0.0596],\n",
       "                      [ 0.0210,  0.0167,  0.0614,  ...,  0.1125,  0.0521, -0.0467],\n",
       "                      [ 0.0260, -0.0203,  0.0476,  ...,  0.0497,  0.0566, -0.0208]])),\n",
       "             ('encoder.layer.10.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0233,  0.0316, -0.0161,  ...,  0.0293,  0.0561, -0.0003])),\n",
       "             ('encoder.layer.10.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0647,  0.0336, -0.0015,  ..., -0.1436,  0.0435,  0.0172],\n",
       "                      [ 0.0673, -0.1072, -0.0100,  ...,  0.0780,  0.0012, -0.0278],\n",
       "                      [-0.0352, -0.0132, -0.0357,  ...,  0.0768,  0.0923, -0.0375],\n",
       "                      ...,\n",
       "                      [ 0.0326,  0.0376,  0.2365,  ...,  0.0903, -0.0630,  0.0592],\n",
       "                      [ 0.0203,  0.0158,  0.0618,  ...,  0.1125,  0.0530, -0.0471],\n",
       "                      [ 0.0268, -0.0204,  0.0471,  ...,  0.0483,  0.0559, -0.0202]])),\n",
       "             ('encoder.layer.10.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0235,  0.0310, -0.0162,  ...,  0.0284,  0.0551,  0.0006])),\n",
       "             ('encoder.layer.10.attention.output.dense.weight',\n",
       "              tensor([[ 0.0050,  0.0538, -0.0093,  ...,  0.0128,  0.0360,  0.0190],\n",
       "                      [-0.0212, -0.0050, -0.0149,  ..., -0.0418,  0.0244, -0.0164],\n",
       "                      [ 0.0311,  0.0218, -0.1362,  ..., -0.0697, -0.0639, -0.0096],\n",
       "                      ...,\n",
       "                      [ 0.0049, -0.0076, -0.0358,  ..., -0.0119, -0.0052, -0.0197],\n",
       "                      [ 0.0321, -0.0038,  0.0465,  ..., -0.0152,  0.0022,  0.0145],\n",
       "                      [ 0.0531, -0.0061,  0.0050,  ..., -0.0076, -0.0168, -0.0287]])),\n",
       "             ('encoder.layer.10.attention.output.dense.bias',\n",
       "              tensor([-0.0041,  0.0633,  0.0535,  ...,  0.0352, -0.0610,  0.0742])),\n",
       "             ('encoder.layer.10.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9707, 0.9912, 1.0039,  ..., 0.9863, 0.9888, 0.9849])),\n",
       "             ('encoder.layer.10.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1819, -0.0036, -0.4734,  ..., -0.0690, -0.1519, -0.0396])),\n",
       "             ('encoder.layer.10.intermediate.dense.weight',\n",
       "              tensor([[-0.0186, -0.0082,  0.0063,  ..., -0.0164, -0.0109, -0.0724],\n",
       "                      [ 0.0105,  0.0210,  0.0364,  ...,  0.0605,  0.0287, -0.0074],\n",
       "                      [ 0.0016, -0.0150,  0.0281,  ...,  0.0309,  0.0354,  0.0003],\n",
       "                      ...,\n",
       "                      [ 0.0212,  0.0146,  0.0211,  ...,  0.0746, -0.0360,  0.0043],\n",
       "                      [ 0.0523, -0.0187,  0.0048,  ...,  0.0298,  0.0580, -0.0283],\n",
       "                      [-0.0114, -0.0151, -0.0091,  ...,  0.0195, -0.0005, -0.0273]])),\n",
       "             ('encoder.layer.10.intermediate.dense.bias',\n",
       "              tensor([-0.0578, -0.0499, -0.0149,  ..., -0.0923, -0.0911, -0.0138])),\n",
       "             ('encoder.layer.10.output.dense.weight',\n",
       "              tensor([[-0.0207,  0.0032, -0.0034,  ...,  0.0599,  0.0145, -0.0527],\n",
       "                      [-0.0373,  0.0092,  0.0012,  ...,  0.0115, -0.0237, -0.0471],\n",
       "                      [ 0.0045, -0.0083,  0.0103,  ...,  0.0019, -0.0099, -0.0026],\n",
       "                      ...,\n",
       "                      [ 0.0113, -0.0172, -0.0156,  ...,  0.0204, -0.0020, -0.0076],\n",
       "                      [-0.0198, -0.0941, -0.0469,  ...,  0.0211,  0.0086, -0.0479],\n",
       "                      [-0.0275, -0.0004, -0.0414,  ...,  0.0021,  0.0263,  0.0101]])),\n",
       "             ('encoder.layer.10.output.dense.bias',\n",
       "              tensor([-0.2124,  0.0537,  0.0872,  ..., -0.0431,  0.0078, -0.1136])),\n",
       "             ('encoder.layer.10.output.LayerNorm.weight',\n",
       "              tensor([0.9766, 0.9888, 1.0049,  ..., 0.9775, 0.9741, 0.9829])),\n",
       "             ('encoder.layer.10.output.LayerNorm.bias',\n",
       "              tensor([ 0.0439, -0.0737, -0.2052,  ..., -0.0423,  0.0371, -0.0467])),\n",
       "             ('encoder.layer.11.attention.self.query.weight',\n",
       "              tensor([[ 0.0356, -0.0126,  0.0254,  ...,  0.0174,  0.0880,  0.0403],\n",
       "                      [ 0.0723, -0.0446, -0.0037,  ..., -0.0252,  0.0167,  0.0327],\n",
       "                      [ 0.0517, -0.0481, -0.2144,  ...,  0.0500,  0.0699, -0.0316],\n",
       "                      ...,\n",
       "                      [ 0.0937, -0.0227,  0.0844,  ..., -0.0406,  0.0629, -0.0690],\n",
       "                      [-0.0662, -0.0240, -0.0636,  ..., -0.0201, -0.0359, -0.0837],\n",
       "                      [ 0.0381,  0.0006, -0.0354,  ..., -0.0559, -0.0938, -0.0453]])),\n",
       "             ('encoder.layer.11.attention.self.query.bias',\n",
       "              tensor([0.0094, 0.0302, 0.0473,  ..., 0.1013, 0.0177, 0.0239])),\n",
       "             ('encoder.layer.11.attention.self.key.weight',\n",
       "              tensor([[-0.0916, -0.0083,  0.0753,  ...,  0.0046, -0.0249, -0.0119],\n",
       "                      [-0.0618, -0.0132, -0.0291,  ...,  0.0228, -0.0328,  0.0745],\n",
       "                      [-0.1138,  0.0077, -0.2325,  ..., -0.0596, -0.0071,  0.0070],\n",
       "                      ...,\n",
       "                      [-0.0389, -0.0297,  0.1083,  ..., -0.0745, -0.0312, -0.0233],\n",
       "                      [-0.0141,  0.0063, -0.0655,  ..., -0.1009,  0.0087,  0.0084],\n",
       "                      [ 0.0117, -0.0765, -0.0356,  ..., -0.0415, -0.0187, -0.0171]])),\n",
       "             ('encoder.layer.11.attention.self.key.bias',\n",
       "              tensor([ 7.4625e-05, -4.0674e-04, -6.3019e-03,  ..., -1.1024e-03,\n",
       "                      -6.7425e-04,  4.9324e-03])),\n",
       "             ('encoder.layer.11.attention.self.value.weight',\n",
       "              tensor([[ 0.0106, -0.0299,  0.0033,  ...,  0.0638,  0.0018, -0.0023],\n",
       "                      [ 0.0240, -0.0329, -0.0044,  ..., -0.0777, -0.0322,  0.0486],\n",
       "                      [-0.0456, -0.0125,  0.0268,  ..., -0.0859, -0.0298,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0046,  0.0456, -0.0011,  ..., -0.0005, -0.0474, -0.0057],\n",
       "                      [ 0.0433,  0.0277,  0.0012,  ...,  0.0469,  0.0358, -0.0773],\n",
       "                      [-0.0119, -0.0010,  0.0015,  ..., -0.0457,  0.0319, -0.0246]])),\n",
       "             ('encoder.layer.11.attention.self.value.bias',\n",
       "              tensor([-0.0104,  0.0126,  0.0059,  ..., -0.0277,  0.0114, -0.0346])),\n",
       "             ('encoder.layer.11.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0359, -0.0121,  0.0254,  ...,  0.0178,  0.0880,  0.0397],\n",
       "                      [ 0.0717, -0.0450, -0.0035,  ..., -0.0246,  0.0176,  0.0327],\n",
       "                      [ 0.0521, -0.0477, -0.2135,  ...,  0.0506,  0.0692, -0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0936, -0.0231,  0.0848,  ..., -0.0409,  0.0634, -0.0677],\n",
       "                      [-0.0669, -0.0238, -0.0641,  ..., -0.0196, -0.0348, -0.0831],\n",
       "                      [ 0.0378,  0.0003, -0.0349,  ..., -0.0559, -0.0935, -0.0464]])),\n",
       "             ('encoder.layer.11.attention.self.w2e_query.bias',\n",
       "              tensor([0.0098, 0.0298, 0.0466,  ..., 0.1000, 0.0183, 0.0238])),\n",
       "             ('encoder.layer.11.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0358, -0.0116,  0.0256,  ...,  0.0172,  0.0873,  0.0394],\n",
       "                      [ 0.0724, -0.0452, -0.0031,  ..., -0.0241,  0.0184,  0.0326],\n",
       "                      [ 0.0527, -0.0477, -0.2147,  ...,  0.0501,  0.0696, -0.0308],\n",
       "                      ...,\n",
       "                      [ 0.0942, -0.0238,  0.0838,  ..., -0.0404,  0.0634, -0.0683],\n",
       "                      [-0.0665, -0.0238, -0.0635,  ..., -0.0198, -0.0349, -0.0836],\n",
       "                      [ 0.0370,  0.0003, -0.0353,  ..., -0.0559, -0.0942, -0.0464]])),\n",
       "             ('encoder.layer.11.attention.self.e2w_query.bias',\n",
       "              tensor([0.0101, 0.0292, 0.0473,  ..., 0.1016, 0.0172, 0.0239])),\n",
       "             ('encoder.layer.11.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0356, -0.0126,  0.0254,  ...,  0.0177,  0.0877,  0.0398],\n",
       "                      [ 0.0726, -0.0440, -0.0030,  ..., -0.0251,  0.0172,  0.0331],\n",
       "                      [ 0.0518, -0.0483, -0.2144,  ...,  0.0499,  0.0697, -0.0311],\n",
       "                      ...,\n",
       "                      [ 0.0936, -0.0242,  0.0839,  ..., -0.0399,  0.0635, -0.0689],\n",
       "                      [-0.0664, -0.0243, -0.0637,  ..., -0.0202, -0.0356, -0.0830],\n",
       "                      [ 0.0378,  0.0004, -0.0357,  ..., -0.0564, -0.0938, -0.0462]])),\n",
       "             ('encoder.layer.11.attention.self.e2e_query.bias',\n",
       "              tensor([0.0096, 0.0302, 0.0469,  ..., 0.1010, 0.0174, 0.0241])),\n",
       "             ('encoder.layer.11.attention.output.dense.weight',\n",
       "              tensor([[-0.0051, -0.0264,  0.0219,  ...,  0.0088,  0.0077, -0.0275],\n",
       "                      [ 0.0444,  0.0070,  0.0266,  ...,  0.0099, -0.0033,  0.0344],\n",
       "                      [-0.0247,  0.0090, -0.0312,  ...,  0.0065,  0.0184, -0.0219],\n",
       "                      ...,\n",
       "                      [-0.0105, -0.0004,  0.0625,  ...,  0.0244,  0.0271, -0.0177],\n",
       "                      [ 0.0043,  0.0189,  0.0361,  ...,  0.0089,  0.0311, -0.0044],\n",
       "                      [ 0.0236, -0.0564, -0.0013,  ..., -0.0180, -0.0252, -0.0247]])),\n",
       "             ('encoder.layer.11.attention.output.dense.bias',\n",
       "              tensor([-0.0502,  0.1439, -0.1538,  ...,  0.0583, -0.0470,  0.0363])),\n",
       "             ('encoder.layer.11.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9780, 0.9946, 1.0039,  ..., 0.9917, 0.9917, 0.9766])),\n",
       "             ('encoder.layer.11.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.2131,  0.0078, -0.3499,  ..., -0.0626, -0.0710, -0.0352])),\n",
       "             ('encoder.layer.11.intermediate.dense.weight',\n",
       "              tensor([[ 0.0027, -0.0360, -0.0068,  ...,  0.0521,  0.0257,  0.0382],\n",
       "                      [ 0.1037,  0.0596,  0.0043,  ...,  0.0592,  0.0305, -0.0858],\n",
       "                      [ 0.0021,  0.0421, -0.0072,  ...,  0.0370,  0.0071, -0.0342],\n",
       "                      ...,\n",
       "                      [ 0.0575,  0.0113,  0.0083,  ..., -0.0046,  0.0500, -0.1034],\n",
       "                      [ 0.0515,  0.0054,  0.0134,  ...,  0.0610, -0.0278,  0.0374],\n",
       "                      [ 0.0683,  0.0210,  0.0369,  ...,  0.0178,  0.0008,  0.0075]])),\n",
       "             ('encoder.layer.11.intermediate.dense.bias',\n",
       "              tensor([ 0.0251, -0.0461, -0.0562,  ..., -0.0541, -0.0627,  0.0369])),\n",
       "             ('encoder.layer.11.output.dense.weight',\n",
       "              tensor([[ 0.0096,  0.0332, -0.0019,  ...,  0.0087,  0.0273, -0.0528],\n",
       "                      [ 0.0209,  0.0415,  0.0043,  ..., -0.0194,  0.0442,  0.0100],\n",
       "                      [-0.0147,  0.0217, -0.0069,  ..., -0.0033, -0.0069, -0.0011],\n",
       "                      ...,\n",
       "                      [ 0.0475, -0.0575,  0.0631,  ..., -0.0210, -0.0167, -0.0103],\n",
       "                      [ 0.0137,  0.0289, -0.0425,  ...,  0.0094, -0.0359,  0.0132],\n",
       "                      [ 0.0227, -0.0406, -0.0009,  ..., -0.0292, -0.0610, -0.0126]])),\n",
       "             ('encoder.layer.11.output.dense.bias',\n",
       "              tensor([-0.1759, -0.0102, -0.0060,  ..., -0.0144, -0.0833, -0.1052])),\n",
       "             ('encoder.layer.11.output.LayerNorm.weight',\n",
       "              tensor([0.9844, 0.9932, 1.0049,  ..., 0.9756, 0.9800, 0.9897])),\n",
       "             ('encoder.layer.11.output.LayerNorm.bias',\n",
       "              tensor([ 0.0851, -0.0881,  0.1752,  ..., -0.0378, -0.0191, -0.0720])),\n",
       "             ('encoder.layer.12.attention.self.query.weight',\n",
       "              tensor([[-0.0488, -0.0256,  0.0858,  ..., -0.0010,  0.0500,  0.0536],\n",
       "                      [-0.0159,  0.0054,  0.0135,  ..., -0.0769, -0.0668,  0.0492],\n",
       "                      [-0.0540,  0.0361, -0.1340,  ...,  0.0570,  0.0264,  0.0520],\n",
       "                      ...,\n",
       "                      [ 0.0245,  0.0216,  0.2898,  ..., -0.0100,  0.0930, -0.0194],\n",
       "                      [-0.0828,  0.0131, -0.1093,  ..., -0.0341,  0.0127, -0.0220],\n",
       "                      [-0.0060, -0.0068, -0.0304,  ..., -0.0873, -0.0026, -0.0832]])),\n",
       "             ('encoder.layer.12.attention.self.query.bias',\n",
       "              tensor([ 0.0054, -0.0075,  0.0036,  ..., -0.2410, -0.0197, -0.0044])),\n",
       "             ('encoder.layer.12.attention.self.key.weight',\n",
       "              tensor([[-2.8244e-02, -1.2457e-01,  7.5012e-02,  ...,  3.4943e-02,\n",
       "                       -1.9699e-02,  6.4453e-02],\n",
       "                      [ 1.1896e-01,  2.5253e-02, -7.4158e-02,  ..., -7.4482e-04,\n",
       "                       -2.5940e-02, -1.8616e-02],\n",
       "                      [-4.1351e-02,  3.2043e-02, -1.0724e-01,  ..., -7.5134e-02,\n",
       "                       -4.4678e-02, -1.8969e-03],\n",
       "                      ...,\n",
       "                      [-6.1989e-03,  1.4053e-02, -3.7012e-01,  ...,  5.9113e-02,\n",
       "                       -5.2299e-03, -8.4534e-03],\n",
       "                      [ 2.6352e-02, -9.7942e-04, -1.9275e-01,  ..., -2.7145e-02,\n",
       "                        5.5962e-03,  5.4016e-02],\n",
       "                      [ 1.5402e-04, -4.5929e-02, -9.6680e-02,  ...,  4.7791e-02,\n",
       "                        8.3847e-03,  9.2545e-03]])),\n",
       "             ('encoder.layer.12.attention.self.key.bias',\n",
       "              tensor([ 0.0002, -0.0009,  0.0004,  ..., -0.0111,  0.0027, -0.0042])),\n",
       "             ('encoder.layer.12.attention.self.value.weight',\n",
       "              tensor([[-0.0885, -0.0014,  0.0082,  ...,  0.0435, -0.0056, -0.0083],\n",
       "                      [ 0.0298,  0.1000, -0.0121,  ..., -0.0118,  0.0301,  0.0829],\n",
       "                      [ 0.0188,  0.0054,  0.0002,  ..., -0.0400, -0.0425,  0.0327],\n",
       "                      ...,\n",
       "                      [-0.0253, -0.0458, -0.0151,  ..., -0.0051, -0.0123,  0.0576],\n",
       "                      [-0.0400, -0.0420,  0.0236,  ..., -0.0110, -0.0389,  0.0612],\n",
       "                      [ 0.0019, -0.0249, -0.0008,  ..., -0.0346,  0.0318,  0.0284]])),\n",
       "             ('encoder.layer.12.attention.self.value.bias',\n",
       "              tensor([ 0.0054, -0.0072,  0.0003,  ...,  0.0293,  0.0158,  0.0316])),\n",
       "             ('encoder.layer.12.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0478, -0.0254,  0.0855,  ..., -0.0012,  0.0502,  0.0533],\n",
       "                      [-0.0180,  0.0039,  0.0115,  ..., -0.0787, -0.0656,  0.0495],\n",
       "                      [-0.0523,  0.0366, -0.1329,  ...,  0.0573,  0.0259,  0.0522],\n",
       "                      ...,\n",
       "                      [ 0.0242,  0.0214,  0.2903,  ..., -0.0090,  0.0942, -0.0187],\n",
       "                      [-0.0834,  0.0134, -0.1102,  ..., -0.0337,  0.0124, -0.0226],\n",
       "                      [-0.0067, -0.0064, -0.0318,  ..., -0.0869, -0.0018, -0.0840]])),\n",
       "             ('encoder.layer.12.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0056, -0.0051,  0.0025,  ..., -0.2412, -0.0190, -0.0032])),\n",
       "             ('encoder.layer.12.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0475, -0.0250,  0.0862,  ..., -0.0003,  0.0501,  0.0543],\n",
       "                      [-0.0178,  0.0040,  0.0118,  ..., -0.0781, -0.0657,  0.0494],\n",
       "                      [-0.0534,  0.0364, -0.1332,  ...,  0.0569,  0.0260,  0.0521],\n",
       "                      ...,\n",
       "                      [ 0.0247,  0.0208,  0.2898,  ..., -0.0093,  0.0936, -0.0187],\n",
       "                      [-0.0831,  0.0134, -0.1100,  ..., -0.0339,  0.0130, -0.0224],\n",
       "                      [-0.0057, -0.0067, -0.0310,  ..., -0.0865, -0.0017, -0.0830]])),\n",
       "             ('encoder.layer.12.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0048, -0.0055,  0.0026,  ..., -0.2407, -0.0190, -0.0041])),\n",
       "             ('encoder.layer.12.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0465, -0.0239,  0.0851,  ..., -0.0013,  0.0496,  0.0545],\n",
       "                      [-0.0178,  0.0037,  0.0127,  ..., -0.0770, -0.0658,  0.0490],\n",
       "                      [-0.0526,  0.0370, -0.1343,  ...,  0.0560,  0.0267,  0.0525],\n",
       "                      ...,\n",
       "                      [ 0.0249,  0.0210,  0.2903,  ..., -0.0099,  0.0939, -0.0187],\n",
       "                      [-0.0829,  0.0136, -0.1091,  ..., -0.0335,  0.0126, -0.0226],\n",
       "                      [-0.0058, -0.0059, -0.0309,  ..., -0.0875, -0.0020, -0.0832]])),\n",
       "             ('encoder.layer.12.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0061, -0.0066,  0.0036,  ..., -0.2408, -0.0195, -0.0038])),\n",
       "             ('encoder.layer.12.attention.output.dense.weight',\n",
       "              tensor([[-0.0414, -0.0168, -0.0210,  ...,  0.0183, -0.0035, -0.0064],\n",
       "                      [-0.0469,  0.0126, -0.0432,  ..., -0.0307,  0.0024,  0.0154],\n",
       "                      [-0.0412, -0.0203,  0.0276,  ...,  0.0149,  0.0392,  0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0165, -0.0113, -0.0403,  ..., -0.0097,  0.0156,  0.0301],\n",
       "                      [-0.0012, -0.0291,  0.0198,  ..., -0.0248,  0.0183, -0.0164],\n",
       "                      [ 0.0039,  0.0388,  0.0415,  ..., -0.0073, -0.0340, -0.0304]])),\n",
       "             ('encoder.layer.12.attention.output.dense.bias',\n",
       "              tensor([ 0.0298, -0.0024,  0.0632,  ..., -0.0140, -0.0419, -0.0074])),\n",
       "             ('encoder.layer.12.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9917, 0.9814, 1.0029,  ..., 0.9839, 0.9805, 0.9849])),\n",
       "             ('encoder.layer.12.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1652,  0.0027, -0.3047,  ..., -0.0290, -0.1437, -0.0361])),\n",
       "             ('encoder.layer.12.intermediate.dense.weight',\n",
       "              tensor([[ 0.0739, -0.0299,  0.0165,  ..., -0.0100, -0.0059,  0.0089],\n",
       "                      [-0.0154, -0.0288,  0.0178,  ..., -0.0423, -0.0396, -0.0234],\n",
       "                      [-0.0438, -0.0429,  0.0853,  ...,  0.0035, -0.0200, -0.0239],\n",
       "                      ...,\n",
       "                      [ 0.0181, -0.0465,  0.0263,  ..., -0.1221, -0.0165, -0.0053],\n",
       "                      [ 0.0189, -0.0502,  0.0145,  ..., -0.0496, -0.0219,  0.0486],\n",
       "                      [ 0.0233,  0.0119, -0.0056,  ...,  0.0166, -0.0277, -0.0094]])),\n",
       "             ('encoder.layer.12.intermediate.dense.bias',\n",
       "              tensor([-0.1082, -0.0402, -0.0091,  ..., -0.1224, -0.0850, -0.1054])),\n",
       "             ('encoder.layer.12.output.dense.weight',\n",
       "              tensor([[ 0.0305, -0.0023, -0.0702,  ...,  0.0267,  0.0273, -0.0189],\n",
       "                      [-0.0123,  0.0209,  0.0146,  ..., -0.0280,  0.0058, -0.0346],\n",
       "                      [ 0.0021,  0.0007, -0.0149,  ..., -0.0040, -0.0253,  0.0004],\n",
       "                      ...,\n",
       "                      [-0.0104, -0.0108,  0.0165,  ..., -0.0426, -0.0157, -0.0237],\n",
       "                      [-0.0203, -0.0099, -0.0200,  ..., -0.0121, -0.0292,  0.0208],\n",
       "                      [-0.0514, -0.0340,  0.0322,  ...,  0.0074, -0.0035, -0.0122]])),\n",
       "             ('encoder.layer.12.output.dense.bias',\n",
       "              tensor([-0.2185,  0.1660, -0.0793,  ..., -0.0086, -0.0798, -0.1241])),\n",
       "             ('encoder.layer.12.output.LayerNorm.weight',\n",
       "              tensor([0.9863, 0.9927, 1.0010,  ..., 0.9873, 0.9834, 0.9907])),\n",
       "             ('encoder.layer.12.output.LayerNorm.bias',\n",
       "              tensor([ 0.0081, -0.0793,  0.0837,  ..., -0.0700, -0.0122, -0.0617])),\n",
       "             ('encoder.layer.13.attention.self.query.weight',\n",
       "              tensor([[ 0.0467,  0.0499, -0.0475,  ..., -0.0418,  0.0445, -0.0552],\n",
       "                      [-0.0258, -0.0089,  0.0503,  ...,  0.0328,  0.0287,  0.0623],\n",
       "                      [-0.0029, -0.0252,  0.0006,  ..., -0.0360, -0.0779, -0.0103],\n",
       "                      ...,\n",
       "                      [ 0.0665, -0.0066,  0.0292,  ...,  0.0056, -0.0182, -0.0072],\n",
       "                      [-0.0050, -0.0266, -0.1427,  ...,  0.0441,  0.0207, -0.0274],\n",
       "                      [ 0.0504,  0.0510, -0.1576,  ...,  0.0230,  0.0385,  0.0675]])),\n",
       "             ('encoder.layer.13.attention.self.query.bias',\n",
       "              tensor([-0.0495,  0.0435,  0.0070,  ...,  0.0418,  0.1788,  0.0484])),\n",
       "             ('encoder.layer.13.attention.self.key.weight',\n",
       "              tensor([[ 0.0242,  0.0640, -0.0420,  ..., -0.0147,  0.0274, -0.0693],\n",
       "                      [ 0.0562, -0.0043,  0.0737,  ..., -0.0331, -0.0074, -0.0347],\n",
       "                      [ 0.0183,  0.0652, -0.0408,  ...,  0.1559,  0.0287, -0.0793],\n",
       "                      ...,\n",
       "                      [-0.0481, -0.0498, -0.0121,  ..., -0.0222,  0.0134, -0.0264],\n",
       "                      [ 0.0221,  0.0304, -0.2097,  ..., -0.0201, -0.0186,  0.0012],\n",
       "                      [-0.0395,  0.0450, -0.1318,  ...,  0.0207,  0.0107,  0.0306]])),\n",
       "             ('encoder.layer.13.attention.self.key.bias',\n",
       "              tensor([ 0.0067, -0.0009,  0.0048,  ...,  0.0031,  0.0032,  0.0026])),\n",
       "             ('encoder.layer.13.attention.self.value.weight',\n",
       "              tensor([[ 0.0549,  0.0644, -0.0161,  ...,  0.0346,  0.0051,  0.0380],\n",
       "                      [ 0.0181,  0.0548,  0.0066,  ..., -0.0371, -0.0209,  0.0256],\n",
       "                      [-0.0051,  0.0461, -0.0021,  ..., -0.0210, -0.0573,  0.0381],\n",
       "                      ...,\n",
       "                      [ 0.0427, -0.0724,  0.0181,  ...,  0.0004, -0.0155, -0.0235],\n",
       "                      [-0.0018, -0.0005, -0.0391,  ...,  0.0100, -0.1066, -0.0103],\n",
       "                      [-0.0410, -0.0927,  0.0247,  ...,  0.0010, -0.0072, -0.0175]])),\n",
       "             ('encoder.layer.13.attention.self.value.bias',\n",
       "              tensor([ 0.0113,  0.0083,  0.0070,  ..., -0.0064, -0.0073, -0.0009])),\n",
       "             ('encoder.layer.13.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0460,  0.0500, -0.0478,  ..., -0.0423,  0.0454, -0.0554],\n",
       "                      [-0.0252, -0.0087,  0.0506,  ...,  0.0336,  0.0300,  0.0627],\n",
       "                      [-0.0026, -0.0251,  0.0008,  ..., -0.0368, -0.0778, -0.0104],\n",
       "                      ...,\n",
       "                      [ 0.0670, -0.0080,  0.0292,  ...,  0.0054, -0.0174, -0.0077],\n",
       "                      [-0.0058, -0.0260, -0.1434,  ...,  0.0430,  0.0199, -0.0277],\n",
       "                      [ 0.0502,  0.0508, -0.1583,  ...,  0.0242,  0.0382,  0.0669]])),\n",
       "             ('encoder.layer.13.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0492,  0.0434,  0.0062,  ...,  0.0423,  0.1794,  0.0481])),\n",
       "             ('encoder.layer.13.attention.self.e2w_query.weight',\n",
       "              tensor([[ 4.5685e-02,  4.8981e-02, -4.7729e-02,  ..., -4.1077e-02,\n",
       "                        4.5044e-02, -5.5939e-02],\n",
       "                      [-2.5772e-02, -8.7662e-03,  4.9744e-02,  ...,  3.2806e-02,\n",
       "                        2.9465e-02,  6.2927e-02],\n",
       "                      [-3.0117e-03, -2.5070e-02, -1.3733e-04,  ..., -3.6774e-02,\n",
       "                       -7.7759e-02, -1.0719e-02],\n",
       "                      ...,\n",
       "                      [ 6.7078e-02, -6.6223e-03,  2.8183e-02,  ...,  4.0321e-03,\n",
       "                       -1.7349e-02, -6.1226e-03],\n",
       "                      [-5.7716e-03, -2.5436e-02, -1.4307e-01,  ...,  4.3976e-02,\n",
       "                        1.9882e-02, -2.7832e-02],\n",
       "                      [ 4.9652e-02,  4.9957e-02, -1.5698e-01,  ...,  2.4918e-02,\n",
       "                        3.8544e-02,  6.6162e-02]])),\n",
       "             ('encoder.layer.13.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0494,  0.0443,  0.0076,  ...,  0.0436,  0.1790,  0.0469])),\n",
       "             ('encoder.layer.13.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0460,  0.0492, -0.0488,  ..., -0.0426,  0.0457, -0.0557],\n",
       "                      [-0.0256, -0.0091,  0.0501,  ...,  0.0329,  0.0296,  0.0629],\n",
       "                      [-0.0033, -0.0258, -0.0003,  ..., -0.0367, -0.0768, -0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0668, -0.0073,  0.0286,  ...,  0.0046, -0.0173, -0.0069],\n",
       "                      [-0.0053, -0.0256, -0.1431,  ...,  0.0431,  0.0197, -0.0277],\n",
       "                      [ 0.0495,  0.0505, -0.1582,  ...,  0.0240,  0.0382,  0.0664]])),\n",
       "             ('encoder.layer.13.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0486,  0.0440,  0.0073,  ...,  0.0427,  0.1793,  0.0479])),\n",
       "             ('encoder.layer.13.attention.output.dense.weight',\n",
       "              tensor([[ 0.0012, -0.0389,  0.0300,  ..., -0.0499,  0.0024,  0.1019],\n",
       "                      [ 0.0078,  0.0095, -0.0061,  ...,  0.0063, -0.0690,  0.0446],\n",
       "                      [-0.0035, -0.0109, -0.0179,  ...,  0.0160, -0.0183, -0.0027],\n",
       "                      ...,\n",
       "                      [-0.0393, -0.0031, -0.0454,  ...,  0.0007, -0.0422,  0.0185],\n",
       "                      [-0.0412,  0.0609, -0.0032,  ...,  0.0147,  0.0768, -0.0290],\n",
       "                      [ 0.0017,  0.0061,  0.0103,  ...,  0.0196,  0.0349,  0.0488]])),\n",
       "             ('encoder.layer.13.attention.output.dense.bias',\n",
       "              tensor([-0.0429,  0.0439, -0.0901,  ...,  0.0370, -0.0334,  0.0341])),\n",
       "             ('encoder.layer.13.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9775, 0.9893, 1.0020,  ..., 0.9888, 0.9824, 0.9766])),\n",
       "             ('encoder.layer.13.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1793,  0.0703, -0.2717,  ..., -0.0598, -0.1188, -0.0613])),\n",
       "             ('encoder.layer.13.intermediate.dense.weight',\n",
       "              tensor([[ 0.0217, -0.0255,  0.0184,  ..., -0.0300, -0.0561, -0.0472],\n",
       "                      [ 0.0326,  0.0015,  0.0090,  ...,  0.0497,  0.0244,  0.0014],\n",
       "                      [ 0.0583, -0.0423,  0.0534,  ...,  0.1165, -0.0111, -0.0607],\n",
       "                      ...,\n",
       "                      [ 0.0292, -0.0145, -0.0065,  ..., -0.0116,  0.0372,  0.0076],\n",
       "                      [ 0.0141,  0.0399,  0.0949,  ...,  0.0481,  0.0398, -0.0367],\n",
       "                      [ 0.0364, -0.1292,  0.0403,  ...,  0.0048, -0.0009, -0.0759]])),\n",
       "             ('encoder.layer.13.intermediate.dense.bias',\n",
       "              tensor([-0.1367, -0.0517, -0.0891,  ..., -0.1030, -0.0341, -0.0382])),\n",
       "             ('encoder.layer.13.output.dense.weight',\n",
       "              tensor([[ 6.0638e-02, -3.4729e-02, -4.3060e-02,  ..., -3.4851e-02,\n",
       "                        1.4038e-02, -8.1482e-03],\n",
       "                      [-1.1391e-02,  5.9814e-03, -5.6061e-02,  ...,  8.0719e-03,\n",
       "                        2.1622e-02, -2.4231e-02],\n",
       "                      [ 1.2413e-02,  3.7689e-03,  1.7185e-03,  ..., -2.6054e-03,\n",
       "                        6.1264e-03, -6.1569e-03],\n",
       "                      ...,\n",
       "                      [-2.8534e-02,  3.8483e-02,  4.7531e-03,  ..., -3.3844e-02,\n",
       "                        1.5282e-02,  3.3081e-02],\n",
       "                      [-8.7402e-02, -2.7878e-02,  3.1113e-02,  ..., -1.9165e-02,\n",
       "                        5.8624e-02,  1.4473e-02],\n",
       "                      [-2.8519e-02, -3.8481e-04, -2.4811e-02,  ..., -2.4536e-02,\n",
       "                       -1.4365e-05, -4.0710e-02]])),\n",
       "             ('encoder.layer.13.output.dense.bias',\n",
       "              tensor([-0.1071,  0.0568, -0.0720,  ..., -0.0243, -0.0503, -0.0881])),\n",
       "             ('encoder.layer.13.output.LayerNorm.weight',\n",
       "              tensor([0.9849, 0.9912, 1.0010,  ..., 0.9883, 0.9873, 0.9922])),\n",
       "             ('encoder.layer.13.output.LayerNorm.bias',\n",
       "              tensor([ 0.0677, -0.1175,  0.2385,  ..., -0.0541, -0.0039, -0.0446])),\n",
       "             ('encoder.layer.14.attention.self.query.weight',\n",
       "              tensor([[-0.0440, -0.0606,  0.0087,  ..., -0.1205, -0.0219, -0.1600],\n",
       "                      [-0.0602,  0.0294, -0.0967,  ...,  0.0375, -0.0198, -0.0383],\n",
       "                      [-0.0041, -0.0288,  0.1078,  ..., -0.0109, -0.0606,  0.0385],\n",
       "                      ...,\n",
       "                      [ 0.0633,  0.0006,  0.0213,  ..., -0.0382, -0.0679,  0.0398],\n",
       "                      [-0.0173,  0.0390, -0.0182,  ..., -0.0922, -0.0248,  0.0566],\n",
       "                      [-0.0659,  0.0229,  0.0090,  ...,  0.0541,  0.0317,  0.0381]])),\n",
       "             ('encoder.layer.14.attention.self.query.bias',\n",
       "              tensor([ 0.1919,  0.1414, -0.1239,  ...,  0.2340, -0.1186,  0.0177])),\n",
       "             ('encoder.layer.14.attention.self.key.weight',\n",
       "              tensor([[ 0.0352,  0.0811,  0.0710,  ...,  0.0091,  0.0045, -0.0096],\n",
       "                      [-0.0663, -0.0061, -0.1246,  ..., -0.0135,  0.0071,  0.0470],\n",
       "                      [-0.0232,  0.0269,  0.0476,  ...,  0.0193, -0.1163,  0.0616],\n",
       "                      ...,\n",
       "                      [ 0.0784, -0.0635,  0.0656,  ..., -0.0961, -0.0451, -0.0300],\n",
       "                      [ 0.0467,  0.0869,  0.0437,  ..., -0.0759,  0.0657,  0.0388],\n",
       "                      [-0.0688, -0.0052,  0.0558,  ..., -0.0034, -0.0491, -0.0246]])),\n",
       "             ('encoder.layer.14.attention.self.key.bias',\n",
       "              tensor([-0.0012,  0.0015, -0.0064,  ...,  0.0006, -0.0010,  0.0037])),\n",
       "             ('encoder.layer.14.attention.self.value.weight',\n",
       "              tensor([[-4.3427e-02,  5.7340e-05,  4.2542e-02,  ..., -4.4189e-02,\n",
       "                       -5.5237e-03, -7.8583e-03],\n",
       "                      [-2.8248e-03, -6.8665e-02, -8.7128e-03,  ...,  6.2622e-02,\n",
       "                        6.3416e-02, -5.0537e-02],\n",
       "                      [ 2.4673e-02, -3.5919e-02, -2.5497e-02,  ..., -6.7383e-02,\n",
       "                        1.3374e-02,  2.2842e-02],\n",
       "                      ...,\n",
       "                      [ 8.0872e-02,  2.5452e-02, -1.7334e-02,  ...,  1.9119e-02,\n",
       "                       -2.5955e-02, -3.3264e-02],\n",
       "                      [ 7.1045e-02,  1.5244e-02, -1.3084e-02,  ..., -5.0774e-03,\n",
       "                       -2.0508e-02,  2.7557e-02],\n",
       "                      [-7.5623e-02, -4.0192e-02, -2.3071e-02,  ..., -2.8782e-03,\n",
       "                        4.7791e-02, -1.3074e-01]])),\n",
       "             ('encoder.layer.14.attention.self.value.bias',\n",
       "              tensor([-3.5119e-04,  6.4240e-03, -1.1986e-02,  ..., -9.7513e-05,\n",
       "                       5.2490e-03,  1.3374e-02])),\n",
       "             ('encoder.layer.14.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0436, -0.0602,  0.0091,  ..., -0.1191, -0.0216, -0.1595],\n",
       "                      [-0.0607,  0.0292, -0.0957,  ...,  0.0371, -0.0190, -0.0381],\n",
       "                      [-0.0033, -0.0289,  0.1082,  ..., -0.0097, -0.0602,  0.0385],\n",
       "                      ...,\n",
       "                      [ 0.0625,  0.0003,  0.0221,  ..., -0.0385, -0.0680,  0.0405],\n",
       "                      [-0.0182,  0.0391, -0.0182,  ..., -0.0934, -0.0236,  0.0570],\n",
       "                      [-0.0662,  0.0227,  0.0080,  ...,  0.0538,  0.0329,  0.0378]])),\n",
       "             ('encoder.layer.14.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.1924,  0.1399, -0.1243,  ...,  0.2332, -0.1191,  0.0183])),\n",
       "             ('encoder.layer.14.attention.self.e2w_query.weight',\n",
       "              tensor([[-4.4159e-02, -6.0425e-02,  8.8730e-03,  ..., -1.1963e-01,\n",
       "                       -2.2507e-02, -1.5979e-01],\n",
       "                      [-6.0547e-02,  3.0106e-02, -9.6985e-02,  ...,  3.6621e-02,\n",
       "                       -1.9363e-02, -3.7842e-02],\n",
       "                      [-3.3741e-03, -2.8809e-02,  1.0767e-01,  ..., -1.0811e-02,\n",
       "                       -5.9998e-02,  3.8269e-02],\n",
       "                      ...,\n",
       "                      [ 6.2927e-02,  5.3346e-05,  2.1423e-02,  ..., -3.7872e-02,\n",
       "                       -6.6284e-02,  3.9673e-02],\n",
       "                      [-1.8723e-02,  3.8635e-02, -1.7502e-02,  ..., -9.2834e-02,\n",
       "                       -2.3926e-02,  5.6305e-02],\n",
       "                      [-6.7017e-02,  2.2842e-02,  7.7782e-03,  ...,  5.2460e-02,\n",
       "                        3.1525e-02,  3.8422e-02]])),\n",
       "             ('encoder.layer.14.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.1925,  0.1407, -0.1238,  ...,  0.2334, -0.1198,  0.0184])),\n",
       "             ('encoder.layer.14.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0433, -0.0596,  0.0081,  ..., -0.1199, -0.0218, -0.1594],\n",
       "                      [-0.0608,  0.0301, -0.0968,  ...,  0.0370, -0.0194, -0.0379],\n",
       "                      [-0.0034, -0.0291,  0.1073,  ..., -0.0106, -0.0601,  0.0381],\n",
       "                      ...,\n",
       "                      [ 0.0622, -0.0006,  0.0224,  ..., -0.0382, -0.0673,  0.0399],\n",
       "                      [-0.0180,  0.0392, -0.0190,  ..., -0.0939, -0.0236,  0.0574],\n",
       "                      [-0.0664,  0.0233,  0.0077,  ...,  0.0534,  0.0324,  0.0381]])),\n",
       "             ('encoder.layer.14.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.1932,  0.1409, -0.1236,  ...,  0.2324, -0.1180,  0.0186])),\n",
       "             ('encoder.layer.14.attention.output.dense.weight',\n",
       "              tensor([[-0.0056, -0.0224,  0.0443,  ..., -0.0428, -0.0007,  0.0840],\n",
       "                      [ 0.0128, -0.0439,  0.0451,  ..., -0.0732, -0.0457, -0.0054],\n",
       "                      [ 0.0380, -0.0344,  0.0119,  ...,  0.0033,  0.0141, -0.0202],\n",
       "                      ...,\n",
       "                      [ 0.0673, -0.0351,  0.0683,  ...,  0.0097, -0.0060, -0.0115],\n",
       "                      [-0.0025, -0.0653, -0.0190,  ...,  0.0271,  0.0058, -0.0071],\n",
       "                      [-0.0092, -0.0266,  0.0236,  ...,  0.0658,  0.0231,  0.0720]])),\n",
       "             ('encoder.layer.14.attention.output.dense.bias',\n",
       "              tensor([-0.0231,  0.0020,  0.0322,  ...,  0.0639, -0.0414, -0.0055])),\n",
       "             ('encoder.layer.14.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9956, 0.9819, 1.0039,  ..., 0.9893, 0.9888, 0.9868])),\n",
       "             ('encoder.layer.14.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0869, -0.0149, -0.1970,  ..., -0.0645, -0.1379, -0.0533])),\n",
       "             ('encoder.layer.14.intermediate.dense.weight',\n",
       "              tensor([[-0.0075, -0.0020,  0.0398,  ...,  0.0012, -0.0152,  0.0420],\n",
       "                      [ 0.0173, -0.0505, -0.0079,  ...,  0.0595, -0.0289,  0.0460],\n",
       "                      [ 0.0445, -0.0673,  0.0124,  ...,  0.0683,  0.0684, -0.0569],\n",
       "                      ...,\n",
       "                      [ 0.0705, -0.0381,  0.0104,  ...,  0.0089, -0.0035, -0.0321],\n",
       "                      [-0.0336, -0.0549, -0.0132,  ...,  0.0289,  0.0120,  0.0190],\n",
       "                      [ 0.0384, -0.0446, -0.0678,  ...,  0.0356, -0.0184,  0.0068]])),\n",
       "             ('encoder.layer.14.intermediate.dense.bias',\n",
       "              tensor([-0.1079, -0.1095, -0.1117,  ..., -0.0576, -0.0796, -0.0810])),\n",
       "             ('encoder.layer.14.output.dense.weight',\n",
       "              tensor([[-0.0217,  0.0294,  0.0087,  ...,  0.0284,  0.0089, -0.0641],\n",
       "                      [ 0.0035, -0.0115, -0.0866,  ..., -0.0077,  0.0157, -0.0653],\n",
       "                      [-0.0097, -0.0200,  0.0356,  ...,  0.0083,  0.0033,  0.0125],\n",
       "                      ...,\n",
       "                      [ 0.0573,  0.0070,  0.0095,  ..., -0.0446,  0.0353, -0.0303],\n",
       "                      [-0.0526,  0.0128,  0.0271,  ...,  0.0456,  0.0032, -0.0313],\n",
       "                      [ 0.0245,  0.0083, -0.0593,  ..., -0.0062, -0.0166, -0.0692]])),\n",
       "             ('encoder.layer.14.output.dense.bias',\n",
       "              tensor([-0.1091,  0.0495, -0.1954,  ..., -0.0115, -0.1292, -0.0688])),\n",
       "             ('encoder.layer.14.output.LayerNorm.weight',\n",
       "              tensor([0.9902, 0.9932, 1.0039,  ..., 0.9883, 0.9897, 0.9902])),\n",
       "             ('encoder.layer.14.output.LayerNorm.bias',\n",
       "              tensor([-0.0245, -0.1100,  0.2477,  ..., -0.0520, -0.0152, -0.0587])),\n",
       "             ('encoder.layer.15.attention.self.query.weight',\n",
       "              tensor([[ 0.0620,  0.0573, -0.1342,  ..., -0.0201,  0.0434,  0.0235],\n",
       "                      [-0.0207,  0.0164,  0.0818,  ...,  0.0889, -0.0285, -0.0184],\n",
       "                      [ 0.0010, -0.0185, -0.0278,  ..., -0.0594,  0.0469, -0.0782],\n",
       "                      ...,\n",
       "                      [ 0.0491,  0.1175, -0.0270,  ...,  0.0266, -0.0189,  0.0104],\n",
       "                      [-0.0193,  0.0881,  0.0353,  ..., -0.0011, -0.0586,  0.0416],\n",
       "                      [-0.0609, -0.0311,  0.0099,  ..., -0.0083,  0.0947, -0.0548]])),\n",
       "             ('encoder.layer.15.attention.self.query.bias',\n",
       "              tensor([-0.0130, -0.0726, -0.0253,  ..., -0.1169, -0.0905, -0.0038])),\n",
       "             ('encoder.layer.15.attention.self.key.weight',\n",
       "              tensor([[-0.0437,  0.0203, -0.2190,  ..., -0.0843, -0.0095, -0.0124],\n",
       "                      [ 0.0635, -0.0227, -0.0543,  ..., -0.0116,  0.0023, -0.0230],\n",
       "                      [-0.0341,  0.0834, -0.0762,  ..., -0.0372, -0.0598, -0.0167],\n",
       "                      ...,\n",
       "                      [ 0.0126,  0.0198, -0.0547,  ..., -0.1058,  0.0357, -0.0164],\n",
       "                      [-0.0944, -0.0173, -0.0423,  ..., -0.0055,  0.0136,  0.0278],\n",
       "                      [ 0.0543, -0.0385,  0.0255,  ..., -0.0328,  0.0463,  0.0562]])),\n",
       "             ('encoder.layer.15.attention.self.key.bias',\n",
       "              tensor([ 0.0009,  0.0151,  0.0054,  ..., -0.0016,  0.0033, -0.0033])),\n",
       "             ('encoder.layer.15.attention.self.value.weight',\n",
       "              tensor([[-0.0707,  0.0461,  0.0057,  ...,  0.0010, -0.0219,  0.0614],\n",
       "                      [-0.0140, -0.0301, -0.0324,  ..., -0.0392,  0.0406, -0.0698],\n",
       "                      [-0.0017, -0.0084,  0.0031,  ..., -0.1066,  0.1023,  0.0998],\n",
       "                      ...,\n",
       "                      [ 0.0151, -0.0585, -0.0005,  ...,  0.0378, -0.0101,  0.0754],\n",
       "                      [-0.0451, -0.0868,  0.0035,  ...,  0.0587,  0.0168,  0.0128],\n",
       "                      [-0.0610,  0.0026, -0.0128,  ..., -0.0711, -0.1055,  0.0049]])),\n",
       "             ('encoder.layer.15.attention.self.value.bias',\n",
       "              tensor([-0.0044,  0.0050,  0.0006,  ...,  0.0032, -0.0044, -0.0212])),\n",
       "             ('encoder.layer.15.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0615,  0.0556, -0.1339,  ..., -0.0208,  0.0425,  0.0237],\n",
       "                      [-0.0204,  0.0145,  0.0825,  ...,  0.0886, -0.0285, -0.0173],\n",
       "                      [ 0.0021, -0.0168, -0.0272,  ..., -0.0598,  0.0464, -0.0778],\n",
       "                      ...,\n",
       "                      [ 0.0488,  0.1176, -0.0269,  ...,  0.0259, -0.0200,  0.0100],\n",
       "                      [-0.0197,  0.0878,  0.0350,  ..., -0.0002, -0.0583,  0.0408],\n",
       "                      [-0.0617, -0.0318,  0.0094,  ..., -0.0086,  0.0946, -0.0556]])),\n",
       "             ('encoder.layer.15.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0126, -0.0731, -0.0265,  ..., -0.1166, -0.0897, -0.0031])),\n",
       "             ('encoder.layer.15.attention.self.e2w_query.weight',\n",
       "              tensor([[ 6.0822e-02,  5.6122e-02, -1.3403e-01,  ..., -2.1027e-02,\n",
       "                        4.2389e-02,  2.4231e-02],\n",
       "                      [-1.9714e-02,  1.5190e-02,  8.2947e-02,  ...,  8.8318e-02,\n",
       "                       -2.8641e-02, -1.8250e-02],\n",
       "                      [ 1.7185e-03, -1.7609e-02, -2.7405e-02,  ..., -5.8502e-02,\n",
       "                        4.6997e-02, -7.7515e-02],\n",
       "                      ...,\n",
       "                      [ 4.8645e-02,  1.1792e-01, -2.6932e-02,  ...,  2.6596e-02,\n",
       "                       -1.9196e-02,  9.8343e-03],\n",
       "                      [-1.9653e-02,  8.7585e-02,  3.4943e-02,  ...,  1.7643e-05,\n",
       "                       -5.8594e-02,  4.1351e-02],\n",
       "                      [-6.1676e-02, -3.2440e-02,  9.7961e-03,  ..., -8.0185e-03,\n",
       "                        9.4543e-02, -5.5237e-02]])),\n",
       "             ('encoder.layer.15.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0129, -0.0737, -0.0257,  ..., -0.1170, -0.0900, -0.0036])),\n",
       "             ('encoder.layer.15.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0620,  0.0565, -0.1329,  ..., -0.0208,  0.0421,  0.0244],\n",
       "                      [-0.0208,  0.0150,  0.0827,  ...,  0.0881, -0.0293, -0.0181],\n",
       "                      [ 0.0007, -0.0170, -0.0285,  ..., -0.0589,  0.0469, -0.0781],\n",
       "                      ...,\n",
       "                      [ 0.0493,  0.1179, -0.0271,  ...,  0.0265, -0.0199,  0.0104],\n",
       "                      [-0.0202,  0.0878,  0.0353,  ..., -0.0003, -0.0587,  0.0407],\n",
       "                      [-0.0625, -0.0317,  0.0096,  ..., -0.0085,  0.0941, -0.0557]])),\n",
       "             ('encoder.layer.15.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0135, -0.0731, -0.0248,  ..., -0.1169, -0.0898, -0.0032])),\n",
       "             ('encoder.layer.15.attention.output.dense.weight',\n",
       "              tensor([[ 0.0132,  0.0012, -0.0203,  ..., -0.0332, -0.0267,  0.0226],\n",
       "                      [ 0.0044,  0.0268, -0.0366,  ..., -0.0063,  0.0477, -0.0233],\n",
       "                      [-0.0302, -0.0359,  0.0726,  ..., -0.0166, -0.0181, -0.0119],\n",
       "                      ...,\n",
       "                      [-0.0005,  0.0582,  0.0144,  ..., -0.0342, -0.0097,  0.0253],\n",
       "                      [-0.0593,  0.0953,  0.0491,  ..., -0.0077,  0.0185,  0.0876],\n",
       "                      [ 0.0207, -0.0543,  0.0082,  ..., -0.0124, -0.0357, -0.0190]])),\n",
       "             ('encoder.layer.15.attention.output.dense.bias',\n",
       "              tensor([-0.0166,  0.0164,  0.0541,  ...,  0.0015, -0.0478, -0.0286])),\n",
       "             ('encoder.layer.15.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9883, 0.9897, 1.0039,  ..., 0.9878, 0.9893, 0.9829])),\n",
       "             ('encoder.layer.15.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1111, -0.0181, -0.1715,  ..., -0.0934, -0.0807, -0.1244])),\n",
       "             ('encoder.layer.15.intermediate.dense.weight',\n",
       "              tensor([[-0.0215, -0.0170,  0.0211,  ...,  0.0115,  0.0492, -0.0308],\n",
       "                      [ 0.0518, -0.0554,  0.0037,  ..., -0.0227, -0.0463, -0.0097],\n",
       "                      [-0.0313,  0.0470,  0.0212,  ...,  0.0958,  0.0073,  0.0263],\n",
       "                      ...,\n",
       "                      [-0.0418, -0.0390,  0.0205,  ...,  0.0809,  0.0416,  0.0274],\n",
       "                      [-0.0383,  0.0682,  0.0560,  ..., -0.0085,  0.0233, -0.0089],\n",
       "                      [ 0.0706,  0.0068,  0.0057,  ...,  0.0411,  0.0718,  0.0269]])),\n",
       "             ('encoder.layer.15.intermediate.dense.bias',\n",
       "              tensor([-0.0442, -0.1071, -0.0778,  ..., -0.0341,  0.0108, -0.0829])),\n",
       "             ('encoder.layer.15.output.dense.weight',\n",
       "              tensor([[-0.0259,  0.0648, -0.0484,  ..., -0.0003,  0.0195, -0.0052],\n",
       "                      [-0.0217,  0.0138, -0.0334,  ..., -0.0560, -0.0031, -0.0030],\n",
       "                      [-0.0159, -0.0107, -0.0237,  ...,  0.0003,  0.0148,  0.0125],\n",
       "                      ...,\n",
       "                      [ 0.0068,  0.0219,  0.0510,  ..., -0.0092,  0.0051,  0.0019],\n",
       "                      [-0.0022, -0.0071,  0.0690,  ..., -0.0408, -0.0167,  0.0035],\n",
       "                      [-0.0446,  0.0178,  0.0220,  ...,  0.0345, -0.0116,  0.0390]])),\n",
       "             ('encoder.layer.15.output.dense.bias',\n",
       "              tensor([-0.1306,  0.0305, -0.2480,  ..., -0.0320, -0.0864, -0.1000])),\n",
       "             ('encoder.layer.15.output.LayerNorm.weight',\n",
       "              tensor([0.9878, 0.9854, 1.0039,  ..., 0.9849, 0.9951, 0.9873])),\n",
       "             ('encoder.layer.15.output.LayerNorm.bias',\n",
       "              tensor([-0.0082, -0.0685,  0.1721,  ..., -0.0154, -0.0311, -0.0166])),\n",
       "             ('encoder.layer.16.attention.self.query.weight',\n",
       "              tensor([[-0.0196,  0.0019, -0.0433,  ..., -0.0118,  0.0911,  0.0331],\n",
       "                      [-0.0457, -0.0659, -0.0247,  ...,  0.0132, -0.0212, -0.0356],\n",
       "                      [ 0.0011, -0.0064,  0.0827,  ..., -0.0672, -0.0600, -0.0093],\n",
       "                      ...,\n",
       "                      [ 0.0691, -0.0829, -0.0294,  ..., -0.0164,  0.0376,  0.0193],\n",
       "                      [-0.0475,  0.0381,  0.0540,  ..., -0.0856,  0.0352, -0.1118],\n",
       "                      [ 0.0099,  0.0125,  0.0357,  ..., -0.0338, -0.0843, -0.0390]])),\n",
       "             ('encoder.layer.16.attention.self.query.bias',\n",
       "              tensor([-0.0085, -0.0684,  0.0119,  ..., -0.0044,  0.0848,  0.0124])),\n",
       "             ('encoder.layer.16.attention.self.key.weight',\n",
       "              tensor([[-0.0525, -0.0161, -0.0313,  ...,  0.0792, -0.0124, -0.0522],\n",
       "                      [ 0.0487, -0.0139, -0.0323,  ...,  0.0777, -0.0447, -0.0287],\n",
       "                      [-0.0167,  0.0693,  0.0786,  ..., -0.0332, -0.0619,  0.0303],\n",
       "                      ...,\n",
       "                      [ 0.0493,  0.0341,  0.0049,  ..., -0.0754, -0.0120, -0.0034],\n",
       "                      [ 0.0020,  0.0837,  0.0179,  ..., -0.0268,  0.0577,  0.0075],\n",
       "                      [ 0.0501, -0.0217,  0.0757,  ..., -0.0883, -0.0316,  0.0468]])),\n",
       "             ('encoder.layer.16.attention.self.key.bias',\n",
       "              tensor([-1.5469e-03, -4.5252e-04,  8.2169e-03,  ..., -1.6356e-03,\n",
       "                      -6.8843e-05,  4.3526e-03])),\n",
       "             ('encoder.layer.16.attention.self.value.weight',\n",
       "              tensor([[ 0.0414, -0.0031,  0.0109,  ...,  0.0368, -0.0610,  0.0514],\n",
       "                      [ 0.0277,  0.0594, -0.0338,  ...,  0.0028,  0.0233,  0.0863],\n",
       "                      [ 0.0110,  0.0028, -0.0090,  ..., -0.0414, -0.0536,  0.0280],\n",
       "                      ...,\n",
       "                      [-0.0561, -0.1257,  0.0250,  ..., -0.0909, -0.0078,  0.0553],\n",
       "                      [-0.0044, -0.0323, -0.0327,  ..., -0.0278,  0.0043,  0.1261],\n",
       "                      [ 0.0391,  0.1238, -0.0008,  ..., -0.0181,  0.0112, -0.0254]])),\n",
       "             ('encoder.layer.16.attention.self.value.bias',\n",
       "              tensor([-0.0092,  0.0052,  0.0026,  ..., -0.0101, -0.0145, -0.0095])),\n",
       "             ('encoder.layer.16.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0202,  0.0024, -0.0433,  ..., -0.0114,  0.0900,  0.0332],\n",
       "                      [-0.0460, -0.0664, -0.0250,  ...,  0.0129, -0.0215, -0.0355],\n",
       "                      [ 0.0012, -0.0068,  0.0821,  ..., -0.0679, -0.0597, -0.0087],\n",
       "                      ...,\n",
       "                      [ 0.0688, -0.0836, -0.0291,  ..., -0.0163,  0.0365,  0.0195],\n",
       "                      [-0.0475,  0.0384,  0.0534,  ..., -0.0855,  0.0357, -0.1119],\n",
       "                      [ 0.0105,  0.0113,  0.0354,  ..., -0.0341, -0.0838, -0.0395]])),\n",
       "             ('encoder.layer.16.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0076, -0.0679,  0.0124,  ..., -0.0043,  0.0844,  0.0132])),\n",
       "             ('encoder.layer.16.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0207,  0.0022, -0.0438,  ..., -0.0119,  0.0906,  0.0344],\n",
       "                      [-0.0465, -0.0660, -0.0257,  ...,  0.0124, -0.0215, -0.0350],\n",
       "                      [ 0.0014, -0.0063,  0.0830,  ..., -0.0674, -0.0603, -0.0098],\n",
       "                      ...,\n",
       "                      [ 0.0689, -0.0839, -0.0284,  ..., -0.0160,  0.0371,  0.0189],\n",
       "                      [-0.0475,  0.0386,  0.0535,  ..., -0.0859,  0.0358, -0.1115],\n",
       "                      [ 0.0114,  0.0121,  0.0361,  ..., -0.0331, -0.0845, -0.0399]])),\n",
       "             ('encoder.layer.16.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0072, -0.0677,  0.0116,  ..., -0.0053,  0.0847,  0.0119])),\n",
       "             ('encoder.layer.16.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0203,  0.0027, -0.0444,  ..., -0.0119,  0.0905,  0.0335],\n",
       "                      [-0.0459, -0.0657, -0.0257,  ...,  0.0126, -0.0211, -0.0359],\n",
       "                      [ 0.0014, -0.0068,  0.0830,  ..., -0.0676, -0.0600, -0.0089],\n",
       "                      ...,\n",
       "                      [ 0.0688, -0.0831, -0.0289,  ..., -0.0164,  0.0368,  0.0191],\n",
       "                      [-0.0475,  0.0383,  0.0538,  ..., -0.0851,  0.0353, -0.1120],\n",
       "                      [ 0.0104,  0.0119,  0.0357,  ..., -0.0336, -0.0836, -0.0393]])),\n",
       "             ('encoder.layer.16.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0066, -0.0674,  0.0116,  ..., -0.0048,  0.0844,  0.0126])),\n",
       "             ('encoder.layer.16.attention.output.dense.weight',\n",
       "              tensor([[ 0.0403, -0.0420, -0.0107,  ...,  0.0044, -0.0164,  0.0075],\n",
       "                      [ 0.0006,  0.0209,  0.0110,  ...,  0.0295, -0.0629, -0.0204],\n",
       "                      [ 0.0556, -0.0715,  0.0200,  ..., -0.0106, -0.0302,  0.0325],\n",
       "                      ...,\n",
       "                      [ 0.0179,  0.0094, -0.0593,  ...,  0.0848,  0.0364,  0.0056],\n",
       "                      [-0.0514, -0.0359, -0.0234,  ...,  0.0208, -0.0741,  0.0303],\n",
       "                      [ 0.0041, -0.0126, -0.0050,  ..., -0.0682, -0.0622, -0.0392]])),\n",
       "             ('encoder.layer.16.attention.output.dense.bias',\n",
       "              tensor([-0.0025, -0.0225,  0.0823,  ..., -0.0599,  0.0308, -0.0674])),\n",
       "             ('encoder.layer.16.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9980, 0.9941, 1.0078,  ..., 0.9912, 0.9951, 0.9976])),\n",
       "             ('encoder.layer.16.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0794, -0.0439, -0.2108,  ..., -0.0630, -0.0681, -0.0668])),\n",
       "             ('encoder.layer.16.intermediate.dense.weight',\n",
       "              tensor([[ 0.0764, -0.0260,  0.0473,  ...,  0.0425,  0.0108, -0.0328],\n",
       "                      [ 0.0170,  0.0441,  0.0222,  ...,  0.0631, -0.0727,  0.0036],\n",
       "                      [ 0.0163,  0.0162, -0.0125,  ...,  0.1248, -0.0081, -0.0133],\n",
       "                      ...,\n",
       "                      [-0.0786, -0.0622,  0.0157,  ...,  0.0253,  0.0300, -0.0213],\n",
       "                      [-0.0357, -0.0204,  0.0433,  ...,  0.0102, -0.0472, -0.0468],\n",
       "                      [-0.0128, -0.0894,  0.0395,  ...,  0.0269, -0.0498,  0.0314]])),\n",
       "             ('encoder.layer.16.intermediate.dense.bias',\n",
       "              tensor([-0.0790, -0.0588, -0.1002,  ..., -0.0635, -0.0787, -0.0875])),\n",
       "             ('encoder.layer.16.output.dense.weight',\n",
       "              tensor([[ 0.0109,  0.0328,  0.0648,  ..., -0.0171, -0.0012,  0.0048],\n",
       "                      [-0.0130, -0.0046,  0.0122,  ..., -0.0371, -0.0667, -0.0250],\n",
       "                      [ 0.0068, -0.0015, -0.0163,  ...,  0.0015,  0.0015,  0.0062],\n",
       "                      ...,\n",
       "                      [-0.0144,  0.0413,  0.0055,  ...,  0.0039, -0.0348, -0.0575],\n",
       "                      [-0.0558, -0.0398,  0.0435,  ..., -0.0102, -0.0304,  0.0128],\n",
       "                      [-0.0037,  0.0193, -0.0089,  ..., -0.0358,  0.0088,  0.0350]])),\n",
       "             ('encoder.layer.16.output.dense.bias',\n",
       "              tensor([-0.0817,  0.0129, -0.2003,  ..., -0.0397, -0.0638, -0.1039])),\n",
       "             ('encoder.layer.16.output.LayerNorm.weight',\n",
       "              tensor([0.9780, 0.9961, 1.0059,  ..., 0.9741, 0.9912, 0.9878])),\n",
       "             ('encoder.layer.16.output.LayerNorm.bias',\n",
       "              tensor([-0.0200, -0.0485,  0.1780,  ..., -0.0254, -0.0309, -0.0301])),\n",
       "             ('encoder.layer.17.attention.self.query.weight',\n",
       "              tensor([[-0.0025, -0.0144,  0.0612,  ...,  0.0392, -0.0261,  0.0591],\n",
       "                      [ 0.0263,  0.0111, -0.0267,  ...,  0.0825, -0.0316,  0.0501],\n",
       "                      [ 0.1404,  0.0714,  0.0313,  ..., -0.0880, -0.0371, -0.0043],\n",
       "                      ...,\n",
       "                      [-0.0271, -0.0431,  0.0747,  ..., -0.1210,  0.0543, -0.0731],\n",
       "                      [ 0.0447, -0.0082,  0.0473,  ..., -0.0052, -0.0441,  0.0298],\n",
       "                      [ 0.0129,  0.0948, -0.0287,  ...,  0.0013,  0.0137, -0.0209]])),\n",
       "             ('encoder.layer.17.attention.self.query.bias',\n",
       "              tensor([-0.1755,  0.0590,  0.0238,  ..., -0.0483,  0.0392,  0.0130])),\n",
       "             ('encoder.layer.17.attention.self.key.weight',\n",
       "              tensor([[ 0.0301, -0.0104,  0.0533,  ..., -0.0618,  0.0421,  0.0252],\n",
       "                      [ 0.0470,  0.0137,  0.0359,  ...,  0.0915, -0.0418,  0.0223],\n",
       "                      [ 0.0160,  0.0344, -0.0348,  ..., -0.0642,  0.0806, -0.0016],\n",
       "                      ...,\n",
       "                      [ 0.0152,  0.0612,  0.0259,  ...,  0.0212,  0.0424, -0.0739],\n",
       "                      [ 0.0330,  0.0546,  0.0499,  ...,  0.0514,  0.0179,  0.0204],\n",
       "                      [-0.0836,  0.0066, -0.0238,  ...,  0.0525,  0.0056,  0.0623]])),\n",
       "             ('encoder.layer.17.attention.self.key.bias',\n",
       "              tensor([ 0.0075, -0.0181,  0.0159,  ..., -0.0047,  0.0122, -0.0042])),\n",
       "             ('encoder.layer.17.attention.self.value.weight',\n",
       "              tensor([[-0.0153,  0.0032, -0.0081,  ...,  0.0113,  0.0057,  0.0009],\n",
       "                      [-0.0189,  0.0219, -0.0104,  ...,  0.0272,  0.0158,  0.0283],\n",
       "                      [ 0.0119,  0.0108, -0.0102,  ...,  0.0194, -0.0050, -0.0737],\n",
       "                      ...,\n",
       "                      [-0.0241,  0.0324,  0.0048,  ..., -0.0291, -0.0849, -0.1095],\n",
       "                      [ 0.0182, -0.0961, -0.0291,  ...,  0.0067, -0.0311,  0.0963],\n",
       "                      [ 0.0613, -0.0652,  0.0103,  ..., -0.1134,  0.0496, -0.0442]])),\n",
       "             ('encoder.layer.17.attention.self.value.bias',\n",
       "              tensor([ 0.0080, -0.0018, -0.0005,  ...,  0.0019,  0.0087,  0.0055])),\n",
       "             ('encoder.layer.17.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0024, -0.0143,  0.0623,  ...,  0.0395, -0.0253,  0.0595],\n",
       "                      [ 0.0258,  0.0107, -0.0263,  ...,  0.0829, -0.0305,  0.0504],\n",
       "                      [ 0.1403,  0.0710,  0.0320,  ..., -0.0884, -0.0381, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0274, -0.0437,  0.0747,  ..., -0.1210,  0.0554, -0.0722],\n",
       "                      [ 0.0448, -0.0087,  0.0464,  ..., -0.0058, -0.0444,  0.0294],\n",
       "                      [ 0.0126,  0.0944, -0.0292,  ...,  0.0004,  0.0127, -0.0226]])),\n",
       "             ('encoder.layer.17.attention.self.w2e_query.bias',\n",
       "              tensor([-0.1764,  0.0582,  0.0237,  ..., -0.0485,  0.0391,  0.0143])),\n",
       "             ('encoder.layer.17.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0021, -0.0154,  0.0628,  ...,  0.0399, -0.0247,  0.0589],\n",
       "                      [ 0.0263,  0.0115, -0.0262,  ...,  0.0828, -0.0306,  0.0501],\n",
       "                      [ 0.1409,  0.0712,  0.0323,  ..., -0.0884, -0.0374, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0273, -0.0440,  0.0747,  ..., -0.1212,  0.0544, -0.0728],\n",
       "                      [ 0.0450, -0.0083,  0.0471,  ..., -0.0054, -0.0440,  0.0292],\n",
       "                      [ 0.0134,  0.0948, -0.0282,  ...,  0.0008,  0.0133, -0.0222]])),\n",
       "             ('encoder.layer.17.attention.self.e2w_query.bias',\n",
       "              tensor([-0.1770,  0.0579,  0.0234,  ..., -0.0483,  0.0386,  0.0137])),\n",
       "             ('encoder.layer.17.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0026, -0.0146,  0.0626,  ...,  0.0393, -0.0253,  0.0590],\n",
       "                      [ 0.0264,  0.0104, -0.0264,  ...,  0.0828, -0.0313,  0.0506],\n",
       "                      [ 0.1410,  0.0710,  0.0321,  ..., -0.0886, -0.0378, -0.0038],\n",
       "                      ...,\n",
       "                      [-0.0276, -0.0439,  0.0743,  ..., -0.1221,  0.0547, -0.0728],\n",
       "                      [ 0.0453, -0.0077,  0.0472,  ..., -0.0052, -0.0438,  0.0295],\n",
       "                      [ 0.0132,  0.0951, -0.0287,  ...,  0.0012,  0.0133, -0.0219]])),\n",
       "             ('encoder.layer.17.attention.self.e2e_query.bias',\n",
       "              tensor([-0.1763,  0.0583,  0.0239,  ..., -0.0474,  0.0381,  0.0135])),\n",
       "             ('encoder.layer.17.attention.output.dense.weight',\n",
       "              tensor([[-0.0009, -0.0266, -0.0172,  ..., -0.0211, -0.0330,  0.0538],\n",
       "                      [ 0.0276,  0.0079,  0.0107,  ...,  0.0716, -0.0469,  0.0632],\n",
       "                      [ 0.0026,  0.0094, -0.0050,  ...,  0.0144, -0.0335, -0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0324,  0.0123, -0.0420,  ...,  0.0280,  0.0308,  0.0225],\n",
       "                      [-0.0289,  0.0283, -0.0078,  ..., -0.0434,  0.0610, -0.0330],\n",
       "                      [ 0.0229, -0.0194, -0.0584,  ..., -0.0039, -0.0276,  0.0182]])),\n",
       "             ('encoder.layer.17.attention.output.dense.bias',\n",
       "              tensor([-0.0240,  0.0378,  0.0308,  ..., -0.0087, -0.0490, -0.0173])),\n",
       "             ('encoder.layer.17.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9868, 0.9985, 1.0039,  ..., 0.9844, 0.9844, 0.9849])),\n",
       "             ('encoder.layer.17.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0967, -0.0631, -0.2181,  ..., -0.0829, -0.0676, -0.0845])),\n",
       "             ('encoder.layer.17.intermediate.dense.weight',\n",
       "              tensor([[ 0.0078, -0.0436,  0.0242,  ..., -0.0528, -0.0386, -0.0195],\n",
       "                      [ 0.0850, -0.0295,  0.0198,  ...,  0.0225, -0.0598, -0.0074],\n",
       "                      [-0.0068,  0.0132,  0.0107,  ...,  0.0237,  0.0309,  0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0731, -0.0610, -0.0360,  ..., -0.0074,  0.0329,  0.0040],\n",
       "                      [-0.0060,  0.0971,  0.0130,  ..., -0.0481, -0.0654,  0.0122],\n",
       "                      [-0.0505, -0.0226, -0.0033,  ..., -0.0255,  0.0027,  0.0257]])),\n",
       "             ('encoder.layer.17.intermediate.dense.bias',\n",
       "              tensor([-0.0443, -0.0903, -0.0247,  ...,  0.0204, -0.1123, -0.0455])),\n",
       "             ('encoder.layer.17.output.dense.weight',\n",
       "              tensor([[ 0.0262,  0.0680, -0.0140,  ...,  0.0036, -0.0249, -0.0595],\n",
       "                      [ 0.0068, -0.0053,  0.0210,  ...,  0.0045,  0.0037, -0.0068],\n",
       "                      [-0.0193, -0.0238, -0.0004,  ...,  0.0133,  0.0316, -0.0163],\n",
       "                      ...,\n",
       "                      [ 0.0141,  0.0981, -0.0147,  ...,  0.0158, -0.0340,  0.0019],\n",
       "                      [ 0.0084,  0.0090, -0.0237,  ...,  0.0167,  0.0405,  0.0001],\n",
       "                      [-0.0217, -0.0357, -0.0156,  ...,  0.0092, -0.0204,  0.0151]])),\n",
       "             ('encoder.layer.17.output.dense.bias',\n",
       "              tensor([-0.0692,  0.0158, -0.1523,  ..., -0.0157, -0.0880, -0.0509])),\n",
       "             ('encoder.layer.17.output.LayerNorm.weight',\n",
       "              tensor([0.9849, 0.9917, 1.0029,  ..., 0.9810, 0.9858, 0.9849])),\n",
       "             ('encoder.layer.17.output.LayerNorm.bias',\n",
       "              tensor([-0.0041, -0.0272,  0.1224,  ..., -0.0133, -0.0379, -0.0070])),\n",
       "             ('encoder.layer.18.attention.self.query.weight',\n",
       "              tensor([[ 0.0310, -0.0033,  0.1387,  ...,  0.0225,  0.0681, -0.0144],\n",
       "                      [ 0.0337,  0.0215,  0.0124,  ..., -0.1433, -0.0501, -0.0421],\n",
       "                      [-0.0525,  0.0578,  0.1871,  ...,  0.0400, -0.0252, -0.0235],\n",
       "                      ...,\n",
       "                      [-0.0516, -0.0028, -0.0283,  ...,  0.0216, -0.0192, -0.0321],\n",
       "                      [-0.0627,  0.0326, -0.0139,  ...,  0.0160,  0.0525,  0.1091],\n",
       "                      [-0.0167,  0.0413,  0.1418,  ..., -0.0323,  0.0136, -0.0525]])),\n",
       "             ('encoder.layer.18.attention.self.query.bias',\n",
       "              tensor([-0.2759, -0.0118, -0.1447,  ...,  0.0094, -0.0058,  0.0213])),\n",
       "             ('encoder.layer.18.attention.self.key.weight',\n",
       "              tensor([[-0.0598, -0.0174,  0.0510,  ...,  0.0112, -0.0073,  0.0454],\n",
       "                      [-0.0240,  0.0817,  0.1118,  ..., -0.0175, -0.0041, -0.0597],\n",
       "                      [ 0.0692,  0.0491,  0.2571,  ..., -0.0257,  0.0065,  0.0103],\n",
       "                      ...,\n",
       "                      [-0.0539, -0.0307, -0.0146,  ..., -0.0363,  0.0638,  0.0253],\n",
       "                      [ 0.0620, -0.0158, -0.0206,  ..., -0.0181, -0.0436, -0.0036],\n",
       "                      [-0.0193, -0.0167,  0.1440,  ...,  0.0345, -0.0144,  0.0785]])),\n",
       "             ('encoder.layer.18.attention.self.key.bias',\n",
       "              tensor([ 0.0002,  0.0003,  0.0022,  ..., -0.0043,  0.0019,  0.0061])),\n",
       "             ('encoder.layer.18.attention.self.value.weight',\n",
       "              tensor([[ 0.0257,  0.0199, -0.0020,  ...,  0.0125,  0.0016,  0.0071],\n",
       "                      [-0.0346,  0.0596,  0.0168,  ...,  0.0101,  0.0037,  0.0246],\n",
       "                      [ 0.0109, -0.0405, -0.0327,  ...,  0.1033, -0.0280,  0.0014],\n",
       "                      ...,\n",
       "                      [ 0.0123, -0.0056,  0.0166,  ...,  0.0234, -0.0264, -0.0351],\n",
       "                      [ 0.0363, -0.0037, -0.0435,  ...,  0.0092,  0.0319,  0.0016],\n",
       "                      [ 0.0259,  0.0686, -0.0159,  ..., -0.0423,  0.0176,  0.0026]])),\n",
       "             ('encoder.layer.18.attention.self.value.bias',\n",
       "              tensor([-0.0075,  0.0049, -0.0170,  ..., -0.0064,  0.0030, -0.0120])),\n",
       "             ('encoder.layer.18.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0308, -0.0016,  0.1382,  ...,  0.0225,  0.0675, -0.0144],\n",
       "                      [ 0.0326,  0.0206,  0.0118,  ..., -0.1445, -0.0501, -0.0424],\n",
       "                      [-0.0527,  0.0578,  0.1864,  ...,  0.0393, -0.0249, -0.0241],\n",
       "                      ...,\n",
       "                      [-0.0516, -0.0031, -0.0276,  ...,  0.0214, -0.0200, -0.0306],\n",
       "                      [-0.0628,  0.0321, -0.0133,  ...,  0.0152,  0.0528,  0.1090],\n",
       "                      [-0.0167,  0.0409,  0.1429,  ..., -0.0325,  0.0147, -0.0523]])),\n",
       "             ('encoder.layer.18.attention.self.w2e_query.bias',\n",
       "              tensor([-0.2749, -0.0114, -0.1438,  ...,  0.0094, -0.0061,  0.0200])),\n",
       "             ('encoder.layer.18.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0312, -0.0020,  0.1373,  ...,  0.0215,  0.0679, -0.0149],\n",
       "                      [ 0.0325,  0.0206,  0.0124,  ..., -0.1437, -0.0499, -0.0419],\n",
       "                      [-0.0536,  0.0582,  0.1862,  ...,  0.0396, -0.0251, -0.0236],\n",
       "                      ...,\n",
       "                      [-0.0514, -0.0030, -0.0274,  ...,  0.0215, -0.0203, -0.0314],\n",
       "                      [-0.0645,  0.0326, -0.0127,  ...,  0.0157,  0.0520,  0.1094],\n",
       "                      [-0.0181,  0.0415,  0.1426,  ..., -0.0311,  0.0135, -0.0525]])),\n",
       "             ('encoder.layer.18.attention.self.e2w_query.bias',\n",
       "              tensor([-0.2744, -0.0119, -0.1432,  ...,  0.0094, -0.0058,  0.0204])),\n",
       "             ('encoder.layer.18.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0307, -0.0016,  0.1377,  ...,  0.0223,  0.0677, -0.0148],\n",
       "                      [ 0.0331,  0.0205,  0.0126,  ..., -0.1440, -0.0498, -0.0421],\n",
       "                      [-0.0530,  0.0579,  0.1863,  ...,  0.0394, -0.0252, -0.0237],\n",
       "                      ...,\n",
       "                      [-0.0513, -0.0036, -0.0270,  ...,  0.0216, -0.0195, -0.0315],\n",
       "                      [-0.0638,  0.0327, -0.0135,  ...,  0.0155,  0.0523,  0.1093],\n",
       "                      [-0.0182,  0.0419,  0.1423,  ..., -0.0317,  0.0130, -0.0525]])),\n",
       "             ('encoder.layer.18.attention.self.e2e_query.bias',\n",
       "              tensor([-0.2747, -0.0121, -0.1434,  ...,  0.0091, -0.0052,  0.0210])),\n",
       "             ('encoder.layer.18.attention.output.dense.weight',\n",
       "              tensor([[-0.0367, -0.0226, -0.0600,  ..., -0.0258, -0.0083, -0.0373],\n",
       "                      [-0.0209,  0.0700, -0.0516,  ..., -0.0005, -0.0236,  0.0150],\n",
       "                      [-0.0378,  0.0180, -0.0059,  ...,  0.0090, -0.0240, -0.0021],\n",
       "                      ...,\n",
       "                      [ 0.0329,  0.0092,  0.0703,  ..., -0.0055,  0.0251,  0.0186],\n",
       "                      [-0.0049,  0.0205,  0.0229,  ..., -0.0155,  0.0012,  0.0128],\n",
       "                      [ 0.0003,  0.0100, -0.0009,  ..., -0.0007,  0.0266,  0.0232]])),\n",
       "             ('encoder.layer.18.attention.output.dense.bias',\n",
       "              tensor([-0.0156,  0.0790,  0.0290,  ...,  0.0712,  0.0370,  0.0011])),\n",
       "             ('encoder.layer.18.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9844, 0.9858, 1.0068,  ..., 0.9888, 0.9775, 0.9883])),\n",
       "             ('encoder.layer.18.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0967, -0.0235, -0.2546,  ..., -0.0727, -0.0626, -0.0679])),\n",
       "             ('encoder.layer.18.intermediate.dense.weight',\n",
       "              tensor([[ 0.0531, -0.0237,  0.0333,  ...,  0.0265,  0.0056, -0.0266],\n",
       "                      [ 0.0641, -0.0410,  0.0074,  ..., -0.0130,  0.0010, -0.0476],\n",
       "                      [ 0.0182, -0.0307, -0.0296,  ..., -0.0369,  0.0098, -0.0245],\n",
       "                      ...,\n",
       "                      [ 0.0176,  0.0610,  0.0417,  ...,  0.0286,  0.0301,  0.0031],\n",
       "                      [-0.0314, -0.0527,  0.0035,  ...,  0.0367, -0.0278,  0.0063],\n",
       "                      [ 0.0405,  0.0546, -0.0630,  ...,  0.0055,  0.0096, -0.0022]])),\n",
       "             ('encoder.layer.18.intermediate.dense.bias',\n",
       "              tensor([-0.0728, -0.1020, -0.0056,  ..., -0.0469, -0.0974, -0.0814])),\n",
       "             ('encoder.layer.18.output.dense.weight',\n",
       "              tensor([[-0.0396,  0.0020,  0.0182,  ...,  0.0207, -0.0287, -0.0345],\n",
       "                      [-0.0392, -0.0367, -0.0211,  ...,  0.0434, -0.0288, -0.0079],\n",
       "                      [ 0.0152, -0.0046, -0.0080,  ..., -0.0103, -0.0041, -0.0163],\n",
       "                      ...,\n",
       "                      [ 0.0177,  0.0180,  0.0403,  ..., -0.0037, -0.0016, -0.0109],\n",
       "                      [-0.0109, -0.0129, -0.0012,  ..., -0.0042,  0.0506,  0.0118],\n",
       "                      [-0.0299, -0.0143,  0.0425,  ...,  0.0028, -0.0568, -0.0229]])),\n",
       "             ('encoder.layer.18.output.dense.bias',\n",
       "              tensor([-0.0771,  0.0003, -0.1595,  ...,  0.0427, -0.0415, -0.0423])),\n",
       "             ('encoder.layer.18.output.LayerNorm.weight',\n",
       "              tensor([0.9824, 0.9985, 1.0059,  ..., 0.9810, 0.9873, 0.9800])),\n",
       "             ('encoder.layer.18.output.LayerNorm.bias',\n",
       "              tensor([-0.0076, -0.0493,  0.1214,  ..., -0.0184, -0.0269, -0.0289])),\n",
       "             ('encoder.layer.19.attention.self.query.weight',\n",
       "              tensor([[-0.0494, -0.0257, -0.0154,  ..., -0.0724,  0.0584, -0.1398],\n",
       "                      [ 0.0345,  0.0157, -0.1326,  ...,  0.0322,  0.0449,  0.0746],\n",
       "                      [-0.0240, -0.0155,  0.0447,  ..., -0.0638, -0.0773,  0.0163],\n",
       "                      ...,\n",
       "                      [-0.0046, -0.0125, -0.1968,  ...,  0.0892, -0.0090, -0.0332],\n",
       "                      [-0.1260,  0.0588,  0.0543,  ..., -0.0107,  0.0589, -0.0865],\n",
       "                      [-0.0288,  0.0571,  0.0611,  ...,  0.1001,  0.0637, -0.0143]])),\n",
       "             ('encoder.layer.19.attention.self.query.bias',\n",
       "              tensor([-0.0135, -0.0614, -0.0117,  ..., -0.0227,  0.0388, -0.0207])),\n",
       "             ('encoder.layer.19.attention.self.key.weight',\n",
       "              tensor([[-0.0225,  0.0094, -0.0019,  ...,  0.0379, -0.0851, -0.0089],\n",
       "                      [ 0.0622,  0.0584, -0.0960,  ...,  0.0609, -0.0431,  0.0600],\n",
       "                      [-0.0529, -0.0144,  0.0392,  ...,  0.0244,  0.1096, -0.0484],\n",
       "                      ...,\n",
       "                      [-0.0778, -0.0218, -0.2588,  ...,  0.0128,  0.0647,  0.0310],\n",
       "                      [-0.0156,  0.0067,  0.1630,  ...,  0.0240,  0.0862,  0.0146],\n",
       "                      [ 0.0134, -0.0760,  0.1261,  ..., -0.0471, -0.0170,  0.0728]])),\n",
       "             ('encoder.layer.19.attention.self.key.bias',\n",
       "              tensor([ 0.0070, -0.0076,  0.0174,  ..., -0.0101, -0.0190,  0.0177])),\n",
       "             ('encoder.layer.19.attention.self.value.weight',\n",
       "              tensor([[ 0.0265,  0.0144,  0.0313,  ...,  0.0293,  0.0184,  0.0257],\n",
       "                      [-0.0121,  0.0083, -0.0035,  ...,  0.0392,  0.0278, -0.0225],\n",
       "                      [-0.0375, -0.0092,  0.0154,  ...,  0.0316, -0.0218, -0.0326],\n",
       "                      ...,\n",
       "                      [ 0.0145,  0.0169,  0.0109,  ..., -0.0225, -0.0126, -0.0178],\n",
       "                      [ 0.0264,  0.0260, -0.0373,  ...,  0.0266, -0.0201, -0.0450],\n",
       "                      [-0.0201,  0.0596, -0.0245,  ...,  0.0354,  0.0258, -0.0063]])),\n",
       "             ('encoder.layer.19.attention.self.value.bias',\n",
       "              tensor([ 3.0174e-03,  6.9275e-02,  3.5071e-04,  ..., -3.7098e-03,\n",
       "                       6.0618e-05, -1.7593e-02])),\n",
       "             ('encoder.layer.19.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0500, -0.0252, -0.0150,  ..., -0.0726,  0.0582, -0.1396],\n",
       "                      [ 0.0341,  0.0155, -0.1322,  ...,  0.0320,  0.0453,  0.0739],\n",
       "                      [-0.0241, -0.0164,  0.0439,  ..., -0.0631, -0.0767,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0045, -0.0131, -0.1970,  ...,  0.0890, -0.0089, -0.0335],\n",
       "                      [-0.1260,  0.0584,  0.0540,  ..., -0.0111,  0.0589, -0.0862],\n",
       "                      [-0.0275,  0.0560,  0.0606,  ...,  0.0992,  0.0646, -0.0158]])),\n",
       "             ('encoder.layer.19.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0136, -0.0610, -0.0111,  ..., -0.0235,  0.0390, -0.0218])),\n",
       "             ('encoder.layer.19.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0503, -0.0251, -0.0154,  ..., -0.0720,  0.0580, -0.1395],\n",
       "                      [ 0.0339,  0.0148, -0.1318,  ...,  0.0329,  0.0457,  0.0741],\n",
       "                      [-0.0236, -0.0161,  0.0439,  ..., -0.0634, -0.0760,  0.0161],\n",
       "                      ...,\n",
       "                      [-0.0044, -0.0131, -0.1967,  ...,  0.0901, -0.0094, -0.0330],\n",
       "                      [-0.1262,  0.0578,  0.0543,  ..., -0.0117,  0.0596, -0.0865],\n",
       "                      [-0.0278,  0.0565,  0.0616,  ...,  0.0999,  0.0643, -0.0152]])),\n",
       "             ('encoder.layer.19.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0135, -0.0617, -0.0112,  ..., -0.0238,  0.0389, -0.0220])),\n",
       "             ('encoder.layer.19.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0498, -0.0256, -0.0152,  ..., -0.0721,  0.0583, -0.1393],\n",
       "                      [ 0.0337,  0.0162, -0.1332,  ...,  0.0316,  0.0450,  0.0745],\n",
       "                      [-0.0246, -0.0158,  0.0433,  ..., -0.0641, -0.0771,  0.0161],\n",
       "                      ...,\n",
       "                      [-0.0043, -0.0128, -0.1969,  ...,  0.0898, -0.0094, -0.0330],\n",
       "                      [-0.1261,  0.0580,  0.0541,  ..., -0.0116,  0.0596, -0.0866],\n",
       "                      [-0.0270,  0.0565,  0.0615,  ...,  0.1002,  0.0643, -0.0152]])),\n",
       "             ('encoder.layer.19.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0136, -0.0602, -0.0104,  ..., -0.0232,  0.0385, -0.0220])),\n",
       "             ('encoder.layer.19.attention.output.dense.weight',\n",
       "              tensor([[-0.0027,  0.0258, -0.0212,  ...,  0.0243,  0.0151, -0.0046],\n",
       "                      [ 0.0063, -0.0319, -0.0446,  ..., -0.0044,  0.0387,  0.0027],\n",
       "                      [ 0.0010, -0.0481, -0.0291,  ...,  0.0385, -0.0255,  0.0137],\n",
       "                      ...,\n",
       "                      [-0.0619, -0.0606, -0.0305,  ...,  0.0019, -0.0008,  0.0151],\n",
       "                      [-0.0196,  0.0453,  0.0075,  ...,  0.0130,  0.0197, -0.0075],\n",
       "                      [-0.0241, -0.0363,  0.0073,  ..., -0.0078, -0.0267, -0.0442]])),\n",
       "             ('encoder.layer.19.attention.output.dense.bias',\n",
       "              tensor([ 0.0030,  0.0602,  0.0794,  ..., -0.0011,  0.0254,  0.0068])),\n",
       "             ('encoder.layer.19.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9785, 0.9893, 1.0078,  ..., 0.9731, 0.9873, 0.9927])),\n",
       "             ('encoder.layer.19.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0815, -0.0384, -0.2178,  ..., -0.0638, -0.0837, -0.0627])),\n",
       "             ('encoder.layer.19.intermediate.dense.weight',\n",
       "              tensor([[ 0.0501, -0.0396,  0.0133,  ...,  0.0851,  0.0759,  0.1544],\n",
       "                      [ 0.0516, -0.0094,  0.0536,  ...,  0.0216,  0.0282,  0.0237],\n",
       "                      [ 0.0202,  0.0144,  0.0355,  ..., -0.0170, -0.0037,  0.0042],\n",
       "                      ...,\n",
       "                      [ 0.0777, -0.0235,  0.0235,  ..., -0.0045, -0.0512,  0.0404],\n",
       "                      [ 0.0240, -0.0102, -0.0387,  ..., -0.0165,  0.0339, -0.0841],\n",
       "                      [ 0.0152,  0.0425,  0.0344,  ..., -0.0325, -0.0134,  0.0352]])),\n",
       "             ('encoder.layer.19.intermediate.dense.bias',\n",
       "              tensor([-0.1025,  0.0120, -0.0414,  ..., -0.1160,  0.0042, -0.0175])),\n",
       "             ('encoder.layer.19.output.dense.weight',\n",
       "              tensor([[ 0.0163, -0.0167, -0.0239,  ..., -0.0398, -0.0058,  0.0093],\n",
       "                      [-0.0569, -0.0376,  0.0096,  ...,  0.0515, -0.0132,  0.0199],\n",
       "                      [ 0.0133, -0.0144,  0.0024,  ..., -0.0162,  0.0085, -0.0007],\n",
       "                      ...,\n",
       "                      [ 0.0079, -0.0095,  0.0257,  ..., -0.0509,  0.0146,  0.0218],\n",
       "                      [ 0.0269, -0.0103, -0.0317,  ..., -0.0216, -0.0056, -0.0068],\n",
       "                      [ 0.0063,  0.0131, -0.0023,  ...,  0.0360,  0.0397,  0.0316]])),\n",
       "             ('encoder.layer.19.output.dense.bias',\n",
       "              tensor([-0.0396,  0.0266, -0.0498,  ...,  0.1116, -0.0568,  0.0031])),\n",
       "             ('encoder.layer.19.output.LayerNorm.weight',\n",
       "              tensor([0.9629, 0.9946, 1.0049,  ..., 0.9775, 0.9912, 0.9829])),\n",
       "             ('encoder.layer.19.output.LayerNorm.bias',\n",
       "              tensor([-0.0115, -0.0338,  0.0751,  ..., -0.0206, -0.0154, -0.0063])),\n",
       "             ('encoder.layer.20.attention.self.query.weight',\n",
       "              tensor([[-0.0135,  0.0141, -0.0103,  ...,  0.0032, -0.0529,  0.0183],\n",
       "                      [-0.0717, -0.0754,  0.0288,  ..., -0.0293, -0.0356, -0.0032],\n",
       "                      [-0.0204, -0.0227,  0.0008,  ...,  0.0310,  0.0418, -0.0027],\n",
       "                      ...,\n",
       "                      [ 0.0937, -0.0094, -0.0301,  ...,  0.0708, -0.0226,  0.0198],\n",
       "                      [ 0.0023,  0.0027,  0.1947,  ..., -0.0231,  0.0257,  0.0019],\n",
       "                      [-0.0258,  0.0158, -0.1173,  ..., -0.0471, -0.0370, -0.0479]])),\n",
       "             ('encoder.layer.20.attention.self.query.bias',\n",
       "              tensor([-0.0265,  0.0259,  0.0136,  ...,  0.0921, -0.0348,  0.0515])),\n",
       "             ('encoder.layer.20.attention.self.key.weight',\n",
       "              tensor([[ 0.0144, -0.0725, -0.0235,  ..., -0.1069, -0.0224, -0.0865],\n",
       "                      [-0.0043, -0.0015,  0.0377,  ..., -0.0191,  0.0018, -0.0090],\n",
       "                      [ 0.0270,  0.0513, -0.0859,  ...,  0.1076,  0.0244,  0.0363],\n",
       "                      ...,\n",
       "                      [-0.0400, -0.0552, -0.1095,  ..., -0.0244, -0.0118,  0.0293],\n",
       "                      [-0.0255,  0.0522,  0.2231,  ...,  0.0243, -0.0611,  0.0279],\n",
       "                      [-0.0188,  0.0211, -0.0475,  ..., -0.0924, -0.0144,  0.0152]])),\n",
       "             ('encoder.layer.20.attention.self.key.bias',\n",
       "              tensor([-0.0054, -0.0048,  0.0036,  ..., -0.0118,  0.0155, -0.0161])),\n",
       "             ('encoder.layer.20.attention.self.value.weight',\n",
       "              tensor([[-0.0486, -0.0069,  0.0269,  ..., -0.0248, -0.0012,  0.0612],\n",
       "                      [-0.0159, -0.0032, -0.0187,  ..., -0.0260,  0.1050,  0.0197],\n",
       "                      [ 0.0007,  0.0330, -0.0116,  ..., -0.0687, -0.0788,  0.0149],\n",
       "                      ...,\n",
       "                      [-0.0618,  0.0314,  0.0218,  ...,  0.0701,  0.0107,  0.0195],\n",
       "                      [ 0.0903,  0.0067,  0.0598,  ..., -0.0047,  0.0148, -0.0497],\n",
       "                      [ 0.0185,  0.0395, -0.0121,  ..., -0.0281, -0.0061, -0.0716]])),\n",
       "             ('encoder.layer.20.attention.self.value.bias',\n",
       "              tensor([ 0.0001,  0.0057,  0.0203,  ...,  0.0018,  0.0026, -0.0055])),\n",
       "             ('encoder.layer.20.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0133,  0.0146, -0.0095,  ...,  0.0044, -0.0528,  0.0183],\n",
       "                      [-0.0706, -0.0753,  0.0301,  ..., -0.0288, -0.0353, -0.0044],\n",
       "                      [-0.0209, -0.0238, -0.0005,  ...,  0.0310,  0.0411, -0.0025],\n",
       "                      ...,\n",
       "                      [ 0.0939, -0.0083, -0.0293,  ...,  0.0735, -0.0219,  0.0208],\n",
       "                      [ 0.0016,  0.0031,  0.1948,  ..., -0.0232,  0.0259,  0.0027],\n",
       "                      [-0.0251,  0.0149, -0.1173,  ..., -0.0484, -0.0371, -0.0480]])),\n",
       "             ('encoder.layer.20.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0268,  0.0252,  0.0147,  ...,  0.0913, -0.0343,  0.0510])),\n",
       "             ('encoder.layer.20.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0133,  0.0148, -0.0097,  ...,  0.0042, -0.0531,  0.0182],\n",
       "                      [-0.0715, -0.0742,  0.0296,  ..., -0.0288, -0.0370, -0.0040],\n",
       "                      [-0.0203, -0.0241,  0.0003,  ...,  0.0310,  0.0427, -0.0019],\n",
       "                      ...,\n",
       "                      [ 0.0944, -0.0080, -0.0280,  ...,  0.0741, -0.0224,  0.0201],\n",
       "                      [ 0.0023,  0.0027,  0.1956,  ..., -0.0241,  0.0258,  0.0021],\n",
       "                      [-0.0256,  0.0147, -0.1180,  ..., -0.0476, -0.0369, -0.0470]])),\n",
       "             ('encoder.layer.20.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0264,  0.0260,  0.0138,  ...,  0.0901, -0.0344,  0.0513])),\n",
       "             ('encoder.layer.20.attention.self.e2e_query.weight',\n",
       "              tensor([[-1.3809e-02,  1.5686e-02, -1.0017e-02,  ...,  3.9482e-03,\n",
       "                       -5.3375e-02,  1.8295e-02],\n",
       "                      [-7.1411e-02, -7.4097e-02,  2.9404e-02,  ..., -2.9205e-02,\n",
       "                       -3.5736e-02, -4.2763e-03],\n",
       "                      [-2.0996e-02, -2.3773e-02,  2.3782e-05,  ...,  3.1204e-02,\n",
       "                        4.1504e-02, -1.9779e-03],\n",
       "                      ...,\n",
       "                      [ 9.3811e-02, -8.9722e-03, -2.9236e-02,  ...,  7.2815e-02,\n",
       "                       -2.2339e-02,  2.0401e-02],\n",
       "                      [ 1.6937e-03,  2.2144e-03,  1.9470e-01,  ..., -2.4597e-02,\n",
       "                        2.5742e-02,  2.0771e-03],\n",
       "                      [-2.5223e-02,  1.5930e-02, -1.1755e-01,  ..., -4.6814e-02,\n",
       "                       -3.6987e-02, -4.7394e-02]])),\n",
       "             ('encoder.layer.20.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0261,  0.0258,  0.0140,  ...,  0.0910, -0.0342,  0.0512])),\n",
       "             ('encoder.layer.20.attention.output.dense.weight',\n",
       "              tensor([[ 0.0141, -0.0607, -0.0506,  ...,  0.0567, -0.0533, -0.0154],\n",
       "                      [ 0.0120,  0.0442,  0.0133,  ..., -0.0169, -0.0104, -0.0556],\n",
       "                      [ 0.0259,  0.0087,  0.0064,  ..., -0.0156, -0.0530, -0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0406, -0.0266, -0.0499,  ..., -0.0740, -0.0228,  0.0360],\n",
       "                      [ 0.0176,  0.0038,  0.0066,  ..., -0.0204, -0.0138,  0.0309],\n",
       "                      [ 0.0114,  0.0019, -0.0138,  ...,  0.0191,  0.0138,  0.0343]])),\n",
       "             ('encoder.layer.20.attention.output.dense.bias',\n",
       "              tensor([-0.0117,  0.0777,  0.0611,  ...,  0.0725,  0.0870,  0.0222])),\n",
       "             ('encoder.layer.20.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9702, 0.9956, 1.0078,  ..., 0.9795, 0.9868, 0.9917])),\n",
       "             ('encoder.layer.20.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0316, -0.0351, -0.1602,  ..., -0.0451, -0.0892, -0.0469])),\n",
       "             ('encoder.layer.20.intermediate.dense.weight',\n",
       "              tensor([[ 0.0089, -0.0098,  0.0570,  ...,  0.0077,  0.0101,  0.0077],\n",
       "                      [ 0.0179, -0.0154,  0.0016,  ...,  0.0103, -0.0649,  0.0677],\n",
       "                      [-0.0117, -0.0205, -0.0567,  ..., -0.0200, -0.0344, -0.0379],\n",
       "                      ...,\n",
       "                      [ 0.0060, -0.0305,  0.0015,  ...,  0.0406,  0.0907,  0.0205],\n",
       "                      [ 0.0596,  0.0465,  0.0591,  ..., -0.0485, -0.0080, -0.0314],\n",
       "                      [-0.0179, -0.0428,  0.0470,  ..., -0.0086,  0.0035, -0.0075]])),\n",
       "             ('encoder.layer.20.intermediate.dense.bias',\n",
       "              tensor([-0.0217, -0.0353, -0.0472,  ..., -0.0266, -0.0187, -0.0252])),\n",
       "             ('encoder.layer.20.output.dense.weight',\n",
       "              tensor([[-0.0155,  0.0661,  0.0181,  ...,  0.0620, -0.0085, -0.0115],\n",
       "                      [ 0.0088,  0.0311,  0.0507,  ...,  0.0040,  0.0139, -0.0374],\n",
       "                      [-0.0135, -0.0023, -0.0088,  ..., -0.0088, -0.0088, -0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0119,  0.0092,  0.0508,  ..., -0.0165,  0.0142, -0.0054],\n",
       "                      [-0.0202, -0.0485,  0.0234,  ...,  0.0297,  0.0590,  0.0206],\n",
       "                      [-0.0327,  0.0060,  0.0361,  ...,  0.0190,  0.0394, -0.0054]])),\n",
       "             ('encoder.layer.20.output.dense.bias',\n",
       "              tensor([-0.0567,  0.0044, -0.0077,  ...,  0.0624, -0.0947,  0.0487])),\n",
       "             ('encoder.layer.20.output.LayerNorm.weight',\n",
       "              tensor([0.9624, 0.9907, 1.0049,  ..., 0.9785, 0.9854, 0.9761])),\n",
       "             ('encoder.layer.20.output.LayerNorm.bias',\n",
       "              tensor([-0.0321, -0.0316,  0.0782,  ..., -0.0300, -0.0230, -0.0139])),\n",
       "             ('encoder.layer.21.attention.self.query.weight',\n",
       "              tensor([[ 0.0313, -0.0815, -0.2120,  ..., -0.0113, -0.0081, -0.0399],\n",
       "                      [-0.0277, -0.0828,  0.0516,  ..., -0.0235,  0.0214,  0.0026],\n",
       "                      [ 0.0591,  0.0351,  0.0579,  ...,  0.0312, -0.0441, -0.0711],\n",
       "                      ...,\n",
       "                      [ 0.0060,  0.0133, -0.1488,  ...,  0.0714,  0.0658,  0.0537],\n",
       "                      [-0.0631,  0.0123,  0.0345,  ...,  0.0069,  0.0118,  0.0064],\n",
       "                      [-0.0428, -0.0414,  0.0454,  ...,  0.0176, -0.0244,  0.0657]])),\n",
       "             ('encoder.layer.21.attention.self.query.bias',\n",
       "              tensor([ 0.1652, -0.0307, -0.0158,  ..., -0.0682,  0.0426, -0.0465])),\n",
       "             ('encoder.layer.21.attention.self.key.weight',\n",
       "              tensor([[ 0.0140,  0.0523, -0.1556,  ...,  0.0720,  0.0301,  0.0097],\n",
       "                      [ 0.0472,  0.0454,  0.0679,  ...,  0.0105,  0.1289, -0.0372],\n",
       "                      [ 0.0011, -0.0027, -0.0004,  ..., -0.0781,  0.0145, -0.0092],\n",
       "                      ...,\n",
       "                      [-0.0558, -0.0397, -0.1234,  ...,  0.0264, -0.0538,  0.0315],\n",
       "                      [ 0.0833, -0.0176,  0.0697,  ..., -0.0969,  0.0291, -0.0070],\n",
       "                      [-0.0284,  0.0186,  0.0795,  ..., -0.0420,  0.0089, -0.0056]])),\n",
       "             ('encoder.layer.21.attention.self.key.bias',\n",
       "              tensor([-0.0618, -0.0095,  0.0029,  ..., -0.0012,  0.0003,  0.0061])),\n",
       "             ('encoder.layer.21.attention.self.value.weight',\n",
       "              tensor([[ 0.0320, -0.0331, -0.0540,  ..., -0.0317,  0.0140, -0.0276],\n",
       "                      [ 0.0392, -0.0499, -0.0010,  ...,  0.0255, -0.0567,  0.0702],\n",
       "                      [ 0.0150, -0.0408, -0.0123,  ...,  0.0084, -0.0396,  0.0258],\n",
       "                      ...,\n",
       "                      [ 0.0247, -0.0698, -0.0109,  ..., -0.0315, -0.0745, -0.0319],\n",
       "                      [ 0.0282, -0.0320, -0.0421,  ...,  0.0715, -0.0160,  0.0277],\n",
       "                      [-0.0226, -0.0001,  0.0956,  ..., -0.0317, -0.0220,  0.0236]])),\n",
       "             ('encoder.layer.21.attention.self.value.bias',\n",
       "              tensor([ 0.0071, -0.0036, -0.0004,  ..., -0.0107, -0.0255, -0.0129])),\n",
       "             ('encoder.layer.21.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0313, -0.0810, -0.2109,  ..., -0.0106, -0.0086, -0.0404],\n",
       "                      [-0.0278, -0.0827,  0.0525,  ..., -0.0221,  0.0214,  0.0026],\n",
       "                      [ 0.0590,  0.0358,  0.0587,  ...,  0.0324, -0.0428, -0.0715],\n",
       "                      ...,\n",
       "                      [ 0.0069,  0.0118, -0.1499,  ...,  0.0717,  0.0670,  0.0523],\n",
       "                      [-0.0630,  0.0124,  0.0348,  ...,  0.0073,  0.0112,  0.0061],\n",
       "                      [-0.0436, -0.0406,  0.0455,  ...,  0.0173, -0.0254,  0.0656]])),\n",
       "             ('encoder.layer.21.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.1646, -0.0317, -0.0166,  ..., -0.0676,  0.0429, -0.0446])),\n",
       "             ('encoder.layer.21.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0313, -0.0813, -0.2122,  ..., -0.0117, -0.0089, -0.0405],\n",
       "                      [-0.0273, -0.0820,  0.0516,  ..., -0.0233,  0.0215,  0.0021],\n",
       "                      [ 0.0584,  0.0349,  0.0594,  ...,  0.0333, -0.0430, -0.0711],\n",
       "                      ...,\n",
       "                      [ 0.0069,  0.0120, -0.1493,  ...,  0.0715,  0.0668,  0.0538],\n",
       "                      [-0.0625,  0.0132,  0.0349,  ...,  0.0070,  0.0119,  0.0068],\n",
       "                      [-0.0437, -0.0402,  0.0458,  ...,  0.0179, -0.0257,  0.0662]])),\n",
       "             ('encoder.layer.21.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.1658, -0.0312, -0.0172,  ..., -0.0682,  0.0421, -0.0457])),\n",
       "             ('encoder.layer.21.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0315, -0.0814, -0.2109,  ..., -0.0107, -0.0084, -0.0399],\n",
       "                      [-0.0273, -0.0832,  0.0533,  ..., -0.0219,  0.0218,  0.0027],\n",
       "                      [ 0.0585,  0.0361,  0.0583,  ...,  0.0324, -0.0433, -0.0723],\n",
       "                      ...,\n",
       "                      [ 0.0064,  0.0116, -0.1495,  ...,  0.0717,  0.0671,  0.0526],\n",
       "                      [-0.0641,  0.0124,  0.0349,  ...,  0.0071,  0.0113,  0.0065],\n",
       "                      [-0.0432, -0.0412,  0.0452,  ...,  0.0172, -0.0250,  0.0657]])),\n",
       "             ('encoder.layer.21.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.1649, -0.0322, -0.0164,  ..., -0.0685,  0.0426, -0.0457])),\n",
       "             ('encoder.layer.21.attention.output.dense.weight',\n",
       "              tensor([[-0.0025,  0.0458, -0.0312,  ..., -0.0226,  0.0055,  0.0366],\n",
       "                      [ 0.0351,  0.0163, -0.0299,  ...,  0.0084,  0.0271, -0.0189],\n",
       "                      [ 0.0117, -0.0417, -0.0055,  ..., -0.0131,  0.0153, -0.0416],\n",
       "                      ...,\n",
       "                      [ 0.0182,  0.0421, -0.0054,  ...,  0.0201, -0.0207,  0.0496],\n",
       "                      [-0.0484,  0.0739, -0.0655,  ..., -0.0018, -0.0438, -0.0179],\n",
       "                      [ 0.0147,  0.0130, -0.0577,  ...,  0.0553, -0.0240, -0.0257]])),\n",
       "             ('encoder.layer.21.attention.output.dense.bias',\n",
       "              tensor([-0.0268,  0.0895,  0.0458,  ...,  0.0353,  0.1769,  0.0312])),\n",
       "             ('encoder.layer.21.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9673, 0.9897, 1.0059,  ..., 0.9775, 0.9922, 0.9893])),\n",
       "             ('encoder.layer.21.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0484, -0.0605, -0.1381,  ..., -0.0503, -0.1013, -0.0357])),\n",
       "             ('encoder.layer.21.intermediate.dense.weight',\n",
       "              tensor([[-0.0125, -0.0347,  0.0392,  ...,  0.0515,  0.0213, -0.0267],\n",
       "                      [ 0.0027,  0.0022, -0.0748,  ...,  0.0260,  0.0011,  0.0546],\n",
       "                      [ 0.0002,  0.0395, -0.0457,  ..., -0.0037,  0.0085,  0.0097],\n",
       "                      ...,\n",
       "                      [-0.0079, -0.0183,  0.0262,  ..., -0.0218, -0.0705, -0.0249],\n",
       "                      [ 0.0079, -0.0706,  0.0151,  ..., -0.0226,  0.0091, -0.0209],\n",
       "                      [ 0.0024, -0.0013,  0.0187,  ..., -0.0108,  0.0338,  0.0370]])),\n",
       "             ('encoder.layer.21.intermediate.dense.bias',\n",
       "              tensor([-0.0268, -0.0455,  0.0202,  ..., -0.0285, -0.0021, -0.0143])),\n",
       "             ('encoder.layer.21.output.dense.weight',\n",
       "              tensor([[-1.4450e-02, -2.0564e-05, -4.2229e-03,  ...,  3.7720e-02,\n",
       "                       -2.1622e-02, -3.8422e-02],\n",
       "                      [ 2.3479e-03,  1.0132e-02, -3.6865e-02,  ...,  1.4954e-02,\n",
       "                       -3.3997e-02,  5.3680e-02],\n",
       "                      [-1.4687e-02,  3.7785e-03,  4.2953e-03,  ...,  1.0460e-02,\n",
       "                        7.3051e-03,  1.3718e-02],\n",
       "                      ...,\n",
       "                      [-2.8732e-02,  1.1368e-02,  2.6184e-02,  ..., -1.7822e-02,\n",
       "                       -1.1414e-02, -4.9210e-04],\n",
       "                      [-3.3173e-02,  1.6558e-04, -3.9825e-02,  ..., -3.5004e-02,\n",
       "                       -1.0461e-01,  3.9597e-03],\n",
       "                      [-9.4452e-03,  6.1989e-05,  3.2215e-03,  ..., -3.3455e-03,\n",
       "                       -2.9739e-02,  2.5444e-03]])),\n",
       "             ('encoder.layer.21.output.dense.bias',\n",
       "              tensor([-0.0097,  0.0060, -0.0721,  ...,  0.0911, -0.1213,  0.0145])),\n",
       "             ('encoder.layer.21.output.LayerNorm.weight',\n",
       "              tensor([0.9683, 0.9893, 1.0020,  ..., 0.9829, 0.9863, 0.9917])),\n",
       "             ('encoder.layer.21.output.LayerNorm.bias',\n",
       "              tensor([-0.0446, -0.0148,  0.0367,  ..., -0.0397, -0.0576, -0.0172])),\n",
       "             ('encoder.layer.22.attention.self.query.weight',\n",
       "              tensor([[ 0.0027,  0.0379,  0.0845,  ...,  0.0141,  0.0215,  0.0627],\n",
       "                      [ 0.0147, -0.0403,  0.0055,  ..., -0.1011,  0.0528,  0.0120],\n",
       "                      [ 0.1000, -0.0248,  0.1840,  ...,  0.0100,  0.0579, -0.0062],\n",
       "                      ...,\n",
       "                      [-0.0086, -0.0108, -0.0818,  ..., -0.0722, -0.0103,  0.0692],\n",
       "                      [-0.0422,  0.0748, -0.0131,  ...,  0.0585, -0.0373, -0.0318],\n",
       "                      [ 0.0331,  0.0579,  0.1002,  ...,  0.0266, -0.0220, -0.0792]])),\n",
       "             ('encoder.layer.22.attention.self.query.bias',\n",
       "              tensor([-0.0043,  0.0063,  0.1520,  ...,  0.0035,  0.1005, -0.0566])),\n",
       "             ('encoder.layer.22.attention.self.key.weight',\n",
       "              tensor([[-0.0690, -0.0500,  0.0703,  ..., -0.0008, -0.0575,  0.0455],\n",
       "                      [ 0.0248, -0.0253,  0.0254,  ...,  0.0299, -0.0143,  0.0128],\n",
       "                      [ 0.0058,  0.0305,  0.0906,  ...,  0.0168, -0.0210,  0.0133],\n",
       "                      ...,\n",
       "                      [ 0.0836, -0.0033, -0.1017,  ..., -0.0584, -0.0534, -0.0911],\n",
       "                      [ 0.0242,  0.0667, -0.0609,  ...,  0.0342,  0.0382, -0.0350],\n",
       "                      [-0.0486,  0.0172, -0.0297,  ..., -0.0002,  0.0193, -0.0102]])),\n",
       "             ('encoder.layer.22.attention.self.key.bias',\n",
       "              tensor([-0.0028,  0.0007, -0.0029,  ...,  0.0049, -0.0011, -0.0003])),\n",
       "             ('encoder.layer.22.attention.self.value.weight',\n",
       "              tensor([[ 0.0247,  0.0353,  0.0444,  ...,  0.0455, -0.0217,  0.0506],\n",
       "                      [-0.0467, -0.0139, -0.0150,  ...,  0.0509, -0.0746,  0.0573],\n",
       "                      [-0.0201,  0.0293,  0.0070,  ..., -0.0036, -0.0171,  0.0177],\n",
       "                      ...,\n",
       "                      [-0.0434,  0.0021, -0.0140,  ..., -0.0321,  0.0290, -0.0474],\n",
       "                      [ 0.0134,  0.0121,  0.0356,  ...,  0.0077,  0.0052, -0.0363],\n",
       "                      [-0.0213, -0.0169, -0.0398,  ..., -0.0293,  0.0153,  0.0217]])),\n",
       "             ('encoder.layer.22.attention.self.value.bias',\n",
       "              tensor([ 0.0083, -0.0132,  0.0137,  ..., -0.0119, -0.0051, -0.0074])),\n",
       "             ('encoder.layer.22.attention.self.w2e_query.weight',\n",
       "              tensor([[ 0.0027,  0.0377,  0.0852,  ...,  0.0142,  0.0212,  0.0618],\n",
       "                      [ 0.0148, -0.0396,  0.0044,  ..., -0.1011,  0.0522,  0.0117],\n",
       "                      [ 0.1010, -0.0232,  0.1851,  ...,  0.0107,  0.0584, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0075, -0.0107, -0.0817,  ..., -0.0717, -0.0110,  0.0698],\n",
       "                      [-0.0421,  0.0753, -0.0126,  ...,  0.0585, -0.0378, -0.0310],\n",
       "                      [ 0.0330,  0.0578,  0.0995,  ...,  0.0262, -0.0227, -0.0779]])),\n",
       "             ('encoder.layer.22.attention.self.w2e_query.bias',\n",
       "              tensor([-0.0048,  0.0069,  0.1509,  ...,  0.0028,  0.1001, -0.0558])),\n",
       "             ('encoder.layer.22.attention.self.e2w_query.weight',\n",
       "              tensor([[ 0.0026,  0.0376,  0.0854,  ...,  0.0149,  0.0217,  0.0614],\n",
       "                      [ 0.0148, -0.0399,  0.0049,  ..., -0.1002,  0.0526,  0.0118],\n",
       "                      [ 0.1011, -0.0236,  0.1849,  ...,  0.0100,  0.0576, -0.0078],\n",
       "                      ...,\n",
       "                      [-0.0073, -0.0104, -0.0812,  ..., -0.0717, -0.0103,  0.0692],\n",
       "                      [-0.0418,  0.0745, -0.0126,  ...,  0.0589, -0.0370, -0.0318],\n",
       "                      [ 0.0332,  0.0589,  0.1003,  ...,  0.0262, -0.0219, -0.0789]])),\n",
       "             ('encoder.layer.22.attention.self.e2w_query.bias',\n",
       "              tensor([-0.0046,  0.0064,  0.1508,  ...,  0.0027,  0.0996, -0.0565])),\n",
       "             ('encoder.layer.22.attention.self.e2e_query.weight',\n",
       "              tensor([[ 0.0026,  0.0377,  0.0861,  ...,  0.0155,  0.0211,  0.0614],\n",
       "                      [ 0.0147, -0.0394,  0.0043,  ..., -0.1008,  0.0518,  0.0119],\n",
       "                      [ 0.1009, -0.0234,  0.1849,  ...,  0.0101,  0.0583, -0.0072],\n",
       "                      ...,\n",
       "                      [-0.0078, -0.0103, -0.0817,  ..., -0.0718, -0.0112,  0.0698],\n",
       "                      [-0.0419,  0.0748, -0.0130,  ...,  0.0589, -0.0370, -0.0316],\n",
       "                      [ 0.0327,  0.0581,  0.1004,  ...,  0.0264, -0.0226, -0.0782]])),\n",
       "             ('encoder.layer.22.attention.self.e2e_query.bias',\n",
       "              tensor([-0.0050,  0.0067,  0.1514,  ...,  0.0032,  0.0996, -0.0564])),\n",
       "             ('encoder.layer.22.attention.output.dense.weight',\n",
       "              tensor([[ 0.0406,  0.0515, -0.0049,  ..., -0.0326, -0.0337, -0.0120],\n",
       "                      [ 0.0062,  0.0237,  0.0297,  ..., -0.0476,  0.0051,  0.0297],\n",
       "                      [ 0.0197,  0.0032, -0.0261,  ..., -0.0191,  0.0526, -0.0032],\n",
       "                      ...,\n",
       "                      [ 0.0317,  0.0226, -0.0203,  ...,  0.0116, -0.0233, -0.0105],\n",
       "                      [ 0.0439, -0.0158,  0.0201,  ..., -0.0173, -0.0075, -0.0430],\n",
       "                      [ 0.0301,  0.0418,  0.0377,  ..., -0.0351,  0.0058, -0.0032]])),\n",
       "             ('encoder.layer.22.attention.output.dense.bias',\n",
       "              tensor([ 0.0753,  0.0949,  0.0677,  ...,  0.0082,  0.1453, -0.0301])),\n",
       "             ('encoder.layer.22.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9521, 0.9858, 0.9995,  ..., 0.9741, 0.9937, 0.9854])),\n",
       "             ('encoder.layer.22.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0498, -0.0141, -0.1243,  ..., -0.0382, -0.1030,  0.0334])),\n",
       "             ('encoder.layer.22.intermediate.dense.weight',\n",
       "              tensor([[-0.0006, -0.0699, -0.0486,  ..., -0.0094,  0.0135,  0.0815],\n",
       "                      [-0.0194, -0.0201,  0.0625,  ...,  0.0030,  0.0440,  0.0008],\n",
       "                      [-0.0282, -0.0662,  0.0743,  ...,  0.0126, -0.0145, -0.0492],\n",
       "                      ...,\n",
       "                      [-0.0321,  0.0190,  0.0443,  ...,  0.0499,  0.0122,  0.0396],\n",
       "                      [ 0.0627,  0.0158,  0.0451,  ...,  0.0217, -0.0021,  0.0066],\n",
       "                      [ 0.0054, -0.0773, -0.0609,  ..., -0.0082,  0.0189, -0.0474]])),\n",
       "             ('encoder.layer.22.intermediate.dense.bias',\n",
       "              tensor([ 0.0182, -0.0081, -0.0126,  ..., -0.0461,  0.0150, -0.0288])),\n",
       "             ('encoder.layer.22.output.dense.weight',\n",
       "              tensor([[-0.0263,  0.0348, -0.0259,  ...,  0.0071, -0.0061, -0.0853],\n",
       "                      [ 0.0141, -0.0254,  0.0232,  ..., -0.0068, -0.0297,  0.0171],\n",
       "                      [-0.0156, -0.0123, -0.0045,  ...,  0.0007, -0.0034,  0.0123],\n",
       "                      ...,\n",
       "                      [-0.0124, -0.0284,  0.0129,  ..., -0.0218, -0.0054,  0.0573],\n",
       "                      [ 0.0166, -0.0370,  0.0408,  ..., -0.0111, -0.0259, -0.0277],\n",
       "                      [-0.0075,  0.0702,  0.0308,  ..., -0.0215,  0.0051, -0.0247]])),\n",
       "             ('encoder.layer.22.output.dense.bias',\n",
       "              tensor([ 0.0238,  0.0466, -0.0745,  ...,  0.0241, -0.1318,  0.0461])),\n",
       "             ('encoder.layer.22.output.LayerNorm.weight',\n",
       "              tensor([0.9609, 0.9951, 1.0010,  ..., 0.9819, 0.9902, 0.9810])),\n",
       "             ('encoder.layer.22.output.LayerNorm.bias',\n",
       "              tensor([-0.0226,  0.0389,  0.0476,  ..., -0.0325, -0.0121,  0.0176])),\n",
       "             ('encoder.layer.23.attention.self.query.weight',\n",
       "              tensor([[-4.0314e-02,  1.9501e-02,  9.3323e-02,  ..., -8.6426e-02,\n",
       "                        8.3191e-02,  6.0547e-02],\n",
       "                      [-4.3365e-02,  1.8631e-02,  1.0114e-01,  ..., -7.4005e-03,\n",
       "                       -1.5900e-02, -2.0618e-03],\n",
       "                      [ 3.9764e-02,  4.3915e-02,  3.1433e-02,  ..., -8.6288e-03,\n",
       "                       -8.4595e-02, -3.3203e-02],\n",
       "                      ...,\n",
       "                      [ 9.9976e-02, -5.0201e-02,  1.2720e-01,  ...,  7.9727e-04,\n",
       "                       -7.8354e-03,  6.5002e-02],\n",
       "                      [-5.1636e-02, -6.2287e-05, -9.3269e-04,  ..., -4.9316e-02,\n",
       "                       -1.0574e-02, -1.5030e-02],\n",
       "                      [-3.7289e-03, -4.9347e-02, -5.7098e-02,  ...,  4.6631e-02,\n",
       "                       -6.2164e-02,  1.4992e-02]])),\n",
       "             ('encoder.layer.23.attention.self.query.bias',\n",
       "              tensor([ 0.0779,  0.2739,  0.0301,  ..., -0.2007,  0.1144,  0.0806])),\n",
       "             ('encoder.layer.23.attention.self.key.weight',\n",
       "              tensor([[ 0.0566, -0.0259,  0.2134,  ..., -0.0132,  0.0252,  0.0230],\n",
       "                      [ 0.0719, -0.0682,  0.0745,  ...,  0.0134, -0.0398,  0.0105],\n",
       "                      [-0.1116, -0.0293, -0.0365,  ..., -0.1260,  0.0406, -0.0294],\n",
       "                      ...,\n",
       "                      [ 0.0476,  0.0104,  0.0692,  ..., -0.0438,  0.0012,  0.0547],\n",
       "                      [ 0.0222,  0.0122, -0.0670,  ..., -0.0203,  0.0358,  0.0352],\n",
       "                      [-0.0143, -0.0095, -0.0158,  ...,  0.1092,  0.0035,  0.0642]])),\n",
       "             ('encoder.layer.23.attention.self.key.bias',\n",
       "              tensor([-0.0166, -0.0016, -0.0149,  ...,  0.0866, -0.0135,  0.0022])),\n",
       "             ('encoder.layer.23.attention.self.value.weight',\n",
       "              tensor([[-0.0673, -0.0646, -0.0130,  ..., -0.0350,  0.0011,  0.0113],\n",
       "                      [ 0.0217,  0.0052,  0.0398,  ..., -0.0249,  0.0017, -0.0498],\n",
       "                      [-0.0486,  0.0667, -0.0142,  ...,  0.0062, -0.0479, -0.0122],\n",
       "                      ...,\n",
       "                      [ 0.0513,  0.0268, -0.0282,  ..., -0.0098, -0.0249,  0.0138],\n",
       "                      [ 0.0006, -0.0338,  0.0256,  ..., -0.0154, -0.0006,  0.0147],\n",
       "                      [ 0.0104, -0.0231,  0.0254,  ..., -0.0006,  0.0199,  0.0167]])),\n",
       "             ('encoder.layer.23.attention.self.value.bias',\n",
       "              tensor([-0.0151,  0.0174,  0.0117,  ...,  0.0080,  0.0070,  0.0140])),\n",
       "             ('encoder.layer.23.attention.self.w2e_query.weight',\n",
       "              tensor([[-0.0405,  0.0187,  0.0936,  ..., -0.0858,  0.0836,  0.0594],\n",
       "                      [-0.0434,  0.0176,  0.1013,  ..., -0.0061, -0.0153, -0.0034],\n",
       "                      [ 0.0402,  0.0434,  0.0307,  ..., -0.0089, -0.0853, -0.0320],\n",
       "                      ...,\n",
       "                      [ 0.1009, -0.0491,  0.1274,  ...,  0.0009, -0.0081,  0.0644],\n",
       "                      [-0.0510, -0.0008,  0.0014,  ..., -0.0474, -0.0116, -0.0148],\n",
       "                      [-0.0046, -0.0502, -0.0556,  ...,  0.0484, -0.0629,  0.0157]])),\n",
       "             ('encoder.layer.23.attention.self.w2e_query.bias',\n",
       "              tensor([ 0.0772,  0.2725,  0.0311,  ..., -0.2014,  0.1130,  0.0799])),\n",
       "             ('encoder.layer.23.attention.self.e2w_query.weight',\n",
       "              tensor([[-0.0409,  0.0191,  0.0937,  ..., -0.0863,  0.0839,  0.0599],\n",
       "                      [-0.0432,  0.0182,  0.1023,  ..., -0.0069, -0.0157, -0.0030],\n",
       "                      [ 0.0404,  0.0438,  0.0305,  ..., -0.0095, -0.0849, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.1009, -0.0497,  0.1282,  ...,  0.0009, -0.0081,  0.0643],\n",
       "                      [-0.0516, -0.0006,  0.0004,  ..., -0.0482, -0.0116, -0.0151],\n",
       "                      [-0.0051, -0.0501, -0.0565,  ...,  0.0479, -0.0630,  0.0153]])),\n",
       "             ('encoder.layer.23.attention.self.e2w_query.bias',\n",
       "              tensor([ 0.0774,  0.2727,  0.0311,  ..., -0.2014,  0.1130,  0.0798])),\n",
       "             ('encoder.layer.23.attention.self.e2e_query.weight',\n",
       "              tensor([[-0.0409,  0.0191,  0.0937,  ..., -0.0863,  0.0839,  0.0599],\n",
       "                      [-0.0432,  0.0182,  0.1023,  ..., -0.0069, -0.0157, -0.0030],\n",
       "                      [ 0.0404,  0.0438,  0.0305,  ..., -0.0095, -0.0849, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.1009, -0.0497,  0.1282,  ...,  0.0009, -0.0081,  0.0643],\n",
       "                      [-0.0516, -0.0006,  0.0004,  ..., -0.0482, -0.0116, -0.0151],\n",
       "                      [-0.0051, -0.0501, -0.0565,  ...,  0.0479, -0.0630,  0.0153]])),\n",
       "             ('encoder.layer.23.attention.self.e2e_query.bias',\n",
       "              tensor([ 0.0774,  0.2727,  0.0311,  ..., -0.2014,  0.1130,  0.0798])),\n",
       "             ('encoder.layer.23.attention.output.dense.weight',\n",
       "              tensor([[-0.0220, -0.0084, -0.0024,  ...,  0.0421, -0.0300,  0.0327],\n",
       "                      [-0.0416, -0.0088,  0.0247,  ...,  0.0493, -0.0093, -0.0458],\n",
       "                      [-0.0201,  0.0063,  0.0087,  ..., -0.0102,  0.0114, -0.0321],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0511, -0.0129,  ..., -0.0214,  0.0007, -0.0029],\n",
       "                      [ 0.0151,  0.0432,  0.0133,  ...,  0.0107,  0.0044,  0.0040],\n",
       "                      [ 0.0373, -0.0148, -0.0276,  ..., -0.0148,  0.0150,  0.0123]])),\n",
       "             ('encoder.layer.23.attention.output.dense.bias',\n",
       "              tensor([ 0.0627,  0.0713, -0.0060,  ...,  0.0313,  0.0207,  0.1620])),\n",
       "             ('encoder.layer.23.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9604, 0.9790, 0.9917,  ..., 0.9766, 0.9897, 0.9604])),\n",
       "             ('encoder.layer.23.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1370,  0.0294, -0.1637,  ..., -0.0656, -0.1442, -0.0920])),\n",
       "             ('encoder.layer.23.intermediate.dense.weight',\n",
       "              tensor([[-0.0112, -0.0859, -0.0120,  ..., -0.0127,  0.0096, -0.0239],\n",
       "                      [-0.0166, -0.0244, -0.0121,  ..., -0.0124,  0.0184, -0.0579],\n",
       "                      [-0.0006, -0.0931, -0.0034,  ...,  0.0340,  0.0327, -0.0181],\n",
       "                      ...,\n",
       "                      [-0.0374,  0.0201,  0.0123,  ...,  0.0053, -0.0398, -0.0084],\n",
       "                      [ 0.0427,  0.0011, -0.0074,  ..., -0.0186,  0.0629,  0.0438],\n",
       "                      [ 0.0406, -0.0222, -0.0293,  ...,  0.0483,  0.0296,  0.0448]])),\n",
       "             ('encoder.layer.23.intermediate.dense.bias',\n",
       "              tensor([ 0.0101, -0.0674, -0.1279,  ..., -0.0406, -0.0937, -0.0124])),\n",
       "             ('encoder.layer.23.output.dense.weight',\n",
       "              tensor([[ 0.0252, -0.0401, -0.0190,  ...,  0.0146,  0.0268, -0.0052],\n",
       "                      [ 0.0116,  0.0637, -0.0232,  ..., -0.0174, -0.0400,  0.0264],\n",
       "                      [-0.0019, -0.0097,  0.0051,  ...,  0.0105, -0.0260, -0.0152],\n",
       "                      ...,\n",
       "                      [ 0.0148, -0.0326,  0.0784,  ...,  0.0278, -0.0183,  0.0429],\n",
       "                      [ 0.0102, -0.0142,  0.0476,  ...,  0.0056,  0.0263, -0.0089],\n",
       "                      [-0.0397,  0.0108,  0.0006,  ...,  0.0340,  0.0153, -0.0161]])),\n",
       "             ('encoder.layer.23.output.dense.bias',\n",
       "              tensor([-0.0757, -0.0241, -0.0950,  ...,  0.0761, -0.1588,  0.0798])),\n",
       "             ('encoder.layer.23.output.LayerNorm.weight',\n",
       "              tensor([0.9805, 0.9932, 0.9951,  ..., 0.9756, 1.0010, 0.9854])),\n",
       "             ('encoder.layer.23.output.LayerNorm.bias',\n",
       "              tensor([-0.0358, -0.0344, -0.0120,  ..., -0.0469,  0.0007, -0.0184])),\n",
       "             ('pooler.dense.weight',\n",
       "              tensor([[-2.1347e-02, -6.3019e-03, -2.8824e-02,  ...,  9.4299e-03,\n",
       "                       -7.8812e-03,  1.5518e-02],\n",
       "                      [-2.5616e-03, -1.5396e-02,  5.1193e-03,  ..., -4.0070e-02,\n",
       "                       -1.0307e-02, -4.0100e-02],\n",
       "                      [ 7.8888e-03,  1.9897e-02, -1.4257e-03,  ...,  5.3406e-03,\n",
       "                       -1.0704e-02,  1.6003e-03],\n",
       "                      ...,\n",
       "                      [ 1.4782e-05, -7.4730e-03, -1.6571e-02,  ..., -2.6047e-02,\n",
       "                       -7.8011e-04, -6.7635e-03],\n",
       "                      [-8.0185e-03, -1.4694e-02, -2.6031e-02,  ..., -3.0762e-02,\n",
       "                       -1.1337e-02,  2.3163e-02],\n",
       "                      [-6.0120e-03,  2.7924e-02, -4.3488e-02,  ...,  2.1973e-02,\n",
       "                        1.4162e-03, -1.3374e-02]])),\n",
       "             ('pooler.dense.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('embeddings.word_embeddings.weight',\n",
       "              tensor([[-0.1410, -0.0089,  0.0384,  ...,  0.0511, -0.0069, -0.0374],\n",
       "                      [ 0.0089, -0.0142,  0.0128,  ..., -0.0154,  0.0242,  0.0137],\n",
       "                      [-0.0790,  0.0005, -0.1168,  ...,  0.1091,  0.0659, -0.0386],\n",
       "                      ...,\n",
       "                      [ 0.0396,  0.0010,  0.0478,  ..., -0.0250, -0.0500,  0.0352],\n",
       "                      [ 0.0481,  0.0262,  0.0424,  ..., -0.0371, -0.0062,  0.0085],\n",
       "                      [-0.0130, -0.0106, -0.0229,  ...,  0.0451,  0.0108, -0.0358]])),\n",
       "             ('embeddings.position_embeddings.weight',\n",
       "              tensor([[-0.0038,  0.0252, -0.0092,  ...,  0.0177,  0.0062, -0.0161],\n",
       "                      [ 0.0128, -0.0005, -0.0293,  ...,  0.0063, -0.0179,  0.0244],\n",
       "                      [ 0.0298,  0.0152, -0.0552,  ..., -0.0707, -0.0465,  0.0450],\n",
       "                      ...,\n",
       "                      [-0.0208, -0.0063,  0.0473,  ..., -0.0387,  0.0448,  0.0538],\n",
       "                      [-0.0282,  0.1193,  0.0454,  ...,  0.0206, -0.1188,  0.0498],\n",
       "                      [ 0.0958, -0.0753,  0.0517,  ..., -0.1151, -0.1053,  0.0489]])),\n",
       "             ('embeddings.token_type_embeddings.weight',\n",
       "              tensor([[-0.0009,  0.0003,  0.0006,  ..., -0.0002, -0.0004, -0.0011]])),\n",
       "             ('embeddings.LayerNorm.weight',\n",
       "              tensor([0.9316, 0.9233, 0.9126,  ..., 0.9395, 0.9136, 0.9019])),\n",
       "             ('embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.0300,  0.0422,  0.1936,  ..., -0.2252, -0.0895,  0.1246])),\n",
       "             ('entity_embeddings.entity_embeddings.weight',\n",
       "              tensor([[-0.0420, -0.0610, -0.0482,  ..., -0.0336, -0.0533, -0.0462],\n",
       "                      [ 0.0699,  0.0621,  0.0854,  ...,  0.0551,  0.0466,  0.0777],\n",
       "                      [ 0.0074, -0.0067,  0.0015,  ..., -0.0110, -0.0052, -0.0003],\n",
       "                      ...,\n",
       "                      [-0.0780, -0.0544, -0.0635,  ...,  0.0061, -0.0908, -0.0801],\n",
       "                      [-0.0913, -0.0692, -0.0123,  ..., -0.1384, -0.0340, -0.0620],\n",
       "                      [ 0.0124, -0.0218, -0.0023,  ..., -0.1331, -0.0721, -0.0953]])),\n",
       "             ('entity_embeddings.entity_embedding_dense.weight',\n",
       "              tensor([[-0.1981,  0.0007, -0.0202,  ...,  0.0644, -0.0417, -0.0397],\n",
       "                      [-0.0745,  0.0542, -0.0619,  ...,  0.0468,  0.2284,  0.1207],\n",
       "                      [-0.1025,  0.0271,  0.0388,  ...,  0.1439,  0.0417, -0.0260],\n",
       "                      ...,\n",
       "                      [ 0.0622,  0.0238,  0.0708,  ..., -0.0285, -0.0433, -0.0186],\n",
       "                      [-0.1016,  0.0193,  0.0932,  ..., -0.1866, -0.1316,  0.0490],\n",
       "                      [-0.0086, -0.0434,  0.0285,  ..., -0.0317,  0.0038,  0.0186]])),\n",
       "             ('entity_embeddings.position_embeddings.weight',\n",
       "              tensor([[-0.0203, -0.0177, -0.0124,  ..., -0.0187,  0.0235,  0.0100],\n",
       "                      [-0.0510,  0.0136, -0.0595,  ..., -0.2035, -0.0274, -0.0600],\n",
       "                      [-0.0271, -0.1049, -0.0072,  ..., -0.1039,  0.0197, -0.0698],\n",
       "                      ...,\n",
       "                      [ 0.0192,  0.0089,  0.0098,  ..., -0.0163, -0.0025, -0.0114],\n",
       "                      [-0.0093,  0.0056,  0.0043,  ..., -0.0050, -0.0219,  0.0092],\n",
       "                      [ 0.0004,  0.0029, -0.0044,  ..., -0.0157, -0.0013, -0.0172]])),\n",
       "             ('entity_embeddings.token_type_embeddings.weight',\n",
       "              tensor([[ 0.0201,  0.0640,  0.0471,  ..., -0.0645, -0.0461,  0.0504]])),\n",
       "             ('entity_embeddings.LayerNorm.weight',\n",
       "              tensor([1.0410, 1.0244, 1.0098,  ..., 1.0059, 1.0859, 0.9888])),\n",
       "             ('entity_embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.3530, -0.1464,  0.0742,  ...,  0.5566,  0.0612, -0.2042])),\n",
       "             ('qa_outputs.weight',\n",
       "              tensor([[-0.0028, -0.0093,  0.0183,  ...,  0.0241, -0.0452, -0.0288],\n",
       "                      [-0.0175,  0.0186,  0.0271,  ..., -0.0182,  0.0148,  0.0008]])),\n",
       "             ('qa_outputs.bias', tensor([0.0002, 0.0005]))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model = torch.load(\"./pytorch_model.bin\",map_location='cpu')# luke github官方上面提供的squad微调后权重\n",
    "torch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50265, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model['embeddings.word_embeddings.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 1024])\n",
      "[[-0.00344849  0.03479004  0.00061941 ...  0.00167656  0.059021\n",
      "  -0.04260254]\n",
      " [-0.02487183  0.05307007 -0.01480865 ... -0.03038025 -0.01448059\n",
      "   0.01166534]\n",
      " [ 0.00621414  0.07080078 -0.03323364 ...  0.08026123  0.01176453\n",
      "  -0.01317596]\n",
      " ...\n",
      " [-0.05853271  0.02101135 -0.04269409 ... -0.02983093  0.00513077\n",
      "   0.06939697]\n",
      " [ 0.04238892  0.02316284 -0.0612793  ... -0.05517578 -0.01571655\n",
      "   0.01708984]\n",
      " [-0.01829529 -0.04544067 -0.01016998 ...  0.04708862  0.02294922\n",
      "  -0.01771545]]\n",
      "torch.Size([1024])\n",
      "[ 0.31274414  0.05606079 -0.0748291  ... -0.07067871 -0.04995728\n",
      " -0.06677246]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00439072 -0.01828003 -0.01376343 ... -0.0040741   0.00939941\n",
      "  -0.01475525]\n",
      " [-0.02403259 -0.0002172   0.02523804 ...  0.04003906  0.04351807\n",
      "  -0.02008057]\n",
      " [-0.02658081 -0.05276489 -0.01207733 ... -0.03643799  0.00733566\n",
      "   0.0145874 ]\n",
      " ...\n",
      " [-0.07049561 -0.02668762 -0.01916504 ... -0.01908875  0.00925446\n",
      "   0.10125732]\n",
      " [ 0.01512146  0.00782013 -0.01699829 ... -0.00339508 -0.00845337\n",
      "   0.0440979 ]\n",
      " [-0.00911713 -0.06359863  0.04125977 ...  0.04672241  0.01481628\n",
      "  -0.04647827]]\n",
      "torch.Size([1024])\n",
      "[-0.00476074 -0.00275993 -0.0002768  ...  0.00123215  0.0017643\n",
      "  0.00122166]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03005981 -0.00054312 -0.02426147 ... -0.01795959  0.00263977\n",
      "   0.02197266]\n",
      " [ 0.05657959  0.04312134  0.0014267  ... -0.0153656   0.0925293\n",
      "  -0.02000427]\n",
      " [-0.01490021 -0.04251099  0.01272583 ... -0.05157471  0.00157738\n",
      "   0.06768799]\n",
      " ...\n",
      " [-0.01080322  0.00770569 -0.01192474 ...  0.03640747  0.02568054\n",
      "   0.01068115]\n",
      " [-0.00354004 -0.01351166 -0.05099487 ...  0.03860474 -0.03372192\n",
      "   0.0284729 ]\n",
      " [ 0.00422287 -0.00912476 -0.01343536 ... -0.0255127   0.08776855\n",
      "  -0.01817322]]\n",
      "torch.Size([1024])\n",
      "[-0.00065231  0.00230217 -0.00862122 ... -0.02230835 -0.02050781\n",
      " -0.03408813]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00246048  0.03552246  0.00109196 ...  0.0027523   0.05969238\n",
      "  -0.04248047]\n",
      " [-0.02500916  0.05361938 -0.01500702 ... -0.03024292 -0.01462555\n",
      "   0.01208496]\n",
      " [ 0.00557327  0.0713501  -0.03369141 ...  0.08056641  0.01131439\n",
      "  -0.01274109]\n",
      " ...\n",
      " [-0.05877686  0.02069092 -0.04244995 ... -0.029953    0.00476074\n",
      "   0.06933594]\n",
      " [ 0.04202271  0.02272034 -0.0607605  ... -0.05471802 -0.01570129\n",
      "   0.0173645 ]\n",
      " [-0.01831055 -0.04580688 -0.01037598 ...  0.04690552  0.02339172\n",
      "  -0.01799011]]\n",
      "torch.Size([1024])\n",
      "[ 0.31225586  0.05523682 -0.07562256 ... -0.0703125  -0.04983521\n",
      " -0.06652832]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00289154  0.03512573  0.00112629 ...  0.00242615  0.06051636\n",
      "  -0.04351807]\n",
      " [-0.02503967  0.05285645 -0.01525879 ... -0.03007507 -0.01576233\n",
      "   0.01247406]\n",
      " [ 0.00651932  0.0713501  -0.03311157 ...  0.08044434  0.01205444\n",
      "  -0.01361847]\n",
      " ...\n",
      " [-0.05895996  0.02087402 -0.04248047 ... -0.02992249  0.0043602\n",
      "   0.06921387]\n",
      " [ 0.04251099  0.0222168  -0.06085205 ... -0.0552063  -0.01525879\n",
      "   0.01754761]\n",
      " [-0.01885986 -0.04568481 -0.01074219 ...  0.04800415  0.02226257\n",
      "  -0.01797485]]\n",
      "torch.Size([1024])\n",
      "[ 0.31103516  0.05661011 -0.07617188 ... -0.07104492 -0.04968262\n",
      " -0.06604004]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00305748  0.03509521  0.000741   ...  0.00245285  0.06011963\n",
      "  -0.0428772 ]\n",
      " [-0.02601624  0.05276489 -0.01495361 ... -0.02999878 -0.01396179\n",
      "   0.01099396]\n",
      " [ 0.00556183  0.07006836 -0.03491211 ...  0.08117676  0.01173401\n",
      "  -0.01331329]\n",
      " ...\n",
      " [-0.05923462  0.02001953 -0.04309082 ... -0.02912903  0.00381851\n",
      "   0.0703125 ]\n",
      " [ 0.04104614  0.02159119 -0.06097412 ... -0.05517578 -0.01635742\n",
      "   0.01821899]\n",
      " [-0.01930237 -0.04598999 -0.01094055 ...  0.04824829  0.02200317\n",
      "  -0.01852417]]\n",
      "torch.Size([1024])\n",
      "[ 0.31152344  0.05490112 -0.07543945 ... -0.0703125  -0.04968262\n",
      " -0.06738281]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00186729  0.04022217 -0.01715088 ... -0.0144043  -0.03305054\n",
      "  -0.01701355]\n",
      " [-0.03363037  0.0138855  -0.01635742 ...  0.03109741 -0.00930786\n",
      "   0.02700806]\n",
      " [ 0.02740479 -0.07391357  0.01890564 ... -0.03204346 -0.0066452\n",
      "   0.0994873 ]\n",
      " ...\n",
      " [ 0.02806091  0.00106907  0.02159119 ...  0.01281738 -0.01074219\n",
      "  -0.03634644]\n",
      " [-0.00840759  0.05136108 -0.04690552 ...  0.04263306  0.02584839\n",
      "  -0.01600647]\n",
      " [ 0.04751587  0.02294922  0.0916748  ...  0.02767944  0.00907898\n",
      "   0.00701904]]\n",
      "torch.Size([1024])\n",
      "[-0.01324463  0.02928162  0.0859375  ...  0.07305908 -0.00679779\n",
      "  0.01024628]\n",
      "torch.Size([1024])\n",
      "[0.9794922  0.9897461  0.9736328  ... 0.98339844 0.9902344  0.9970703 ]\n",
      "torch.Size([1024])\n",
      "[-0.43017578  0.27612305 -0.00635147 ...  0.0111618   0.33007812\n",
      " -0.29785156]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 5.86242676e-02 -6.44531250e-02 -9.37500000e-02 ...  5.28335571e-03\n",
      "   2.01873779e-02 -1.51824951e-02]\n",
      " [ 1.52893066e-02 -2.75268555e-02  2.06756592e-02 ...  1.53961182e-02\n",
      "  -3.77502441e-02  1.21398926e-01]\n",
      " [ 3.72009277e-02 -6.68334961e-02  1.15215778e-04 ...  2.90679932e-02\n",
      "  -2.66876221e-02 -2.17895508e-02]\n",
      " ...\n",
      " [ 1.60675049e-02 -8.92944336e-02  4.42504883e-03 ...  3.31115723e-02\n",
      "  -5.17578125e-02 -6.73294067e-04]\n",
      " [ 1.34155273e-01  5.19714355e-02 -1.30004883e-01 ... -1.48681641e-01\n",
      "  -3.17687988e-02  2.18353271e-02]\n",
      " [ 7.13500977e-02 -2.89764404e-02 -6.04553223e-02 ...  9.59014893e-03\n",
      "  -5.74340820e-02 -2.94189453e-02]]\n",
      "torch.Size([4096])\n",
      "[-0.09387207 -0.07592773 -0.08447266 ... -0.10888672 -0.06933594\n",
      " -0.09405518]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.04370117  0.10180664  0.02964783 ... -0.05514526  0.05947876\n",
      "   0.06567383]\n",
      " [ 0.01795959  0.01129913 -0.00933838 ... -0.007061    0.01832581\n",
      "  -0.01124573]\n",
      " [ 0.02734375 -0.07415771  0.052948   ... -0.04284668 -0.01070404\n",
      "   0.00046253]\n",
      " ...\n",
      " [-0.01366425 -0.00316429  0.0534668  ...  0.00959015 -0.05737305\n",
      "   0.01515198]\n",
      " [-0.04956055  0.03305054 -0.07025146 ...  0.059021   -0.03552246\n",
      "  -0.00524139]\n",
      " [-0.09533691 -0.04486084 -0.09460449 ... -0.05328369  0.05203247\n",
      "  -0.02912903]]\n",
      "torch.Size([1024])\n",
      "[ 0.06445312 -0.04055786  0.04077148 ...  0.00722122 -0.09521484\n",
      "  0.05541992]\n",
      "torch.Size([1024])\n",
      "[0.96875    0.9604492  0.96728516 ... 0.97265625 0.96972656 0.94873047]\n",
      "torch.Size([1024])\n",
      "[ 0.39770508 -0.18859863  0.04302979 ... -0.04837036 -0.27368164\n",
      "  0.19995117]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02424622 -0.11035156  0.01853943 ... -0.06652832 -0.03025818\n",
      "  -0.03317261]\n",
      " [ 0.02836609 -0.01065826  0.09710693 ... -0.02371216  0.02754211\n",
      "   0.16577148]\n",
      " [ 0.00976562 -0.04147339  0.03237915 ...  0.0082016  -0.00090885\n",
      "  -0.00334167]\n",
      " ...\n",
      " [ 0.01663208  0.03082275  0.065979   ...  0.04425049 -0.05026245\n",
      "   0.10272217]\n",
      " [-0.11444092  0.06970215  0.06817627 ... -0.01424408 -0.07427979\n",
      "   0.06149292]\n",
      " [ 0.02986145 -0.06842041  0.02455139 ...  0.06268311 -0.00162125\n",
      "   0.00349045]]\n",
      "torch.Size([1024])\n",
      "[ 0.07312012  0.05065918 -0.06811523 ...  0.08276367  0.04483032\n",
      " -0.07666016]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00908661  0.06008911 -0.00575638 ... -0.03170776  0.01027679\n",
      "  -0.01556396]\n",
      " [-0.02046204 -0.08764648 -0.05673218 ...  0.05484009 -0.03811646\n",
      "   0.01800537]\n",
      " [-0.01339722  0.03872681  0.03540039 ...  0.00563049  0.0004499\n",
      "  -0.01132202]\n",
      " ...\n",
      " [-0.06268311 -0.06817627  0.08062744 ...  0.02104187  0.02406311\n",
      "   0.00179577]\n",
      " [ 0.04931641 -0.04608154  0.03567505 ...  0.04544067  0.03396606\n",
      "  -0.03274536]\n",
      " [ 0.06100464  0.04006958  0.05603027 ...  0.09088135  0.02363586\n",
      "  -0.0012722 ]]\n",
      "torch.Size([1024])\n",
      "[ 1.8186569e-03 -4.3773651e-04 -1.1653900e-03 ...  6.2823296e-05\n",
      "  4.4751167e-04  2.1400452e-03]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06408691  0.005867   -0.02523804 ... -0.00380325  0.05233765\n",
      "   0.02766418]\n",
      " [-0.01756287  0.03646851 -0.03509521 ... -0.01321411  0.03149414\n",
      "  -0.02093506]\n",
      " [ 0.00328636  0.0355835   0.00231171 ...  0.02549744  0.08569336\n",
      "  -0.01693726]\n",
      " ...\n",
      " [-0.00514221 -0.08349609 -0.03034973 ... -0.02200317  0.03683472\n",
      "   0.02461243]\n",
      " [-0.06268311  0.06707764 -0.01651001 ... -0.00474167  0.022995\n",
      "  -0.01283264]\n",
      " [ 0.03643799  0.0345459   0.01608276 ...  0.01050568  0.03213501\n",
      "  -0.01615906]]\n",
      "torch.Size([1024])\n",
      "[ 0.00918579  0.00175285  0.00619507 ...  0.00062847 -0.05532837\n",
      " -0.00101566]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02438354 -0.11035156  0.01821899 ... -0.06665039 -0.03097534\n",
      "  -0.03317261]\n",
      " [ 0.02896118 -0.01095581  0.097229   ... -0.02230835  0.02787781\n",
      "   0.16552734]\n",
      " [ 0.01103973 -0.04122925  0.03219604 ...  0.00706863 -0.00148678\n",
      "  -0.00320244]\n",
      " ...\n",
      " [ 0.01748657  0.03044128  0.06604004 ...  0.04437256 -0.05010986\n",
      "   0.10253906]\n",
      " [-0.11444092  0.06976318  0.06835938 ... -0.01380157 -0.0736084\n",
      "   0.06222534]\n",
      " [ 0.02828979 -0.06787109  0.02462769 ...  0.06173706 -0.00321388\n",
      "   0.0033989 ]]\n",
      "torch.Size([1024])\n",
      "[ 0.07287598  0.05133057 -0.06835938 ...  0.08282471  0.04571533\n",
      " -0.07763672]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02516174 -0.11114502  0.01863098 ... -0.06671143 -0.03091431\n",
      "  -0.03347778]\n",
      " [ 0.02947998 -0.01105499  0.0970459  ... -0.02305603  0.02597046\n",
      "   0.16625977]\n",
      " [ 0.00986481 -0.04150391  0.03149414 ...  0.00767136 -0.00087118\n",
      "  -0.00316238]\n",
      " ...\n",
      " [ 0.01712036  0.03137207  0.06567383 ...  0.04418945 -0.05001831\n",
      "   0.10327148]\n",
      " [-0.11444092  0.06945801  0.06774902 ... -0.01348114 -0.07421875\n",
      "   0.06298828]\n",
      " [ 0.02868652 -0.06811523  0.02423096 ...  0.06225586 -0.00175285\n",
      "   0.00299835]]\n",
      "torch.Size([1024])\n",
      "[ 0.07403564  0.0512085  -0.06793213 ...  0.08331299  0.04592896\n",
      " -0.07775879]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02514648 -0.11004639  0.01911926 ... -0.06646729 -0.02992249\n",
      "  -0.03393555]\n",
      " [ 0.02882385 -0.01098633  0.09661865 ... -0.0224762   0.02667236\n",
      "   0.1661377 ]\n",
      " [ 0.00998688 -0.04165649  0.03173828 ...  0.00793457 -0.00106049\n",
      "  -0.00338173]\n",
      " ...\n",
      " [ 0.01786804  0.03155518  0.06658936 ...  0.04333496 -0.05032349\n",
      "   0.10394287]\n",
      " [-0.11413574  0.07019043  0.06799316 ... -0.01316833 -0.07403564\n",
      "   0.06268311]\n",
      " [ 0.0287323  -0.06866455  0.02401733 ...  0.06185913 -0.00208855\n",
      "   0.00328064]]\n",
      "torch.Size([1024])\n",
      "[ 0.07342529  0.05096436 -0.06811523 ...  0.08398438  0.04528809\n",
      " -0.07720947]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.03533936 -0.01235962  0.0089798  ... -0.07092285 -0.02970886\n",
      "   0.01899719]\n",
      " [ 0.00142097 -0.05337524 -0.00276375 ... -0.07543945 -0.04000854\n",
      "   0.00746155]\n",
      " [ 0.04168701  0.01325989 -0.02430725 ... -0.03314209  0.01780701\n",
      "   0.03265381]\n",
      " ...\n",
      " [-0.00606537 -0.01660156  0.03512573 ...  0.02484131 -0.02485657\n",
      "   0.04525757]\n",
      " [-0.02200317  0.0094223   0.0079422  ... -0.04812622 -0.03924561\n",
      "  -0.05136108]\n",
      " [ 0.00708008 -0.02323914  0.04214478 ...  0.00617599 -0.04629517\n",
      "   0.02513123]]\n",
      "torch.Size([1024])\n",
      "[-0.21643066  0.03671265 -0.08111572 ... -0.07434082  0.23339844\n",
      "  0.07366943]\n",
      "torch.Size([1024])\n",
      "[0.9848633  1.         0.95703125 ... 0.9790039  0.9892578  0.9711914 ]\n",
      "torch.Size([1024])\n",
      "[-0.32836914  0.18151855 -0.03292847 ... -0.07214355  0.25048828\n",
      " -0.22839355]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.02961731 -0.03384399  0.00075817 ... -0.02316284  0.09851074\n",
      "   0.04934692]\n",
      " [-0.00585175 -0.06726074 -0.0324707  ...  0.03573608  0.00187016\n",
      "  -0.05328369]\n",
      " [-0.00430298  0.08282471  0.07495117 ...  0.01564026  0.01893616\n",
      "  -0.00815582]\n",
      " ...\n",
      " [-0.03625488 -0.04455566  0.12298584 ...  0.00025773  0.01272583\n",
      "  -0.03240967]\n",
      " [ 0.07366943 -0.05804443 -0.10388184 ... -0.03155518  0.02394104\n",
      "  -0.0826416 ]\n",
      " [ 0.00161648  0.074646    0.09509277 ... -0.01846313 -0.02583313\n",
      "   0.03065491]]\n",
      "torch.Size([4096])\n",
      "[ 0.09466553 -0.05108643 -0.05447388 ... -0.08642578 -0.08538818\n",
      " -0.08514404]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.0241394  -0.01829529  0.0625     ... -0.02082825 -0.09002686\n",
      "   0.05108643]\n",
      " [ 0.04595947 -0.01686096 -0.01506805 ... -0.03256226 -0.00580597\n",
      "  -0.04486084]\n",
      " [ 0.04156494  0.03451538  0.06536865 ... -0.02484131 -0.05194092\n",
      "   0.09588623]\n",
      " ...\n",
      " [ 0.04251099 -0.05761719 -0.07373047 ... -0.0383606   0.02337646\n",
      "   0.03436279]\n",
      " [ 0.01031494  0.08325195  0.10784912 ...  0.06445312 -0.04199219\n",
      "  -0.0218811 ]\n",
      " [-0.06143188  0.07226562  0.00406265 ... -0.03427124  0.06884766\n",
      "   0.03939819]]\n",
      "torch.Size([1024])\n",
      "[ 0.0109024   0.00528717  0.06744385 ...  0.01170349 -0.0475769\n",
      "  0.01473236]\n",
      "torch.Size([1024])\n",
      "[0.9609375  0.9941406  0.9404297  ... 0.97021484 0.9682617  0.93652344]\n",
      "torch.Size([1024])\n",
      "[ 0.18969727 -0.19335938 -0.04953003 ... -0.01381683 -0.27246094\n",
      "  0.15893555]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00029254 -0.04794312  0.04309082 ... -0.02885437 -0.06762695\n",
      "  -0.01528931]\n",
      " [-0.08227539 -0.08978271  0.03546143 ... -0.02301025  0.00292969\n",
      "   0.01337433]\n",
      " [-0.02043152 -0.00785065 -0.03933716 ... -0.03509521 -0.01552582\n",
      "  -0.0209198 ]\n",
      " ...\n",
      " [ 0.02186584 -0.01641846 -0.0112915  ... -0.03555298  0.08074951\n",
      "  -0.07012939]\n",
      " [ 0.03149414 -0.09545898 -0.05004883 ... -0.04324341  0.00023532\n",
      "   0.01296234]\n",
      " [ 0.02151489 -0.02320862 -0.06872559 ...  0.07470703 -0.00579834\n",
      "   0.0456543 ]]\n",
      "torch.Size([1024])\n",
      "[-0.06027222  0.12719727  0.11340332 ... -0.15270996  0.06506348\n",
      " -0.16491699]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01306915  0.13781738  0.0401001  ...  0.03469849  0.01831055\n",
      "  -0.05456543]\n",
      " [ 0.00033307  0.01579285 -0.01766968 ... -0.03152466 -0.03729248\n",
      "   0.04241943]\n",
      " [ 0.06652832 -0.00953674  0.00575638 ... -0.05279541  0.02592468\n",
      "  -0.04473877]\n",
      " ...\n",
      " [-0.00247765 -0.03549194 -0.03311157 ... -0.00190163 -0.05291748\n",
      "  -0.06628418]\n",
      " [-0.05664062 -0.03521729  0.03271484 ...  0.00112534 -0.05032349\n",
      "   0.01951599]\n",
      " [ 0.03356934  0.01287079 -0.0254364  ...  0.06518555  0.00982666\n",
      "   0.05032349]]\n",
      "torch.Size([1024])\n",
      "[-0.00056839 -0.00320816 -0.00154877 ...  0.00248528 -0.00064135\n",
      " -0.00027657]\n",
      "torch.Size([1024, 1024])\n",
      "[[-3.4370422e-03  4.9163818e-02  2.2186279e-02 ...  2.5100708e-02\n",
      "   2.7755737e-02 -1.3780594e-03]\n",
      " [-3.8623810e-05  8.9843750e-02 -2.1041870e-02 ... -4.3487549e-03\n",
      "  -3.1524658e-02 -6.6528320e-03]\n",
      " [ 1.9546509e-02  4.7271729e-02  3.5247803e-03 ...  3.5003662e-02\n",
      "   2.9113770e-02 -2.3574829e-02]\n",
      " ...\n",
      " [-1.2527466e-02  2.6397705e-02 -1.1474609e-02 ... -3.8879395e-02\n",
      "  -2.4734497e-02  4.0863037e-02]\n",
      " [ 6.2347412e-02  3.8513184e-02 -4.0588379e-02 ... -2.2827148e-02\n",
      "   6.5612793e-02  2.9357910e-02]\n",
      " [-2.3437500e-02 -1.0963440e-02  1.7681122e-03 ... -1.1505127e-02\n",
      "   1.5342712e-02  5.3466797e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.02934265  0.01486969  0.00894928 ... -0.00258636  0.01081848\n",
      " -0.0051918 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00047064 -0.04815674  0.0430603  ... -0.02900696 -0.06915283\n",
      "  -0.01512146]\n",
      " [-0.08251953 -0.09057617  0.03610229 ... -0.02270508  0.00410461\n",
      "   0.01448059]\n",
      " [-0.02084351 -0.00719452 -0.03875732 ... -0.03442383 -0.01403809\n",
      "  -0.02087402]\n",
      " ...\n",
      " [ 0.02114868 -0.01689148 -0.01197052 ... -0.03475952  0.0814209\n",
      "  -0.06945801]\n",
      " [ 0.03186035 -0.09484863 -0.05023193 ... -0.04312134 -0.00026393\n",
      "   0.01186371]\n",
      " [ 0.02114868 -0.02410889 -0.06884766 ...  0.07550049 -0.00557709\n",
      "   0.0461731 ]]\n",
      "torch.Size([1024])\n",
      "[-0.05993652  0.12658691  0.11248779 ... -0.15258789  0.06524658\n",
      " -0.16467285]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00087595 -0.04724121  0.04345703 ... -0.02841187 -0.06762695\n",
      "  -0.0150528 ]\n",
      " [-0.08154297 -0.09033203  0.03622437 ... -0.02412415  0.0045166\n",
      "   0.01346588]\n",
      " [-0.02084351 -0.00757217 -0.03799438 ... -0.03479004 -0.01534271\n",
      "  -0.02151489]\n",
      " ...\n",
      " [ 0.02230835 -0.01585388 -0.0118866  ... -0.03533936  0.08148193\n",
      "  -0.06951904]\n",
      " [ 0.03179932 -0.0949707  -0.04977417 ... -0.04299927  0.00089693\n",
      "   0.01208496]\n",
      " [ 0.02177429 -0.02398682 -0.06903076 ...  0.07519531 -0.00586319\n",
      "   0.04608154]]\n",
      "torch.Size([1024])\n",
      "[-0.0607605   0.12695312  0.11309814 ... -0.15283203  0.06494141\n",
      " -0.16467285]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00035858 -0.04800415  0.04318237 ... -0.02767944 -0.06781006\n",
      "  -0.01508331]\n",
      " [-0.08190918 -0.09088135  0.03567505 ... -0.02359009  0.00362968\n",
      "   0.01410675]\n",
      " [-0.01976013 -0.00791168 -0.03863525 ... -0.03518677 -0.01537323\n",
      "  -0.02072144]\n",
      " ...\n",
      " [ 0.02241516 -0.01628113 -0.01130676 ... -0.03585815  0.08099365\n",
      "  -0.0690918 ]\n",
      " [ 0.03173828 -0.09454346 -0.05041504 ... -0.04248047  0.00048661\n",
      "   0.01157379]\n",
      " [ 0.02160645 -0.02397156 -0.0682373  ...  0.07427979 -0.00576782\n",
      "   0.04629517]]\n",
      "torch.Size([1024])\n",
      "[-0.06079102  0.12695312  0.11352539 ... -0.15209961  0.06469727\n",
      " -0.16430664]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01337433 -0.01846313  0.0227356  ... -0.00416565 -0.01051331\n",
      "   0.02148438]\n",
      " [ 0.00532913  0.01609802 -0.01507568 ... -0.0475769  -0.01202393\n",
      "  -0.0025692 ]\n",
      " [ 0.00634003  0.04095459 -0.06903076 ... -0.01333618 -0.01316071\n",
      "  -0.01345825]\n",
      " ...\n",
      " [-0.03161621 -0.00732803  0.05032349 ... -0.00461578  0.01126862\n",
      "  -0.01072693]\n",
      " [-0.07879639  0.00223541  0.00444794 ...  0.04428101  0.02073669\n",
      "  -0.0085907 ]\n",
      " [ 0.05648804  0.04840088  0.00163269 ...  0.00451279  0.05648804\n",
      "   0.02700806]]\n",
      "torch.Size([1024])\n",
      "[ 0.06121826 -0.05752563  0.0322876  ...  0.08178711 -0.03805542\n",
      "  0.07501221]\n",
      "torch.Size([1024])\n",
      "[0.984375  0.984375  0.9838867 ... 0.9638672 0.9560547 0.9716797]\n",
      "torch.Size([1024])\n",
      "[-0.09368896 -0.00354195 -0.3413086  ... -0.02697754 -0.07067871\n",
      "  0.21704102]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 2.16369629e-02  8.62426758e-02  6.92138672e-02 ... -4.69055176e-02\n",
      "  -1.32369995e-02 -4.23278809e-02]\n",
      " [-2.51464844e-02 -6.81762695e-02  9.27124023e-02 ... -7.45849609e-02\n",
      "   5.35278320e-02 -2.31170654e-03]\n",
      " [-7.16552734e-02  4.03976440e-03  9.17968750e-02 ...  1.45568848e-02\n",
      "   2.18658447e-02  2.68554688e-03]\n",
      " ...\n",
      " [-3.84216309e-02 -1.55487061e-02  5.83267212e-03 ...  9.18579102e-03\n",
      "  -1.15585327e-03  1.90734863e-02]\n",
      " [-6.42089844e-02  1.24588013e-02 -1.45874023e-02 ... -1.80721283e-03\n",
      "   3.43017578e-02 -9.19799805e-02]\n",
      " [-1.72853470e-05  1.86309814e-02  1.57470703e-02 ... -1.38702393e-02\n",
      "  -5.05371094e-02 -1.00891113e-01]]\n",
      "torch.Size([4096])\n",
      "[-0.02307129 -0.07983398 -0.06970215 ...  0.05947876 -0.08599854\n",
      " -0.09014893]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.02279663  0.08483887  0.01730347 ... -0.03848267 -0.10614014\n",
      "   0.00263977]\n",
      " [-0.00318718  0.01858521 -0.06109619 ...  0.04818726 -0.02893066\n",
      "  -0.0112915 ]\n",
      " [ 0.05227661 -0.05661011  0.05844116 ...  0.01107025 -0.04824829\n",
      "  -0.07598877]\n",
      " ...\n",
      " [ 0.00221062 -0.04544067  0.06610107 ...  0.01366425  0.10467529\n",
      "  -0.00168705]\n",
      " [ 0.04812622 -0.00901031 -0.03071594 ...  0.01106262 -0.09381104\n",
      "  -0.00971985]\n",
      " [ 0.03015137 -0.05050659 -0.02290344 ... -0.04071045  0.01360321\n",
      "   0.00240898]]\n",
      "torch.Size([1024])\n",
      "[-0.00809479 -0.04272461  0.01171112 ...  0.03105164  0.01490021\n",
      "  0.04556274]\n",
      "torch.Size([1024])\n",
      "[0.9658203  0.96777344 0.95166016 ... 0.9760742  0.97753906 0.9584961 ]\n",
      "torch.Size([1024])\n",
      "[-0.03240967 -0.10876465  0.20812988 ... -0.04971313 -0.02713013\n",
      " -0.20300293]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06921387  0.01133728  0.03631592 ...  0.02511597  0.05111694\n",
      "  -0.01313019]\n",
      " [-0.01921082 -0.07873535 -0.04125977 ...  0.03643799 -0.01439667\n",
      "   0.0317688 ]\n",
      " [-0.02035522 -0.01655579  0.08044434 ...  0.03408813 -0.01741028\n",
      "   0.00568008]\n",
      " ...\n",
      " [-0.05728149 -0.0113678  -0.01029205 ...  0.03961182  0.08953857\n",
      "  -0.01564026]\n",
      " [ 0.0670166  -0.03198242  0.04144287 ... -0.08959961  0.02297974\n",
      "  -0.0345459 ]\n",
      " [ 0.03268433  0.06445312 -0.02198792 ... -0.04379272 -0.0319519\n",
      "   0.02166748]]\n",
      "torch.Size([1024])\n",
      "[-0.02522278 -0.05148315  0.03155518 ...  0.01299286  0.11737061\n",
      " -0.0814209 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.13476562 -0.0401001  -0.00137711 ...  0.02178955  0.05084229\n",
      "  -0.02754211]\n",
      " [ 0.02676392  0.09942627  0.09069824 ... -0.02391052  0.08258057\n",
      "  -0.04400635]\n",
      " [ 0.00500107 -0.04098511  0.09155273 ... -0.02142334  0.01705933\n",
      "  -0.02130127]\n",
      " ...\n",
      " [-0.02503967 -0.00436783 -0.00508499 ...  0.07141113 -0.06268311\n",
      "  -0.03985596]\n",
      " [ 0.00439072 -0.02392578 -0.00449753 ...  0.03875732 -0.03123474\n",
      "   0.00587082]\n",
      " [ 0.02960205  0.01164246  0.02302551 ...  0.0174408  -0.02845764\n",
      "  -0.01818848]]\n",
      "torch.Size([1024])\n",
      "[-0.00050783  0.00151157  0.00058031 ...  0.00031233 -0.00209427\n",
      "  0.00011992]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01061249 -0.02958679 -0.07305908 ...  0.0305481   0.09521484\n",
      "   0.0223999 ]\n",
      " [-0.01641846  0.03921509  0.04595947 ... -0.029953    0.0100708\n",
      "  -0.00678253]\n",
      " [ 0.04025269  0.0390625  -0.06982422 ... -0.05038452  0.02740479\n",
      "   0.02023315]\n",
      " ...\n",
      " [ 0.07092285  0.00270653  0.01218414 ...  0.01965332  0.03240967\n",
      "   0.04455566]\n",
      " [-0.02401733  0.04931641 -0.03393555 ... -0.00354958 -0.10510254\n",
      "  -0.01109314]\n",
      " [ 0.02732849 -0.00938416 -0.04095459 ... -0.02992249 -0.00139141\n",
      "  -0.04931641]]\n",
      "torch.Size([1024])\n",
      "[-0.01893616 -0.00915527 -0.00869751 ...  0.00563812  0.00590134\n",
      " -0.00089502]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.0703125   0.00981903  0.03643799 ...  0.02604675  0.05175781\n",
      "  -0.01264191]\n",
      " [-0.0193634  -0.07879639 -0.04119873 ...  0.03659058 -0.01416779\n",
      "   0.03106689]\n",
      " [-0.01916504 -0.01690674  0.08026123 ...  0.03329468 -0.01756287\n",
      "   0.00629044]\n",
      " ...\n",
      " [-0.05804443 -0.01105499 -0.01009369 ...  0.03964233  0.08984375\n",
      "  -0.01568604]\n",
      " [ 0.06628418 -0.03311157  0.0411377  ... -0.08935547  0.02282715\n",
      "  -0.03469849]\n",
      " [ 0.03225708  0.06384277 -0.0221405  ... -0.04397583 -0.03222656\n",
      "   0.02160645]]\n",
      "torch.Size([1024])\n",
      "[-0.02519226 -0.05184937  0.03173828 ...  0.01384735  0.11706543\n",
      " -0.08050537]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06988525  0.01116943  0.03689575 ...  0.02577209  0.05136108\n",
      "  -0.01312256]\n",
      " [-0.01919556 -0.0793457  -0.04168701 ...  0.03695679 -0.01434326\n",
      "   0.03179932]\n",
      " [-0.02001953 -0.01643372  0.08093262 ...  0.03375244 -0.01742554\n",
      "   0.00546646]\n",
      " ...\n",
      " [-0.05700684 -0.01073456 -0.01039886 ...  0.03955078  0.09008789\n",
      "  -0.01626587]\n",
      " [ 0.06622314 -0.03302002  0.0413208  ... -0.08947754  0.02310181\n",
      "  -0.03509521]\n",
      " [ 0.0324707   0.06390381 -0.02288818 ... -0.04388428 -0.03289795\n",
      "   0.02183533]]\n",
      "torch.Size([1024])\n",
      "[-0.02552795 -0.05172729  0.03134155 ...  0.01211548  0.11706543\n",
      " -0.08117676]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06921387  0.01116943  0.03726196 ...  0.02532959  0.05151367\n",
      "  -0.01309967]\n",
      " [-0.01853943 -0.0791626  -0.04116821 ...  0.0368042  -0.01435089\n",
      "   0.03173828]\n",
      " [-0.01976013 -0.01673889  0.08074951 ...  0.03344727 -0.0173645\n",
      "   0.00563049]\n",
      " ...\n",
      " [-0.05740356 -0.01091766 -0.01005554 ...  0.03942871  0.08978271\n",
      "  -0.01531219]\n",
      " [ 0.06671143 -0.03283691  0.0418396  ... -0.09014893  0.02325439\n",
      "  -0.03482056]\n",
      " [ 0.03167725  0.06329346 -0.02206421 ... -0.04330444 -0.03216553\n",
      "   0.0219574 ]]\n",
      "torch.Size([1024])\n",
      "[-0.02568054 -0.05197144  0.03137207 ...  0.01322174  0.11730957\n",
      " -0.08093262]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00108528  0.002491    0.03375244 ...  0.00059986 -0.02708435\n",
      "  -0.02897644]\n",
      " [ 0.01083374 -0.00769424  0.04135132 ...  0.01597595 -0.02030945\n",
      "   0.01400757]\n",
      " [-0.08123779  0.01180267 -0.00595093 ... -0.01303101  0.05657959\n",
      "  -0.00457001]\n",
      " ...\n",
      " [ 0.02320862 -0.00097656 -0.02127075 ...  0.02105713 -0.02932739\n",
      "   0.01626587]\n",
      " [ 0.01152802  0.04428101 -0.00026345 ... -0.00778198 -0.01078796\n",
      "  -0.0085144 ]\n",
      " [-0.02783203 -0.01489258  0.01785278 ... -0.00845337  0.01739502\n",
      "   0.03527832]]\n",
      "torch.Size([1024])\n",
      "[ 0.04159546 -0.01725769 -0.02703857 ... -0.02233887  0.03390503\n",
      " -0.01948547]\n",
      "torch.Size([1024])\n",
      "[0.9902344  0.9794922  0.9770508  ... 0.98876953 0.97802734 0.96435547]\n",
      "torch.Size([1024])\n",
      "[-0.17944336 -0.11749268 -0.3017578  ... -0.04476929  0.1126709\n",
      "  0.03662109]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.01108551  0.03988647 -0.03268433 ... -0.05004883 -0.02409363\n",
      "  -0.03338623]\n",
      " [ 0.0362854   0.03302002  0.01631165 ...  0.02636719 -0.04504395\n",
      "  -0.01597595]\n",
      " [ 0.03399658 -0.06402588 -0.01490784 ...  0.06469727 -0.18249512\n",
      "   0.00705338]\n",
      " ...\n",
      " [-0.02937317 -0.03302002 -0.03668213 ...  0.03289795 -0.02593994\n",
      "  -0.05349731]\n",
      " [ 0.0302124  -0.05706787 -0.03640747 ... -0.00577545  0.01707458\n",
      "  -0.02738953]\n",
      " [ 0.0003624   0.0036335  -0.04800415 ...  0.01136017 -0.06512451\n",
      "  -0.04370117]]\n",
      "torch.Size([4096])\n",
      "[-0.09118652 -0.10986328 -0.05679321 ... -0.1026001  -0.01777649\n",
      " -0.08587646]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.01922607 -0.02853394 -0.02279663 ...  0.0219574  -0.06854248\n",
      "  -0.00878906]\n",
      " [ 0.02333069 -0.00932312 -0.02462769 ... -0.00550461 -0.04840088\n",
      "  -0.06921387]\n",
      " [-0.07653809 -0.07800293  0.02053833 ...  0.05477905 -0.02857971\n",
      "  -0.00310135]\n",
      " ...\n",
      " [ 0.00696945  0.02659607  0.07476807 ... -0.05410767 -0.07330322\n",
      "   0.00163364]\n",
      " [-0.09490967 -0.07800293 -0.0581665  ... -0.02073669 -0.00686264\n",
      "  -0.10986328]\n",
      " [ 0.13769531  0.05209351 -0.06167603 ...  0.0496521  -0.04193115\n",
      "   0.02949524]]\n",
      "torch.Size([1024])\n",
      "[-0.08721924  0.03363037  0.06463623 ...  0.04214478 -0.08178711\n",
      "  0.27026367]\n",
      "torch.Size([1024])\n",
      "[0.97509766 0.98876953 0.96728516 ... 0.9711914  0.9663086  0.9472656 ]\n",
      "torch.Size([1024])\n",
      "[ 0.01330566 -0.00665665  0.19702148 ... -0.02438354 -0.11767578\n",
      " -0.08148193]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00478363 -0.01156616 -0.05789185 ... -0.01004791 -0.03515625\n",
      "  -0.00832367]\n",
      " [-0.00429535  0.00229645  0.04574585 ... -0.05978394 -0.01396179\n",
      "   0.06896973]\n",
      " [-0.08325195  0.00494766  0.01184082 ... -0.0637207  -0.01239777\n",
      "   0.02700806]\n",
      " ...\n",
      " [ 0.01585388  0.00459671 -0.01277161 ...  0.0218811   0.00281334\n",
      "   0.00159264]\n",
      " [ 0.01824951 -0.0272522   0.03945923 ... -0.01051331 -0.02589417\n",
      "   0.01715088]\n",
      " [ 0.03417969 -0.10284424 -0.01727295 ... -0.03945923 -0.03613281\n",
      "  -0.14465332]]\n",
      "torch.Size([1024])\n",
      "[ 0.21105957  0.00433731  0.22802734 ... -0.25341797 -0.1899414\n",
      "  0.20019531]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01719666 -0.07495117 -0.04782104 ... -0.00660706 -0.04321289\n",
      "   0.00797272]\n",
      " [-0.05352783 -0.01225281  0.02082825 ...  0.00514603 -0.02107239\n",
      "   0.00933075]\n",
      " [ 0.01361084  0.02903748  0.03848267 ...  0.03283691  0.06427002\n",
      "  -0.00659561]\n",
      " ...\n",
      " [ 0.03726196  0.07824707  0.03707886 ...  0.05465698  0.00944519\n",
      "   0.08947754]\n",
      " [-0.01561737 -0.02410889 -0.0284729  ... -0.020401   -0.0425415\n",
      "   0.06414795]\n",
      " [ 0.00367546  0.02723694 -0.00622559 ...  0.02326965 -0.03265381\n",
      "   0.02153015]]\n",
      "torch.Size([1024])\n",
      "[-0.0003612  -0.00060129  0.00020075 ... -0.00051022  0.00031853\n",
      " -0.00014853]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.0096817  -0.00054741  0.01153564 ...  0.01882935  0.00332832\n",
      "   0.04815674]\n",
      " [ 0.02127075  0.05960083 -0.02120972 ...  0.06298828 -0.01780701\n",
      "  -0.07385254]\n",
      " [ 0.03634644  0.01325226  0.02275085 ...  0.04968262 -0.03652954\n",
      "   0.06414795]\n",
      " ...\n",
      " [ 0.01008606  0.06689453  0.02180481 ...  0.04510498 -0.00218582\n",
      "   0.02479553]\n",
      " [ 0.02519226  0.0063591   0.01643372 ...  0.0271759  -0.00336456\n",
      "   0.06262207]\n",
      " [ 0.00950623 -0.10205078 -0.00052166 ... -0.04214478  0.03414917\n",
      "   0.00925446]]\n",
      "torch.Size([1024])\n",
      "[-0.00994873 -0.00353432  0.00783539 ... -0.00686646  0.00270653\n",
      " -0.00146866]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00462341 -0.01142883 -0.05740356 ... -0.01051331 -0.03485107\n",
      "  -0.00744247]\n",
      " [-0.00371361  0.0027771   0.0458374  ... -0.05981445 -0.01408386\n",
      "   0.06854248]\n",
      " [-0.08312988  0.00452042  0.01228333 ... -0.06384277 -0.01271057\n",
      "   0.02714539]\n",
      " ...\n",
      " [ 0.01576233  0.00510406 -0.01322937 ...  0.02197266  0.00337029\n",
      "   0.00252914]\n",
      " [ 0.0186615  -0.02758789  0.0390625  ... -0.01002502 -0.02639771\n",
      "   0.0173645 ]\n",
      " [ 0.03515625 -0.10229492 -0.01652527 ... -0.03945923 -0.03543091\n",
      "  -0.14453125]]\n",
      "torch.Size([1024])\n",
      "[ 0.21203613  0.00374031  0.22851562 ... -0.25390625 -0.18920898\n",
      "  0.20007324]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00490189 -0.01187897 -0.05770874 ... -0.01004791 -0.03512573\n",
      "  -0.00863647]\n",
      " [-0.00312614  0.00347519  0.04574585 ... -0.05996704 -0.01428986\n",
      "   0.06951904]\n",
      " [-0.08355713  0.00542068  0.01239014 ... -0.06396484 -0.01260376\n",
      "   0.02633667]\n",
      " ...\n",
      " [ 0.01558685  0.0044632  -0.0125351  ...  0.02246094  0.00343895\n",
      "   0.00197601]\n",
      " [ 0.01850891 -0.02694702  0.03848267 ... -0.01007843 -0.02670288\n",
      "   0.01731873]\n",
      " [ 0.03451538 -0.10223389 -0.01747131 ... -0.03903198 -0.03515625\n",
      "  -0.14489746]]\n",
      "torch.Size([1024])\n",
      "[ 0.21069336  0.00428009  0.22753906 ... -0.25390625 -0.18920898\n",
      "  0.20043945]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00462723 -0.0116806  -0.05804443 ... -0.0104599  -0.03509521\n",
      "  -0.00843811]\n",
      " [-0.00353432  0.00283623  0.04611206 ... -0.05984497 -0.01454163\n",
      "   0.06915283]\n",
      " [-0.08343506  0.00466537  0.01193237 ... -0.06347656 -0.01247406\n",
      "   0.02630615]\n",
      " ...\n",
      " [ 0.01540375  0.00469208 -0.01304626 ...  0.02204895  0.00329399\n",
      "   0.00199127]\n",
      " [ 0.01837158 -0.02767944  0.0390625  ... -0.00997162 -0.02607727\n",
      "   0.01715088]\n",
      " [ 0.03448486 -0.10235596 -0.01734924 ... -0.03912354 -0.03546143\n",
      "  -0.14453125]]\n",
      "torch.Size([1024])\n",
      "[ 0.21069336  0.00458145  0.22729492 ... -0.2541504  -0.18945312\n",
      "  0.20043945]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.03549194 -0.07226562 -0.01889038 ... -0.00745773 -0.01055908\n",
      "   0.06573486]\n",
      " [-0.04394531 -0.0137558  -0.00805664 ...  0.04794312  0.02964783\n",
      "   0.00627518]\n",
      " [ 0.00769424  0.00930786 -0.00970459 ... -0.04095459  0.04525757\n",
      "  -0.01292419]\n",
      " ...\n",
      " [ 0.00561142  0.00782776  0.0048027  ...  0.01018524  0.00301361\n",
      "  -0.01561737]\n",
      " [-0.00101852  0.01430511 -0.02867126 ...  0.05249023  0.00535965\n",
      "  -0.0255127 ]\n",
      " [ 0.01712036  0.04293823 -0.01403046 ... -0.01039886 -0.02459717\n",
      "   0.0064888 ]]\n",
      "torch.Size([1024])\n",
      "[-0.00680542 -0.01159668 -0.00839996 ...  0.01708984 -0.06427002\n",
      " -0.00337982]\n",
      "torch.Size([1024])\n",
      "[0.99121094 0.9941406  0.9873047  ... 0.98583984 0.99658203 0.95751953]\n",
      "torch.Size([1024])\n",
      "[-0.16711426  0.0793457  -0.296875   ...  0.06152344  0.01739502\n",
      "  0.20629883]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.00234032  0.05465698 -0.02934265 ... -0.07513428  0.05380249\n",
      "   0.04141235]\n",
      " [-0.01412964 -0.01657104 -0.00673294 ... -0.01641846 -0.01756287\n",
      "  -0.0871582 ]\n",
      " [-0.03118896  0.01158142  0.04974365 ... -0.09124756  0.02044678\n",
      "  -0.04611206]\n",
      " ...\n",
      " [-0.05728149 -0.02264404  0.06536865 ...  0.12347412  0.0428772\n",
      "  -0.0715332 ]\n",
      " [-0.00492477 -0.07983398 -0.0869751  ... -0.05368042 -0.02650452\n",
      "   0.06060791]\n",
      " [-0.03643799 -0.02508545  0.00614166 ...  0.02368164  0.03552246\n",
      "  -0.04434204]]\n",
      "torch.Size([4096])\n",
      "[-0.09082031 -0.07928467 -0.07226562 ... -0.07043457 -0.0524292\n",
      " -0.0552063 ]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.01927185  0.06039429  0.00758743 ...  0.03640747 -0.0122757\n",
      "  -0.03030396]\n",
      " [-0.04562378 -0.02890015 -0.05432129 ...  0.03417969 -0.0569458\n",
      "   0.00274277]\n",
      " [ 0.01615906  0.08294678  0.10424805 ...  0.00239754  0.05307007\n",
      "  -0.02981567]\n",
      " ...\n",
      " [-0.0369873  -0.04620361 -0.06549072 ...  0.13769531 -0.06628418\n",
      "   0.01408386]\n",
      " [ 0.03601074 -0.02424622  0.03079224 ...  0.10284424 -0.01707458\n",
      "   0.01158142]\n",
      " [ 0.00485611 -0.0453186  -0.0970459  ... -0.03900146  0.06365967\n",
      "  -0.0401001 ]]\n",
      "torch.Size([1024])\n",
      "[-0.08361816 -0.01690674  0.13977051 ...  0.01070404 -0.09875488\n",
      "  0.16442871]\n",
      "torch.Size([1024])\n",
      "[0.97216797 0.9921875  0.9746094  ... 0.9765625  0.99560547 0.96484375]\n",
      "torch.Size([1024])\n",
      "[ 0.0116806  -0.10058594  0.27954102 ... -0.10516357 -0.10046387\n",
      " -0.16564941]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 6.9335938e-02 -1.7318726e-02  2.5299072e-02 ... -1.4160156e-02\n",
      "   2.2125244e-02  3.6163330e-02]\n",
      " [ 5.4534912e-02 -1.0047913e-02  6.8130493e-03 ...  1.9931793e-03\n",
      "   4.3853760e-02 -1.3781738e-01]\n",
      " [-5.3283691e-02 -6.5002441e-03 -1.8432617e-02 ...  2.3330688e-02\n",
      "  -4.6936035e-02 -5.9175491e-04]\n",
      " ...\n",
      " [-1.6708374e-02 -1.9165039e-02 -7.5195312e-02 ... -3.3081055e-02\n",
      "   1.2832642e-02  9.7930431e-05]\n",
      " [ 4.6752930e-02 -8.4045410e-02  2.2796631e-02 ...  3.2623291e-02\n",
      "   2.3681641e-02 -3.1311035e-02]\n",
      " [-1.1512756e-02  2.3529053e-02  5.9814453e-02 ...  1.0101318e-02\n",
      "   6.6162109e-02  5.5450439e-02]]\n",
      "torch.Size([1024])\n",
      "[ 0.03161621 -0.02786255 -0.02372742 ...  0.02857971  0.12670898\n",
      " -0.13439941]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 1.6450882e-03  6.4025879e-02 -7.0533752e-03 ... -3.9031982e-02\n",
      "   4.5166016e-03 -1.3633728e-02]\n",
      " [ 3.9093018e-02 -1.9409180e-02 -3.4881592e-02 ...  3.9184570e-02\n",
      "   2.8961182e-02 -3.7811279e-02]\n",
      " [ 3.3538818e-02 -1.5052795e-02 -3.2196045e-02 ... -1.0949707e-01\n",
      "   4.4158936e-02  3.1494141e-02]\n",
      " ...\n",
      " [ 2.9617310e-02 -5.1641464e-04 -5.7983398e-03 ...  2.4765015e-02\n",
      "   6.5551758e-02  4.0740967e-02]\n",
      " [ 1.7715454e-02  5.5847168e-03 -1.2016296e-02 ...  1.3282776e-02\n",
      "  -1.6815186e-02  8.7203979e-03]\n",
      " [-7.2509766e-02  3.5762787e-07  5.9722900e-02 ... -5.2886963e-02\n",
      "   1.7257690e-02  3.1490326e-03]]\n",
      "torch.Size([1024])\n",
      "[ 0.00173187 -0.00076008  0.0011673  ...  0.00070572  0.00370407\n",
      " -0.00178909]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01940918  0.05358887  0.01395416 ... -0.00143433 -0.00585938\n",
      "   0.04800415]\n",
      " [-0.06634521 -0.06494141 -0.01172638 ...  0.02323914 -0.04150391\n",
      "  -0.06054688]\n",
      " [ 0.03823853 -0.04315186 -0.02946472 ... -0.00109005 -0.01293945\n",
      "   0.03219604]\n",
      " ...\n",
      " [ 0.03057861 -0.02351379 -0.01077271 ... -0.02949524 -0.00843811\n",
      "  -0.03149414]\n",
      " [ 0.05688477  0.02932739 -0.09655762 ...  0.0110321  -0.00842285\n",
      "   0.0479126 ]\n",
      " [-0.03378296  0.06915283 -0.02391052 ... -0.02069092 -0.02027893\n",
      "   0.02362061]]\n",
      "torch.Size([1024])\n",
      "[ 0.00257492 -0.00547409 -0.00204086 ...  0.00862122 -0.00524902\n",
      " -0.00942993]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06976318 -0.01637268  0.02557373 ... -0.01457214  0.0224762\n",
      "   0.03668213]\n",
      " [ 0.05413818 -0.00957489  0.00666046 ...  0.00079393  0.04342651\n",
      "  -0.13793945]\n",
      " [-0.05395508 -0.00601578 -0.01823425 ...  0.02278137 -0.04760742\n",
      "  -0.00087118]\n",
      " ...\n",
      " [-0.01611328 -0.01844788 -0.07440186 ... -0.03381348  0.01286316\n",
      "   0.00018477]\n",
      " [ 0.04602051 -0.08520508  0.02203369 ...  0.03308105  0.02371216\n",
      "  -0.03237915]\n",
      " [-0.01228333  0.02357483  0.05911255 ...  0.00963593  0.0657959\n",
      "   0.05532837]]\n",
      "torch.Size([1024])\n",
      "[ 0.03207397 -0.02850342 -0.02427673 ...  0.02870178  0.12646484\n",
      " -0.13439941]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06976318 -0.01673889  0.02467346 ... -0.01404572  0.02278137\n",
      "   0.03530884]\n",
      " [ 0.05429077 -0.00930023  0.00800323 ...  0.00038719  0.04290771\n",
      "  -0.13671875]\n",
      " [-0.0536499  -0.00621033 -0.0196228  ...  0.02342224 -0.04727173\n",
      "  -0.00235367]\n",
      " ...\n",
      " [-0.01693726 -0.01924133 -0.07519531 ... -0.03271484  0.01268005\n",
      "  -0.00071526]\n",
      " [ 0.04696655 -0.08435059  0.02268982 ...  0.03268433  0.0239563\n",
      "  -0.03204346]\n",
      " [-0.01164246  0.02420044  0.0592041  ...  0.00959778  0.06665039\n",
      "   0.05508423]]\n",
      "torch.Size([1024])\n",
      "[ 0.03033447 -0.02653503 -0.02586365 ...  0.02832031  0.12658691\n",
      " -0.13415527]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 6.9213867e-02 -1.5823364e-02  2.6535034e-02 ... -1.5586853e-02\n",
      "   2.2232056e-02  3.7933350e-02]\n",
      " [ 5.5023193e-02 -9.9258423e-03  6.1759949e-03 ...  2.0332336e-03\n",
      "   4.3731689e-02 -1.3891602e-01]\n",
      " [-5.4260254e-02 -5.6838989e-03 -1.7562866e-02 ...  2.1820068e-02\n",
      "  -4.8034668e-02 -4.6908855e-05]\n",
      " ...\n",
      " [-1.6326904e-02 -1.8692017e-02 -7.4951172e-02 ... -3.2775879e-02\n",
      "   1.3389587e-02 -1.2636185e-03]\n",
      " [ 4.6264648e-02 -8.5083008e-02  2.1911621e-02 ...  3.2836914e-02\n",
      "   2.3361206e-02 -3.1341553e-02]\n",
      " [-1.2390137e-02  2.3590088e-02  5.8898926e-02 ...  9.2926025e-03\n",
      "   6.6223145e-02  5.5603027e-02]]\n",
      "torch.Size([1024])\n",
      "[ 0.03295898 -0.02894592 -0.02348328 ...  0.02844238  0.12609863\n",
      " -0.13415527]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0294342  -0.0096283  -0.01861572 ...  0.02241516  0.02497864\n",
      "  -0.02378845]\n",
      " [-0.09954834  0.02639771  0.00841522 ... -0.0531311  -0.02003479\n",
      "   0.04507446]\n",
      " [ 0.0625     -0.00748062  0.04104614 ... -0.0177002  -0.04162598\n",
      "  -0.03134155]\n",
      " ...\n",
      " [-0.00862885 -0.05206299 -0.01449585 ... -0.00683594  0.0221405\n",
      "  -0.03317261]\n",
      " [ 0.00237083  0.01412964  0.03710938 ...  0.00583649 -0.07073975\n",
      "  -0.00750351]\n",
      " [ 0.00349236  0.0249176   0.01928711 ...  0.03189087 -0.00722504\n",
      "  -0.00260544]]\n",
      "torch.Size([1024])\n",
      "[ 0.00688171  0.01009369 -0.07513428 ... -0.02806091 -0.06219482\n",
      " -0.01416779]\n",
      "torch.Size([1024])\n",
      "[0.99072266 0.99853516 0.99853516 ... 0.9794922  0.9921875  0.9692383 ]\n",
      "torch.Size([1024])\n",
      "[-0.12103271  0.05661011 -0.26879883 ...  0.00041342 -0.09289551\n",
      "  0.09381104]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.00387001 -0.03713989 -0.03393555 ... -0.01021576 -0.00738907\n",
      "  -0.02163696]\n",
      " [-0.00557327 -0.04168701 -0.02209473 ... -0.01521301  0.06817627\n",
      "  -0.04003906]\n",
      " [ 0.06341553  0.04681396  0.00465012 ... -0.01099396 -0.03771973\n",
      "   0.05215454]\n",
      " ...\n",
      " [-0.01701355 -0.0531311  -0.01118469 ...  0.06204224 -0.0021553\n",
      "  -0.07165527]\n",
      " [-0.02153015 -0.12194824 -0.00073004 ...  0.02764893  0.06658936\n",
      "  -0.03527832]\n",
      " [-0.06262207  0.0395813   0.05014038 ...  0.02479553  0.00349617\n",
      "   0.04879761]]\n",
      "torch.Size([4096])\n",
      "[-0.07232666 -0.10919189 -0.10852051 ... -0.05203247 -0.11663818\n",
      " -0.10449219]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.02980042  0.05770874 -0.00037241 ... -0.01811218 -0.0362854\n",
      "   0.02696228]\n",
      " [ 0.04324341 -0.05725098  0.06219482 ... -0.04223633 -0.02122498\n",
      "  -0.0703125 ]\n",
      " [ 0.00572205  0.01396942 -0.01239777 ... -0.03065491 -0.0123291\n",
      "  -0.07617188]\n",
      " ...\n",
      " [-0.06811523 -0.06433105 -0.03253174 ...  0.00056219  0.09832764\n",
      "  -0.02285767]\n",
      " [-0.00884247  0.02017212 -0.07611084 ... -0.02481079 -0.00957489\n",
      "   0.00705719]\n",
      " [ 0.00179958 -0.02255249  0.08392334 ... -0.05435181  0.02981567\n",
      "  -0.03900146]]\n",
      "torch.Size([1024])\n",
      "[-0.10644531  0.00956726  0.13671875 ... -0.0007863  -0.0581665\n",
      "  0.14489746]\n",
      "torch.Size([1024])\n",
      "[0.9736328 0.9941406 0.9902344 ... 0.9770508 0.9892578 0.9560547]\n",
      "torch.Size([1024])\n",
      "[-0.01681519 -0.11340332  0.27026367 ... -0.11846924 -0.04550171\n",
      " -0.14782715]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01914978 -0.02740479  0.05548096 ...  0.04397583  0.05072021\n",
      "   0.00695038]\n",
      " [-0.00642395 -0.03463745 -0.00745392 ... -0.00740814 -0.050354\n",
      "  -0.03369141]\n",
      " [ 0.0385437   0.14990234  0.08654785 ...  0.05270386  0.04644775\n",
      "   0.03594971]\n",
      " ...\n",
      " [ 0.01062775 -0.00300026 -0.10333252 ...  0.03041077  0.06750488\n",
      "   0.06246948]\n",
      " [ 0.02586365  0.01747131  0.01927185 ...  0.00416183  0.02565002\n",
      "   0.08557129]\n",
      " [-0.04034424 -0.0035305   0.03866577 ... -0.04309082  0.03335571\n",
      "  -0.02905273]]\n",
      "torch.Size([1024])\n",
      "[-0.30859375  0.05383301 -0.30786133 ... -0.09191895  0.02836609\n",
      "  0.00721359]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02757263 -0.02908325  0.06811523 ... -0.0124054  -0.03060913\n",
      "  -0.00204468]\n",
      " [-0.01719666  0.02902222  0.01914978 ...  0.0994873   0.0760498\n",
      "   0.01579285]\n",
      " [ 0.05297852  0.00232124  0.0164032  ... -0.01366425 -0.03240967\n",
      "  -0.040802  ]\n",
      " ...\n",
      " [-0.01844788  0.01373291  0.00389862 ... -0.0317688   0.01462555\n",
      "  -0.00163078]\n",
      " [-0.07434082 -0.06518555  0.00018013 ...  0.04443359  0.03552246\n",
      "  -0.00759888]\n",
      " [ 0.01256561  0.03710938  0.00108814 ...  0.05691528  0.03089905\n",
      "  -0.00705338]]\n",
      "torch.Size([1024])\n",
      "[-0.00229454  0.00188541  0.00231171 ...  0.00405121 -0.00165939\n",
      "  0.00084352]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0092392   0.01583862 -0.00720596 ... -0.03237915 -0.01404572\n",
      "  -0.00072908]\n",
      " [-0.00250244  0.04031372  0.02005005 ... -0.05825806  0.03515625\n",
      "   0.0144043 ]\n",
      " [-0.01679993 -0.05789185  0.05499268 ...  0.04470825 -0.00382614\n",
      "   0.02481079]\n",
      " ...\n",
      " [ 0.01696777  0.03939819  0.0008049  ...  0.04788208 -0.05688477\n",
      "  -0.00099087]\n",
      " [ 0.01166534 -0.01564026 -0.00362396 ... -0.03060913  0.02005005\n",
      "  -0.01551819]\n",
      " [ 0.01268005  0.02342224  0.02157593 ... -0.03207397  0.10876465\n",
      "   0.02674866]]\n",
      "torch.Size([1024])\n",
      "[-0.00661469 -0.0080719  -0.00189114 ... -0.0177002  -0.01012421\n",
      " -0.00231171]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01867676 -0.02832031  0.0552063  ...  0.04333496  0.05007935\n",
      "   0.00659943]\n",
      " [-0.00630951 -0.03424072 -0.0072403  ... -0.00648499 -0.04986572\n",
      "  -0.03320312]\n",
      " [ 0.03826904  0.14929199  0.08660889 ...  0.05233765  0.04589844\n",
      "   0.03622437]\n",
      " ...\n",
      " [ 0.01023102 -0.00244141 -0.10205078 ...  0.03044128  0.06732178\n",
      "   0.06323242]\n",
      " [ 0.026474    0.0177002   0.01875305 ...  0.00480652  0.02542114\n",
      "   0.08496094]\n",
      " [-0.04031372 -0.00419617  0.03778076 ... -0.04214478  0.03375244\n",
      "  -0.0295105 ]]\n",
      "torch.Size([1024])\n",
      "[-0.30786133  0.05413818 -0.3071289  ... -0.0925293   0.02810669\n",
      "  0.00656509]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02003479 -0.02793884  0.05599976 ...  0.04385376  0.05084229\n",
      "   0.00669479]\n",
      " [-0.00701904 -0.03479004 -0.0069313  ... -0.0075264  -0.05084229\n",
      "  -0.03393555]\n",
      " [ 0.03845215  0.1496582   0.08691406 ...  0.05227661  0.04571533\n",
      "   0.03616333]\n",
      " ...\n",
      " [ 0.01038361 -0.00236511 -0.10284424 ...  0.03118896  0.06726074\n",
      "   0.06280518]\n",
      " [ 0.02653503  0.01870728  0.01956177 ...  0.00383949  0.02513123\n",
      "   0.0859375 ]\n",
      " [-0.040802   -0.00440598  0.03729248 ... -0.04223633  0.03338623\n",
      "  -0.02914429]]\n",
      "torch.Size([1024])\n",
      "[-0.3076172   0.05386353 -0.3076172  ... -0.0927124   0.02822876\n",
      "  0.006073  ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01873779 -0.02812195  0.05529785 ...  0.04354858  0.05108643\n",
      "   0.00701523]\n",
      " [-0.00674057 -0.03460693 -0.00716782 ... -0.00685501 -0.0506897\n",
      "  -0.03390503]\n",
      " [ 0.03814697  0.14953613  0.08630371 ...  0.05230713  0.04608154\n",
      "   0.0362854 ]\n",
      " ...\n",
      " [ 0.01112366 -0.00240707 -0.10333252 ...  0.03076172  0.06707764\n",
      "   0.06329346]\n",
      " [ 0.0267334   0.01786804  0.0181427  ...  0.00492477  0.02503967\n",
      "   0.08532715]\n",
      " [-0.04144287 -0.00452042  0.03826904 ... -0.04208374  0.03311157\n",
      "  -0.02984619]]\n",
      "torch.Size([1024])\n",
      "[-0.30786133  0.05377197 -0.3076172  ... -0.09240723  0.0275116\n",
      "  0.00574112]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.03811646  0.00604248 -0.01806641 ...  0.04119873 -0.03396606\n",
      "  -0.00598526]\n",
      " [ 0.01824951 -0.0333252  -0.03869629 ...  0.01841736  0.03857422\n",
      "  -0.02113342]\n",
      " [ 0.04901123 -0.05578613 -0.03466797 ...  0.02590942  0.06536865\n",
      "  -0.03262329]\n",
      " ...\n",
      " [-0.01520538  0.04870605  0.00136375 ... -0.03964233  0.0066452\n",
      "   0.02026367]\n",
      " [-0.02738953  0.02464294  0.04019165 ...  0.02435303 -0.02055359\n",
      "  -0.04071045]\n",
      " [-0.02201843  0.04684448  0.02354431 ...  0.05731201  0.00594711\n",
      "   0.01951599]]\n",
      "torch.Size([1024])\n",
      "[ 0.00743484 -0.01028442  0.03198242 ... -0.00069714 -0.0668335\n",
      "  0.00932312]\n",
      "torch.Size([1024])\n",
      "[0.9863281 1.0009766 1.        ... 0.9838867 0.9785156 0.9506836]\n",
      "torch.Size([1024])\n",
      "[-0.12121582  0.05728149 -0.28320312 ... -0.0249176  -0.1036377\n",
      "  0.10070801]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.00718689 -0.00978851 -0.01294708 ... -0.00321198  0.03833008\n",
      "   0.06573486]\n",
      " [ 0.00703049  0.00613403  0.00202179 ... -0.02946472  0.02410889\n",
      "  -0.03942871]\n",
      " [-0.06152344 -0.07598877 -0.05014038 ...  0.07751465 -0.01696777\n",
      "  -0.07928467]\n",
      " ...\n",
      " [-0.04870605 -0.04495239  0.00549316 ... -0.01573181  0.07794189\n",
      "  -0.04718018]\n",
      " [ 0.0014019  -0.00065279  0.00926208 ...  0.01169586  0.01219177\n",
      "   0.00710678]\n",
      " [-0.0139389  -0.06298828  0.04779053 ... -0.01731873  0.02050781\n",
      "  -0.12854004]]\n",
      "torch.Size([4096])\n",
      "[-0.08013916 -0.09375    -0.10076904 ... -0.07720947 -0.07061768\n",
      " -0.1739502 ]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.02554321 -0.03155518 -0.01686096 ...  0.03540039  0.02604675\n",
      "  -0.00371742]\n",
      " [ 0.00991821 -0.04244995 -0.00530243 ... -0.00896454  0.03451538\n",
      "   0.0071106 ]\n",
      " [ 0.02575684 -0.01113892 -0.0871582  ...  0.04440308 -0.04296875\n",
      "   0.04025269]\n",
      " ...\n",
      " [ 0.01171112 -0.06192017  0.01113129 ... -0.01651001  0.05462646\n",
      "  -0.04348755]\n",
      " [ 0.02949524 -0.00114441 -0.11181641 ... -0.01965332 -0.02825928\n",
      "   0.06304932]\n",
      " [ 0.03845215  0.01034546  0.01638794 ... -0.02735901  0.02516174\n",
      "  -0.01646423]]\n",
      "torch.Size([1024])\n",
      "[-0.06817627  0.03103638  0.06488037 ... -0.00761795 -0.05438232\n",
      "  0.07025146]\n",
      "torch.Size([1024])\n",
      "[0.98095703 0.9916992  1.0009766  ... 0.98291016 0.97558594 0.9580078 ]\n",
      "torch.Size([1024])\n",
      "[-0.02436829 -0.11230469  0.11077881 ... -0.08129883 -0.0276947\n",
      " -0.13415527]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01799011 -0.01837158  0.00328636 ...  0.02375793 -0.04089355\n",
      "  -0.10675049]\n",
      " [ 0.05371094 -0.08630371 -0.01756287 ...  0.01947021 -0.0401001\n",
      "   0.02114868]\n",
      " [-0.12976074  0.01815796  0.02357483 ...  0.01371765  0.08294678\n",
      "   0.00314713]\n",
      " ...\n",
      " [-0.02890015  0.19506836  0.04421997 ...  0.05584717  0.00957489\n",
      "   0.12683105]\n",
      " [ 0.00819397  0.02905273 -0.0291748  ...  0.01225281  0.07299805\n",
      "   0.10095215]\n",
      " [ 0.01550293  0.0115509   0.02659607 ...  0.09613037  0.11914062\n",
      "   0.04443359]]\n",
      "torch.Size([1024])\n",
      "[ 0.01670837  0.01464844 -0.05490112 ... -0.25463867  0.12475586\n",
      " -0.2619629 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00471497 -0.00284195 -0.05633545 ... -0.01078796 -0.00405121\n",
      "   0.06567383]\n",
      " [ 0.01124573  0.00364685  0.0254364  ...  0.02514648 -0.04299927\n",
      "   0.00370598]\n",
      " [-0.01178741 -0.0463562  -0.01759338 ...  0.02015686 -0.03704834\n",
      "   0.02906799]\n",
      " ...\n",
      " [-0.02148438  0.00195885  0.02958679 ... -0.05291748 -0.07824707\n",
      "  -0.04260254]\n",
      " [-0.06835938  0.04092407  0.01628113 ... -0.00695801 -0.02270508\n",
      "   0.07836914]\n",
      " [ 0.02122498  0.02178955  0.02748108 ...  0.00866699 -0.01200867\n",
      "  -0.03768921]]\n",
      "torch.Size([1024])\n",
      "[ 0.00027442  0.00021183  0.00016272 ... -0.0025959  -0.00191879\n",
      " -0.00165176]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00632477 -0.01635742  0.00390625 ...  0.0194397  -0.00320435\n",
      "  -0.040802  ]\n",
      " [-0.01145172 -0.02832031 -0.02301025 ... -0.01060486 -0.03466797\n",
      "  -0.04653931]\n",
      " [ 0.02651978 -0.02218628  0.02641296 ... -0.01506042  0.02339172\n",
      "   0.0065918 ]\n",
      " ...\n",
      " [-0.00274658 -0.04083252  0.01541901 ...  0.0224762   0.03945923\n",
      "   0.01105499]\n",
      " [-0.05383301 -0.0531311  -0.00344467 ...  0.04650879  0.02030945\n",
      "   0.02142334]\n",
      " [ 0.03335571  0.00058794 -0.02577209 ...  0.03234863 -0.03582764\n",
      "  -0.01474762]]\n",
      "torch.Size([1024])\n",
      "[ 0.00092649  0.03381348 -0.05172729 ...  0.01387787  0.00310326\n",
      "  0.00529861]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01786804 -0.01803589  0.0034523  ...  0.02308655 -0.04003906\n",
      "  -0.10650635]\n",
      " [ 0.05374146 -0.08587646 -0.01643372 ...  0.01994324 -0.04055786\n",
      "   0.01966858]\n",
      " [-0.13049316  0.01704407  0.02330017 ...  0.01535034  0.08374023\n",
      "   0.00260162]\n",
      " ...\n",
      " [-0.02894592  0.1953125   0.04403687 ...  0.05603027  0.00934601\n",
      "   0.12597656]\n",
      " [ 0.00841522  0.02864075 -0.03027344 ...  0.01145935  0.07281494\n",
      "   0.09985352]\n",
      " [ 0.01579285  0.0118103   0.02629089 ...  0.09674072  0.1192627\n",
      "   0.04431152]]\n",
      "torch.Size([1024])\n",
      "[ 0.01702881  0.01400757 -0.05502319 ... -0.25439453  0.12487793\n",
      " -0.2619629 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01882935 -0.01777649  0.00294876 ...  0.02256775 -0.03921509\n",
      "  -0.10748291]\n",
      " [ 0.05496216 -0.08679199 -0.01603699 ...  0.01997375 -0.04034424\n",
      "   0.02061462]\n",
      " [-0.12939453  0.0161438   0.02337646 ...  0.01425934  0.08251953\n",
      "   0.00405502]\n",
      " ...\n",
      " [-0.02865601  0.19592285  0.04541016 ...  0.05557251  0.00861359\n",
      "   0.12768555]\n",
      " [ 0.00816345  0.0292511  -0.02970886 ...  0.01171112  0.07287598\n",
      "   0.10144043]\n",
      " [ 0.01540375  0.01233673  0.02694702 ...  0.09661865  0.1184082\n",
      "   0.04516602]]\n",
      "torch.Size([1024])\n",
      "[ 0.0174408   0.01416779 -0.05471802 ... -0.2536621   0.12536621\n",
      " -0.26171875]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01837158 -0.01812744  0.00372124 ...  0.02311707 -0.04031372\n",
      "  -0.10577393]\n",
      " [ 0.05389404 -0.08538818 -0.016922   ...  0.01850891 -0.04101562\n",
      "   0.02098083]\n",
      " [-0.1307373   0.01611328  0.02268982 ...  0.014534    0.08337402\n",
      "   0.00342178]\n",
      " ...\n",
      " [-0.02893066  0.19470215  0.04415894 ...  0.05575562  0.0092926\n",
      "   0.1274414 ]\n",
      " [ 0.00811768  0.02865601 -0.03024292 ...  0.01180267  0.07263184\n",
      "   0.10107422]\n",
      " [ 0.01534271  0.01168823  0.02607727 ...  0.09674072  0.1192627\n",
      "   0.04489136]]\n",
      "torch.Size([1024])\n",
      "[ 0.01722717  0.01539612 -0.05459595 ... -0.2541504   0.12493896\n",
      " -0.26220703]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00165749 -0.00882721  0.02603149 ...  0.00871277  0.06176758\n",
      "  -0.03240967]\n",
      " [-0.03720093  0.00198174  0.01342773 ...  0.03939819 -0.0769043\n",
      "   0.02536011]\n",
      " [-0.03381348 -0.02235413  0.0125351  ...  0.04522705  0.03796387\n",
      "   0.03601074]\n",
      " ...\n",
      " [ 0.04678345  0.00384903  0.05032349 ...  0.00882721 -0.06500244\n",
      "  -0.00609589]\n",
      " [ 0.01159668  0.01460266  0.00845337 ... -0.00775909  0.01747131\n",
      "   0.03439331]\n",
      " [-0.01111603 -0.02706909 -0.00847626 ... -0.05105591 -0.01486969\n",
      "   0.04519653]]\n",
      "torch.Size([1024])\n",
      "[-0.01599121  0.01773071 -0.03820801 ... -0.04724121 -0.00361061\n",
      "  0.02792358]\n",
      "torch.Size([1024])\n",
      "[0.9892578  0.98583984 1.         ... 0.9824219  0.95996094 0.9736328 ]\n",
      "torch.Size([1024])\n",
      "[-0.09143066  0.01148987 -0.4255371  ... -0.074646   -0.10119629\n",
      " -0.00049686]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.06237793  0.03460693  0.01459503 ...  0.06054688  0.00286102\n",
      "   0.03399658]\n",
      " [ 0.06158447  0.0390625  -0.01078033 ...  0.00220299 -0.03811646\n",
      "  -0.03839111]\n",
      " [-0.03887939 -0.02168274 -0.00274086 ...  0.01520538  0.01681519\n",
      "   0.03686523]\n",
      " ...\n",
      " [ 0.00847626  0.02888489  0.00338554 ... -0.03964233 -0.02160645\n",
      "   0.00881958]\n",
      " [-0.02897644 -0.10461426  0.01708984 ... -0.08752441 -0.00718689\n",
      "  -0.01328278]\n",
      " [-0.05096436 -0.04910278  0.00222778 ...  0.04309082 -0.02650452\n",
      "   0.03329468]]\n",
      "torch.Size([4096])\n",
      "[-0.09265137 -0.09106445 -0.00933838 ...  0.00663376 -0.08666992\n",
      " -0.03173828]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.01520538  0.0690918  -0.01585388 ...  0.0144577  -0.10449219\n",
      "  -0.03872681]\n",
      " [ 0.03488159  0.07830811  0.00630569 ... -0.0378418  -0.06225586\n",
      "   0.03216553]\n",
      " [-0.01698303 -0.00649643 -0.00977325 ...  0.02882385  0.01464844\n",
      "   0.00645065]\n",
      " ...\n",
      " [-0.05877686  0.03875732 -0.02633667 ...  0.02650452 -0.01309967\n",
      "   0.03033447]\n",
      " [-0.0052948  -0.00094795 -0.02325439 ...  0.02740479  0.01766968\n",
      "   0.01282501]\n",
      " [ 0.06750488 -0.02003479  0.01254272 ... -0.02905273  0.01721191\n",
      "  -0.0451355 ]]\n",
      "torch.Size([1024])\n",
      "[-0.19360352  0.04983521  0.11474609 ... -0.01585388 -0.04190063\n",
      "  0.05914307]\n",
      "torch.Size([1024])\n",
      "[0.98583984 0.99072266 1.0009766  ... 0.9838867  0.9770508  0.9511719 ]\n",
      "torch.Size([1024])\n",
      "[-0.03143311 -0.09631348 -0.00432968 ... -0.04702759 -0.0411377\n",
      " -0.10998535]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03607178  0.03674316  0.0308075  ...  0.01864624  0.01448822\n",
      "   0.01267242]\n",
      " [-0.09405518 -0.07312012  0.06622314 ... -0.03573608  0.00245094\n",
      "   0.01320648]\n",
      " [-0.06646729  0.10406494 -0.03286743 ...  0.04492188  0.06671143\n",
      "  -0.00201988]\n",
      " ...\n",
      " [ 0.0604248   0.04095459 -0.00036144 ... -0.00486374  0.08465576\n",
      "  -0.00430298]\n",
      " [ 0.0088501   0.08227539 -0.03265381 ... -0.12536621  0.04138184\n",
      "   0.02604675]\n",
      " [-0.02836609 -0.07806396  0.00050688 ...  0.0033474  -0.01800537\n",
      "  -0.04425049]]\n",
      "torch.Size([1024])\n",
      "[-0.09405518  0.12902832  0.02008057 ... -0.13928223 -0.0541687\n",
      "  0.05667114]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.07348633  0.04580688  0.00209999 ... -0.15820312  0.0519104\n",
      "  -0.01364899]\n",
      " [-0.05505371 -0.001791    0.11663818 ...  0.01330566  0.02070618\n",
      "  -0.03198242]\n",
      " [ 0.04058838 -0.03585815 -0.06143188 ... -0.02822876  0.11071777\n",
      "  -0.02964783]\n",
      " ...\n",
      " [-0.00650787  0.05310059 -0.04141235 ...  0.05847168 -0.00112438\n",
      "   0.02838135]\n",
      " [-0.0803833   0.03137207 -0.0479126  ...  0.01482391  0.03900146\n",
      "  -0.02734375]\n",
      " [-0.0109787  -0.08398438  0.0368042  ...  0.01385498  0.0094223\n",
      "  -0.06311035]]\n",
      "torch.Size([1024])\n",
      "[-0.00025606  0.00350571  0.00314331 ...  0.00037098  0.00016677\n",
      "  0.00068045]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 4.3334961e-02 -8.9597702e-04 -1.5853882e-02 ... -4.4830322e-02\n",
      "   3.0090332e-02  3.4088135e-02]\n",
      " [-5.0109863e-02 -3.3874512e-02  1.3647079e-03 ...  6.5856934e-02\n",
      "  -8.3398819e-04  4.9255371e-02]\n",
      " [ 3.1769276e-05 -5.4359436e-03  5.1460266e-03 ...  2.6245117e-03\n",
      "  -6.6719055e-03 -6.8847656e-02]\n",
      " ...\n",
      " [ 3.9176941e-03  3.1143188e-02  1.5731812e-02 ... -2.3788452e-02\n",
      "  -3.9886475e-02 -3.3874512e-02]\n",
      " [ 5.3619385e-02 -5.0323486e-02  1.0042191e-03 ... -2.3956299e-03\n",
      "  -1.7089844e-02 -1.4877319e-02]\n",
      " [-2.6504517e-02 -1.7395020e-02  2.9468536e-03 ...  3.9978027e-02\n",
      "  -1.6433716e-02 -4.2999268e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.00632095 -0.01564026  0.00958252 ... -0.0151062  -0.00579453\n",
      " -0.00369453]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03488159  0.03686523  0.03030396 ...  0.01852417  0.01514435\n",
      "   0.01291656]\n",
      " [-0.0925293  -0.07330322  0.065979   ... -0.03567505  0.0026226\n",
      "   0.01248169]\n",
      " [-0.06665039  0.10375977 -0.03338623 ...  0.04608154  0.0682373\n",
      "  -0.00160789]\n",
      " ...\n",
      " [ 0.0607605   0.04031372 -0.00116825 ... -0.00585556  0.08520508\n",
      "  -0.0041275 ]\n",
      " [ 0.00901031  0.08197021 -0.03210449 ... -0.12524414  0.04171753\n",
      "   0.02607727]\n",
      " [-0.02825928 -0.07928467  0.00041199 ...  0.00324059 -0.01914978\n",
      "  -0.0435791 ]]\n",
      "torch.Size([1024])\n",
      "[-0.09313965  0.12902832  0.02061462 ... -0.13879395 -0.05465698\n",
      "  0.05615234]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 3.47900391e-02  3.73535156e-02  3.04870605e-02 ...  1.80511475e-02\n",
      "   1.47171021e-02  1.23367310e-02]\n",
      " [-9.32617188e-02 -7.28759766e-02  6.67114258e-02 ... -3.56750488e-02\n",
      "   2.28691101e-03  1.33590698e-02]\n",
      " [-6.71997070e-02  1.03881836e-01 -3.18908691e-02 ...  4.60205078e-02\n",
      "   6.70166016e-02 -2.14195251e-03]\n",
      " ...\n",
      " [ 6.07604980e-02  4.01000977e-02 -7.14302063e-04 ... -4.84085083e-03\n",
      "   8.55102539e-02 -4.31823730e-03]\n",
      " [ 9.15527344e-03  8.18481445e-02 -3.24401855e-02 ... -1.25488281e-01\n",
      "   4.21752930e-02  2.60620117e-02]\n",
      " [-2.84271240e-02 -7.91625977e-02  5.05447388e-05 ...  4.54330444e-03\n",
      "  -1.90734863e-02 -4.39758301e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.09381104  0.1282959   0.01965332 ... -0.1394043  -0.05401611\n",
      "  0.05523682]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 3.5217285e-02  3.7322998e-02  3.1204224e-02 ...  1.7211914e-02\n",
      "   1.5090942e-02  1.2725830e-02]\n",
      " [-9.3200684e-02 -7.2753906e-02  6.6345215e-02 ... -3.6376953e-02\n",
      "   2.1038055e-03  1.2649536e-02]\n",
      " [-6.6284180e-02  1.0449219e-01 -3.2287598e-02 ...  4.4647217e-02\n",
      "   6.7871094e-02 -2.3384094e-03]\n",
      " ...\n",
      " [ 6.1553955e-02  4.1412354e-02  8.6605549e-05 ... -6.2522888e-03\n",
      "   8.5266113e-02 -3.9482117e-03]\n",
      " [ 9.3841553e-03  8.0993652e-02 -3.3416748e-02 ... -1.2512207e-01\n",
      "   4.2205811e-02  2.6840210e-02]\n",
      " [-2.7847290e-02 -7.8063965e-02  1.8768311e-03 ...  3.0097961e-03\n",
      "  -1.9271851e-02 -4.3823242e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.09301758  0.12866211  0.020401   ... -0.13806152 -0.05392456\n",
      "  0.05673218]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03012085 -0.00379562 -0.01229858 ... -0.00341606  0.00629425\n",
      "  -0.00152588]\n",
      " [ 0.00065184 -0.01538849  0.03103638 ... -0.00207329  0.03808594\n",
      "   0.05758667]\n",
      " [ 0.04946899 -0.0362854   0.02287292 ...  0.04159546 -0.03463745\n",
      "   0.00924683]\n",
      " ...\n",
      " [-0.03076172  0.02740479 -0.01396179 ...  0.03607178 -0.03302002\n",
      "  -0.0279541 ]\n",
      " [-0.04821777  0.00526428 -0.02894592 ...  0.00511169  0.00462341\n",
      "   0.00266457]\n",
      " [ 0.02770996 -0.01541901  0.03120422 ...  0.02102661  0.00242233\n",
      "   0.04660034]]\n",
      "torch.Size([1024])\n",
      "[-0.04986572  0.0063324   0.00574112 ...  0.00914764 -0.09698486\n",
      "  0.05532837]\n",
      "torch.Size([1024])\n",
      "[0.98339844 0.99853516 1.0029297  ... 0.9916992  0.9951172  0.97509766]\n",
      "torch.Size([1024])\n",
      "[-0.17089844  0.01279449 -0.5        ... -0.01103973 -0.11010742\n",
      " -0.01402283]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.00955963 -0.00011134  0.02017212 ... -0.06036377  0.01075745\n",
      "  -0.08062744]\n",
      " [ 0.02854919 -0.07348633  0.04019165 ... -0.10351562  0.04489136\n",
      "  -0.02351379]\n",
      " [ 0.03390503  0.09863281  0.04052734 ...  0.02363586  0.01005554\n",
      "   0.00953674]\n",
      " ...\n",
      " [ 0.04403687 -0.02180481  0.03604126 ... -0.02027893 -0.01924133\n",
      "   0.03585815]\n",
      " [ 0.09033203  0.01802063  0.00926971 ...  0.0139389   0.05490112\n",
      "  -0.07263184]\n",
      " [ 0.03323364  0.0065918   0.01757812 ... -0.02731323 -0.06964111\n",
      "  -0.01318359]]\n",
      "torch.Size([4096])\n",
      "[-0.06109619 -0.09881592 -0.05215454 ... -0.0769043  -0.05587769\n",
      " -0.03396606]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.00762177  0.00930786  0.00852966 ... -0.02687073  0.06933594\n",
      "   0.01047516]\n",
      " [-0.0329895   0.0173645   0.06494141 ...  0.01826477  0.01044464\n",
      "   0.02774048]\n",
      " [ 0.03594971 -0.01766968  0.02005005 ...  0.03771973 -0.00276184\n",
      "  -0.00243568]\n",
      " ...\n",
      " [ 0.07348633 -0.0574646   0.03085327 ...  0.05322266 -0.01423645\n",
      "   0.02267456]\n",
      " [-0.01402283 -0.0083313   0.01435852 ... -0.06066895 -0.00887299\n",
      "  -0.00307274]\n",
      " [ 0.02250671  0.02122498  0.02400208 ...  0.0244751   0.00580215\n",
      "   0.02511597]]\n",
      "torch.Size([1024])\n",
      "[-1.6809082e-01 -6.2525272e-05  6.0668945e-02 ... -4.1076660e-02\n",
      " -5.0415039e-02 -5.7250977e-02]\n",
      "torch.Size([1024])\n",
      "[0.97216797 0.9975586  1.0029297  ... 0.9770508  0.97753906 0.953125  ]\n",
      "torch.Size([1024])\n",
      "[ 0.02093506 -0.11120605 -0.02278137 ... -0.08343506 -0.02455139\n",
      " -0.08404541]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00469208 -0.08612061 -0.03927612 ... -0.02641296  0.06903076\n",
      "  -0.06762695]\n",
      " [ 0.02043152 -0.03741455 -0.00826263 ... -0.03268433  0.04632568\n",
      "   0.06060791]\n",
      " [ 0.01824951  0.0223999   0.01574707 ... -0.03564453  0.01541138\n",
      "  -0.02653503]\n",
      " ...\n",
      " [ 0.05755615 -0.02529907 -0.0017128  ... -0.01142883 -0.06481934\n",
      "  -0.01316071]\n",
      " [ 0.04803467  0.01033783 -0.07873535 ...  0.03302002  0.0259552\n",
      "   0.02374268]\n",
      " [-0.01878357 -0.01786804 -0.03967285 ... -0.0513916  -0.03536987\n",
      "  -0.04278564]]\n",
      "torch.Size([1024])\n",
      "[-0.01108551 -0.02998352 -0.06280518 ...  0.00262833 -0.05786133\n",
      "  0.07470703]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.03640747  0.04855347  0.00220871 ... -0.01113892 -0.0300293\n",
      "  -0.04135132]\n",
      " [ 0.03536987 -0.01006317 -0.00493622 ... -0.02996826 -0.02088928\n",
      "  -0.04187012]\n",
      " [ 0.03573608 -0.05053711  0.07019043 ... -0.06671143 -0.02436829\n",
      "   0.01554108]\n",
      " ...\n",
      " [-0.01544189  0.01277924  0.00312614 ...  0.00804138  0.05554199\n",
      "   0.00664139]\n",
      " [ 0.04275513  0.03112793 -0.01156616 ...  0.01647949  0.03222656\n",
      "   0.006073  ]\n",
      " [-0.03768921  0.00688553 -0.03079224 ...  0.08752441 -0.0026474\n",
      "   0.0982666 ]]\n",
      "torch.Size([1024])\n",
      "[-0.00054979 -0.00134659 -0.00231171 ... -0.00352669 -0.00224686\n",
      "  0.00113201]\n",
      "torch.Size([1024, 1024])\n",
      "[[-2.40173340e-02  1.88064575e-03  1.03454590e-02 ... -2.10113525e-02\n",
      "  -5.40161133e-02  2.72369385e-02]\n",
      " [-2.26287842e-02 -3.06243896e-02 -8.02993774e-04 ... -5.29785156e-02\n",
      "  -6.34384155e-03  5.56945801e-02]\n",
      " [ 7.98702240e-06  5.62133789e-02  1.15356445e-02 ...  2.36206055e-02\n",
      "   2.54821777e-02  1.16806030e-02]\n",
      " ...\n",
      " [-5.19104004e-02  3.46984863e-02  1.32827759e-02 ...  5.74340820e-02\n",
      "   5.52978516e-02 -7.71331787e-03]\n",
      " [ 5.41381836e-02  1.63421631e-02 -1.12380981e-02 ... -3.42102051e-02\n",
      "  -3.87573242e-02 -3.15246582e-02]\n",
      " [-3.38439941e-02  1.51977539e-02  8.95690918e-03 ...  2.31933594e-02\n",
      "   5.09643555e-03 -2.07672119e-02]]\n",
      "torch.Size([1024])\n",
      "[ 0.00073671 -0.007164    0.00179005 ...  0.03289795 -0.00175571\n",
      "  0.00113487]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00449753 -0.08477783 -0.03881836 ... -0.02775574  0.06707764\n",
      "  -0.06793213]\n",
      " [ 0.01992798 -0.03717041 -0.00871277 ... -0.0324707   0.04498291\n",
      "   0.0597229 ]\n",
      " [ 0.0174408   0.02142334  0.01468658 ... -0.03695679  0.01217651\n",
      "  -0.02716064]\n",
      " ...\n",
      " [ 0.05795288 -0.02510071 -0.00151443 ... -0.0116272  -0.06481934\n",
      "  -0.01369476]\n",
      " [ 0.04751587  0.01078796 -0.07879639 ...  0.03201294  0.02523804\n",
      "   0.0226593 ]\n",
      " [-0.01951599 -0.01745605 -0.03872681 ... -0.05197144 -0.03555298\n",
      "  -0.04296875]]\n",
      "torch.Size([1024])\n",
      "[-0.01213837 -0.029953   -0.06158447 ...  0.00254059 -0.05825806\n",
      "  0.07366943]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00521088 -0.08453369 -0.03955078 ... -0.02828979  0.06713867\n",
      "  -0.06793213]\n",
      " [ 0.02023315 -0.03775024 -0.00858307 ... -0.03207397  0.04516602\n",
      "   0.05944824]\n",
      " [ 0.01887512  0.021698    0.0151062  ... -0.03649902  0.01295471\n",
      "  -0.02696228]\n",
      " ...\n",
      " [ 0.05792236 -0.02453613 -0.00138283 ... -0.01159668 -0.06494141\n",
      "  -0.01391602]\n",
      " [ 0.04776001  0.00965118 -0.07800293 ...  0.03204346  0.0244751\n",
      "   0.02340698]\n",
      " [-0.01885986 -0.01837158 -0.03881836 ... -0.05212402 -0.0355835\n",
      "  -0.04364014]]\n",
      "torch.Size([1024])\n",
      "[-0.0105896  -0.02923584 -0.06152344 ...  0.0026226  -0.05758667\n",
      "  0.07318115]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00461197 -0.0848999  -0.03857422 ... -0.02676392  0.06872559\n",
      "  -0.0682373 ]\n",
      " [ 0.02020264 -0.03747559 -0.00844574 ... -0.03140259  0.04669189\n",
      "   0.05963135]\n",
      " [ 0.0173645   0.02209473  0.01525116 ... -0.03588867  0.01334381\n",
      "  -0.02688599]\n",
      " ...\n",
      " [ 0.05718994 -0.02485657 -0.00101089 ... -0.01113892 -0.06414795\n",
      "  -0.01429749]\n",
      " [ 0.04815674  0.01042175 -0.07891846 ...  0.03161621  0.02471924\n",
      "   0.02244568]\n",
      " [-0.01847839 -0.01707458 -0.03894043 ... -0.05273438 -0.03631592\n",
      "  -0.04333496]]\n",
      "torch.Size([1024])\n",
      "[-0.01216888 -0.02964783 -0.06207275 ...  0.002388   -0.05697632\n",
      "  0.07366943]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02055359 -0.02558899  0.01054382 ...  0.02070618 -0.01123047\n",
      "  -0.01777649]\n",
      " [ 0.00202179 -0.03900146  0.00248337 ... -0.04504395  0.01564026\n",
      "   0.02098083]\n",
      " [ 0.03543091 -0.06951904 -0.00013363 ... -0.01314545  0.03765869\n",
      "  -0.00394058]\n",
      " ...\n",
      " [ 0.0089035   0.01446533  0.02900696 ... -0.01844788  0.00308037\n",
      "   0.00059652]\n",
      " [-0.01330566 -0.00914001 -0.00806427 ... -0.07843018 -0.01817322\n",
      "   0.05548096]\n",
      " [ 0.02784729  0.0113678   0.02790833 ... -0.01417542 -0.01156616\n",
      "   0.00048876]]\n",
      "torch.Size([1024])\n",
      "[ 0.04672241  0.00345802 -0.1739502  ...  0.05276489 -0.04901123\n",
      "  0.00502014]\n",
      "torch.Size([1024])\n",
      "[0.9824219  0.99316406 1.0029297  ... 0.9824219  0.9902344  0.9868164 ]\n",
      "torch.Size([1024])\n",
      "[-0.18005371 -0.02896118 -0.46679688 ... -0.04833984 -0.1159668\n",
      " -0.02824402]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.02589417  0.0051384  -0.01521301 ...  0.02470398  0.02215576\n",
      "   0.00189781]\n",
      " [ 0.00827026 -0.00066996  0.01799011 ...  0.07965088  0.02461243\n",
      "   0.0165863 ]\n",
      " [ 0.04821777 -0.05230713  0.01286316 ...  0.06280518 -0.07672119\n",
      "   0.06561279]\n",
      " ...\n",
      " [ 0.00717545 -0.03439331  0.01374817 ...  0.06842041  0.00271606\n",
      "  -0.0211792 ]\n",
      " [ 0.01316071 -0.05703735  0.00779724 ...  0.00185108 -0.0057869\n",
      "  -0.01062012]\n",
      " [-0.02125549 -0.03051758  0.01174927 ...  0.01261902  0.04904175\n",
      "   0.02351379]]\n",
      "torch.Size([4096])\n",
      "[-0.05343628 -0.07879639 -0.0242157  ... -0.04815674 -0.04348755\n",
      " -0.10040283]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.0023098   0.02226257 -0.01612854 ... -0.00725555  0.02110291\n",
      "   0.00418854]\n",
      " [ 0.03256226  0.07824707 -0.01554871 ... -0.02127075 -0.00861359\n",
      "  -0.00949097]\n",
      " [ 0.01390839  0.00434113  0.01800537 ...  0.01416016 -0.00349236\n",
      "  -0.00126839]\n",
      " ...\n",
      " [ 0.01165009  0.09094238 -0.04754639 ... -0.05163574  0.02053833\n",
      "   0.01448822]\n",
      " [ 0.03320312  0.04559326 -0.04702759 ...  0.0440979   0.03045654\n",
      "  -0.00335121]\n",
      " [-0.03823853 -0.02536011 -0.04885864 ... -0.0116272   0.01971436\n",
      "   0.00373459]]\n",
      "torch.Size([1024])\n",
      "[-0.13708496  0.06665039 -0.0892334  ... -0.04385376 -0.0769043\n",
      " -0.02420044]\n",
      "torch.Size([1024])\n",
      "[0.97314453 0.9897461  1.0029297  ... 0.9692383  0.9814453  0.9736328 ]\n",
      "torch.Size([1024])\n",
      "[ 0.03256226 -0.06219482 -0.21240234 ... -0.0581665  -0.01280975\n",
      " -0.04510498]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06439209  0.0335083  -0.0017786  ... -0.14282227  0.04428101\n",
      "   0.01730347]\n",
      " [ 0.06707764 -0.10693359 -0.00956726 ...  0.07836914  0.00214577\n",
      "  -0.02836609]\n",
      " [-0.0355835  -0.01404572 -0.03585815 ...  0.07678223  0.09295654\n",
      "  -0.03665161]\n",
      " ...\n",
      " [ 0.03341675  0.03887939  0.23693848 ...  0.08990479 -0.0645752\n",
      "   0.05978394]\n",
      " [ 0.02076721  0.01571655  0.06109619 ...  0.11236572  0.05303955\n",
      "  -0.04745483]\n",
      " [ 0.02682495 -0.02133179  0.0463562  ...  0.05004883  0.05789185\n",
      "  -0.01976013]]\n",
      "torch.Size([1024])\n",
      "[ 0.02386475  0.03114319 -0.01582336 ...  0.02809143  0.05615234\n",
      "  0.00055218]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01433563  0.03875732  0.05490112 ... -0.01646423 -0.02661133\n",
      "  -0.04730225]\n",
      " [-0.09844971 -0.09936523  0.02352905 ... -0.06994629  0.00055742\n",
      "  -0.00565338]\n",
      " [-0.03424072  0.07159424 -0.00762939 ... -0.10479736 -0.00141525\n",
      "  -0.05606079]\n",
      " ...\n",
      " [ 0.01739502 -0.01000214  0.25732422 ... -0.07727051 -0.03131104\n",
      "   0.02648926]\n",
      " [ 0.0087738  -0.00740433  0.08081055 ... -0.00764847  0.00125217\n",
      "  -0.0124054 ]\n",
      " [-0.02975464 -0.0456543   0.02648926 ...  0.06427002 -0.00702286\n",
      "  -0.02441406]]\n",
      "torch.Size([1024])\n",
      "[-0.00052166 -0.0060997  -0.00024796 ...  0.00152111  0.00970459\n",
      "  0.00249863]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00904846  0.0418396   0.0109787  ... -0.0018158  -0.02626038\n",
      "  -0.02879333]\n",
      " [ 0.02209473 -0.00566864 -0.01062012 ... -0.01281738 -0.00421143\n",
      "  -0.01876831]\n",
      " [ 0.03567505  0.04956055  0.00389671 ... -0.00460434  0.02833557\n",
      "  -0.01853943]\n",
      " ...\n",
      " [-0.01450348  0.00767136 -0.00071287 ... -0.00363159  0.00770569\n",
      "  -0.0378418 ]\n",
      " [ 0.01416779  0.01519775 -0.00909424 ...  0.0171814  -0.03994751\n",
      "   0.01608276]\n",
      " [-0.02560425 -0.01773071 -0.01476288 ... -0.02407837  0.00664139\n",
      "  -0.01608276]]\n",
      "torch.Size([1024])\n",
      "[ 0.02146912  0.01071167 -0.03289795 ...  0.01997375 -0.01350403\n",
      "  0.04956055]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06384277  0.03384399 -0.00171852 ... -0.14428711  0.04324341\n",
      "   0.01774597]\n",
      " [ 0.06811523 -0.10748291 -0.00971222 ...  0.07849121  0.0022068\n",
      "  -0.02828979]\n",
      " [-0.03457642 -0.01321411 -0.03552246 ...  0.0769043   0.09283447\n",
      "  -0.03759766]\n",
      " ...\n",
      " [ 0.03256226  0.03848267  0.2368164  ...  0.08929443 -0.06298828\n",
      "   0.05969238]\n",
      " [ 0.02104187  0.01599121  0.06188965 ...  0.11206055  0.05300903\n",
      "  -0.046875  ]\n",
      " [ 0.02655029 -0.02035522  0.04675293 ...  0.04904175  0.05651855\n",
      "  -0.02084351]]\n",
      "torch.Size([1024])\n",
      "[ 0.02365112  0.03067017 -0.01643372 ...  0.02825928  0.0553894\n",
      "  0.00084782]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06420898  0.03308105 -0.00165367 ... -0.14367676  0.0440979\n",
      "   0.01701355]\n",
      " [ 0.06762695 -0.10650635 -0.0102005  ...  0.07733154  0.00131226\n",
      "  -0.02793884]\n",
      " [-0.0352478  -0.01276398 -0.03625488 ...  0.07684326  0.09240723\n",
      "  -0.03713989]\n",
      " ...\n",
      " [ 0.03286743  0.03829956  0.23547363 ...  0.08947754 -0.06390381\n",
      "   0.05960083]\n",
      " [ 0.02098083  0.01669312  0.06137085 ...  0.11254883  0.05212402\n",
      "  -0.04666138]\n",
      " [ 0.02597046 -0.02026367  0.04763794 ...  0.0496521   0.05657959\n",
      "  -0.02079773]]\n",
      "torch.Size([1024])\n",
      "[ 0.02325439  0.03164673 -0.01609802 ...  0.02934265  0.05612183\n",
      " -0.00027752]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06469727  0.03363037 -0.00149727 ... -0.14355469  0.04354858\n",
      "   0.01724243]\n",
      " [ 0.06726074 -0.10723877 -0.01003265 ...  0.07800293  0.00120163\n",
      "  -0.02783203]\n",
      " [-0.0352478  -0.01321411 -0.03570557 ...  0.07684326  0.09228516\n",
      "  -0.03747559]\n",
      " ...\n",
      " [ 0.03262329  0.03756714  0.2364502  ...  0.090271   -0.06298828\n",
      "   0.0592041 ]\n",
      " [ 0.02033997  0.01577759  0.06176758 ...  0.11248779  0.05297852\n",
      "  -0.04711914]\n",
      " [ 0.02676392 -0.02043152  0.04711914 ...  0.04830933  0.05587769\n",
      "  -0.02020264]]\n",
      "torch.Size([1024])\n",
      "[ 0.02345276  0.03100586 -0.01620483 ...  0.02836609  0.05514526\n",
      "  0.00062943]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00502777  0.05377197 -0.00928497 ...  0.01282501  0.03601074\n",
      "   0.01902771]\n",
      " [-0.02119446 -0.00498581 -0.01493073 ... -0.04180908  0.02436829\n",
      "  -0.0164032 ]\n",
      " [ 0.03111267  0.02177429 -0.13623047 ... -0.06970215 -0.06390381\n",
      "  -0.00964355]\n",
      " ...\n",
      " [ 0.00491714 -0.00762558 -0.03582764 ... -0.01192474 -0.00517654\n",
      "  -0.01971436]\n",
      " [ 0.03207397 -0.0037632   0.04653931 ... -0.01521301  0.00218773\n",
      "   0.01447296]\n",
      " [ 0.05307007 -0.00610733  0.00503922 ... -0.00764465 -0.01679993\n",
      "  -0.02867126]]\n",
      "torch.Size([1024])\n",
      "[-0.00414658  0.06329346  0.05352783 ...  0.0352478  -0.06097412\n",
      "  0.07421875]\n",
      "torch.Size([1024])\n",
      "[0.9707031  0.99121094 1.0039062  ... 0.9863281  0.98876953 0.9848633 ]\n",
      "torch.Size([1024])\n",
      "[-0.18188477 -0.00356102 -0.47338867 ... -0.06896973 -0.15185547\n",
      " -0.03961182]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.01860046 -0.00817108  0.00627136 ... -0.01644897 -0.01094818\n",
      "  -0.07244873]\n",
      " [ 0.01047516  0.02102661  0.03637695 ...  0.06054688  0.0287323\n",
      "  -0.00741196]\n",
      " [ 0.00158691 -0.01495361  0.02807617 ...  0.03085327  0.03536987\n",
      "   0.00030565]\n",
      " ...\n",
      " [ 0.02120972  0.01455688  0.02107239 ...  0.074646   -0.03598022\n",
      "   0.00432968]\n",
      " [ 0.05230713 -0.01869202  0.00475693 ...  0.02980042  0.05801392\n",
      "  -0.02832031]\n",
      " [-0.01135254 -0.01508331 -0.00909424 ...  0.01950073 -0.00052881\n",
      "  -0.02726746]]\n",
      "torch.Size([4096])\n",
      "[-0.05783081 -0.04992676 -0.01489258 ... -0.09234619 -0.09112549\n",
      " -0.01383209]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.02070618  0.00317574 -0.00337219 ...  0.05987549  0.01448822\n",
      "  -0.05270386]\n",
      " [-0.03726196  0.00917053  0.00117683 ...  0.01154327 -0.02371216\n",
      "  -0.04705811]\n",
      " [ 0.0044899  -0.00831604  0.01033783 ...  0.00194359 -0.00992584\n",
      "  -0.0026474 ]\n",
      " ...\n",
      " [ 0.01127625 -0.01722717 -0.01557922 ...  0.02035522 -0.00201988\n",
      "  -0.00755692]\n",
      " [-0.01982117 -0.09405518 -0.04690552 ...  0.02110291  0.0085907\n",
      "  -0.0479126 ]\n",
      " [-0.02748108 -0.00041127 -0.04144287 ...  0.00208473  0.02626038\n",
      "   0.01013947]]\n",
      "torch.Size([1024])\n",
      "[-0.21240234  0.05368042  0.0871582  ... -0.04312134  0.00775909\n",
      " -0.11364746]\n",
      "torch.Size([1024])\n",
      "[0.9765625  0.98876953 1.0048828  ... 0.97753906 0.9741211  0.98291016]\n",
      "torch.Size([1024])\n",
      "[ 0.04388428 -0.07366943 -0.2052002  ... -0.04226685  0.03710938\n",
      " -0.04669189]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03564453 -0.01257324  0.02540588 ...  0.01741028  0.0880127\n",
      "   0.04034424]\n",
      " [ 0.07226562 -0.04455566 -0.00366783 ... -0.025177    0.01667786\n",
      "   0.03271484]\n",
      " [ 0.05169678 -0.04806519 -0.21435547 ...  0.05001831  0.06988525\n",
      "  -0.03158569]\n",
      " ...\n",
      " [ 0.09368896 -0.02270508  0.08435059 ... -0.04058838  0.06286621\n",
      "  -0.06903076]\n",
      " [-0.06622314 -0.02398682 -0.06359863 ... -0.02008057 -0.03585815\n",
      "  -0.08374023]\n",
      " [ 0.03811646  0.0006361  -0.03543091 ... -0.0559082  -0.09375\n",
      "  -0.04528809]]\n",
      "torch.Size([1024])\n",
      "[0.0094223  0.0302124  0.04727173 ... 0.10125732 0.01766968 0.02392578]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.09161377 -0.00830841  0.07525635 ...  0.00463104 -0.02485657\n",
      "  -0.01187897]\n",
      " [-0.06176758 -0.01322174 -0.02908325 ...  0.02281189 -0.03283691\n",
      "   0.07446289]\n",
      " [-0.11376953  0.00772858 -0.23254395 ... -0.05957031 -0.00712204\n",
      "   0.00696945]\n",
      " ...\n",
      " [-0.03887939 -0.02970886  0.1083374  ... -0.07446289 -0.03123474\n",
      "  -0.02333069]\n",
      " [-0.01412964  0.00630188 -0.06549072 ... -0.10089111  0.00874329\n",
      "   0.00843811]\n",
      " [ 0.01168823 -0.07647705 -0.03555298 ... -0.04147339 -0.01867676\n",
      "  -0.01713562]]\n",
      "torch.Size([1024])\n",
      "[ 7.4625015e-05 -4.0674210e-04 -6.3018799e-03 ... -1.1024475e-03\n",
      " -6.7424774e-04  4.9324036e-03]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01060486 -0.02986145  0.00328827 ...  0.06378174  0.00178337\n",
      "  -0.00227165]\n",
      " [ 0.0239563  -0.03286743 -0.00443649 ... -0.07769775 -0.03222656\n",
      "   0.0486145 ]\n",
      " [-0.04559326 -0.01251221  0.02684021 ... -0.0859375  -0.02978516\n",
      "   0.02032471]\n",
      " ...\n",
      " [-0.00459671  0.04556274 -0.00111675 ... -0.00048137 -0.04742432\n",
      "  -0.00567627]\n",
      " [ 0.04330444  0.02772522  0.00121593 ...  0.04693604  0.0357666\n",
      "  -0.07733154]\n",
      " [-0.01190948 -0.00096798  0.00149345 ... -0.04571533  0.03186035\n",
      "  -0.02462769]]\n",
      "torch.Size([1024])\n",
      "[-0.01039886  0.01261902  0.00585175 ... -0.02767944  0.01139832\n",
      " -0.03457642]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03585815 -0.0120697   0.02539062 ...  0.01776123  0.0880127\n",
      "   0.03970337]\n",
      " [ 0.07165527 -0.04498291 -0.00345039 ... -0.02459717  0.01763916\n",
      "   0.03268433]\n",
      " [ 0.05209351 -0.04769897 -0.21350098 ...  0.05056763  0.06921387\n",
      "  -0.03146362]\n",
      " ...\n",
      " [ 0.09362793 -0.02311707  0.08477783 ... -0.04092407  0.06341553\n",
      "  -0.06768799]\n",
      " [-0.06689453 -0.02378845 -0.06414795 ... -0.01957703 -0.03479004\n",
      "  -0.08312988]\n",
      " [ 0.03778076  0.00034833 -0.03488159 ... -0.05587769 -0.09350586\n",
      "  -0.04644775]]\n",
      "torch.Size([1024])\n",
      "[0.00983429 0.02978516 0.04660034 ... 0.09997559 0.01829529 0.02375793]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0357666  -0.01156616  0.02555847 ...  0.01716614  0.08728027\n",
      "   0.03942871]\n",
      " [ 0.07244873 -0.04522705 -0.00311089 ... -0.02406311  0.01837158\n",
      "   0.03259277]\n",
      " [ 0.05267334 -0.04769897 -0.21472168 ...  0.05014038  0.06958008\n",
      "  -0.03077698]\n",
      " ...\n",
      " [ 0.09417725 -0.02377319  0.08380127 ... -0.04040527  0.06335449\n",
      "  -0.06829834]\n",
      " [-0.06646729 -0.02377319 -0.0635376  ... -0.01976013 -0.03494263\n",
      "  -0.08361816]\n",
      " [ 0.03701782  0.00034451 -0.03527832 ... -0.05593872 -0.09423828\n",
      "  -0.04641724]]\n",
      "torch.Size([1024])\n",
      "[0.0100708  0.02923584 0.04730225 ... 0.1015625  0.01719666 0.02392578]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03564453 -0.01261139  0.02540588 ...  0.01766968  0.08770752\n",
      "   0.03979492]\n",
      " [ 0.07263184 -0.04403687 -0.00295067 ... -0.02510071  0.01716614\n",
      "   0.03308105]\n",
      " [ 0.05181885 -0.04833984 -0.21435547 ...  0.04986572  0.06970215\n",
      "  -0.03114319]\n",
      " ...\n",
      " [ 0.09362793 -0.02418518  0.0838623  ... -0.03994751  0.0635376\n",
      "  -0.06890869]\n",
      " [-0.06640625 -0.02426147 -0.06365967 ... -0.02023315 -0.03555298\n",
      "  -0.08300781]\n",
      " [ 0.03778076  0.00043464 -0.03570557 ... -0.05636597 -0.09381104\n",
      "  -0.04623413]]\n",
      "torch.Size([1024])\n",
      "[0.00962067 0.03015137 0.046875   ... 0.10095215 0.0174408  0.02406311]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00510025 -0.02642822  0.0218811  ...  0.00884247  0.00769424\n",
      "  -0.02748108]\n",
      " [ 0.04440308  0.00695801  0.02655029 ...  0.0099411  -0.00333786\n",
      "   0.03436279]\n",
      " [-0.02468872  0.00897217 -0.03123474 ...  0.00654221  0.01843262\n",
      "  -0.02189636]\n",
      " ...\n",
      " [-0.01049805 -0.00035787  0.06246948 ...  0.02435303  0.02711487\n",
      "  -0.01774597]\n",
      " [ 0.00430298  0.0189209   0.03610229 ...  0.0088501   0.03108215\n",
      "  -0.0044136 ]\n",
      " [ 0.02362061 -0.05636597 -0.00129986 ... -0.01800537 -0.02516174\n",
      "  -0.02468872]]\n",
      "torch.Size([1024])\n",
      "[-0.0501709   0.1439209  -0.1538086  ...  0.05825806 -0.04696655\n",
      "  0.03625488]\n",
      "torch.Size([1024])\n",
      "[0.97802734 0.9946289  1.0039062  ... 0.9916992  0.9916992  0.9765625 ]\n",
      "torch.Size([1024])\n",
      "[-0.21313477  0.00775528 -0.34985352 ... -0.06262207 -0.07104492\n",
      " -0.03518677]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.00274658 -0.03598022 -0.00682831 ...  0.05209351  0.02571106\n",
      "   0.03820801]\n",
      " [ 0.10369873  0.05957031  0.00426483 ...  0.0592041   0.03051758\n",
      "  -0.08575439]\n",
      " [ 0.00211334  0.04205322 -0.00716019 ...  0.03704834  0.00712967\n",
      "  -0.03421021]\n",
      " ...\n",
      " [ 0.05749512  0.01125336  0.00827026 ... -0.00458145  0.05001831\n",
      "  -0.10339355]\n",
      " [ 0.05154419  0.00539017  0.01344299 ...  0.06100464 -0.02781677\n",
      "   0.03738403]\n",
      " [ 0.06829834  0.02098083  0.03692627 ...  0.01776123  0.00082731\n",
      "   0.00754929]]\n",
      "torch.Size([4096])\n",
      "[ 0.02505493 -0.04608154 -0.05615234 ... -0.05410767 -0.06268311\n",
      "  0.03692627]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.00956726  0.03320312 -0.00192165 ...  0.00867462  0.0272522\n",
      "  -0.05276489]\n",
      " [ 0.02088928  0.04153442  0.00428772 ... -0.01937866  0.04421997\n",
      "   0.00995636]\n",
      " [-0.01469421  0.021698   -0.00694275 ... -0.00328636 -0.00691605\n",
      "  -0.00111008]\n",
      " ...\n",
      " [ 0.04748535 -0.05752563  0.06311035 ... -0.02101135 -0.01672363\n",
      "  -0.01029205]\n",
      " [ 0.01371765  0.02885437 -0.04248047 ...  0.00944519 -0.03588867\n",
      "   0.01316833]\n",
      " [ 0.02270508 -0.04055786 -0.00091791 ... -0.02915955 -0.06100464\n",
      "  -0.01261902]]\n",
      "torch.Size([1024])\n",
      "[-0.17590332 -0.01021576 -0.00597382 ... -0.01441193 -0.08325195\n",
      " -0.10522461]\n",
      "torch.Size([1024])\n",
      "[0.984375   0.99316406 1.0048828  ... 0.97558594 0.97998047 0.9897461 ]\n",
      "torch.Size([1024])\n",
      "[ 0.08514404 -0.08807373  0.1751709  ... -0.03781128 -0.01907349\n",
      " -0.07202148]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04882812 -0.02555847  0.08575439 ... -0.00101852  0.04998779\n",
      "   0.05358887]\n",
      " [-0.01589966  0.0054245   0.01353455 ... -0.0769043  -0.06677246\n",
      "   0.04916382]\n",
      " [-0.05395508  0.03613281 -0.1340332  ...  0.05700684  0.02636719\n",
      "   0.05200195]\n",
      " ...\n",
      " [ 0.02453613  0.02163696  0.28979492 ... -0.00997925  0.09295654\n",
      "  -0.01939392]\n",
      " [-0.08276367  0.01309967 -0.10931396 ... -0.03405762  0.01270294\n",
      "  -0.02197266]\n",
      " [-0.00596619 -0.00679398 -0.03041077 ... -0.08728027 -0.00256157\n",
      "  -0.08319092]]\n",
      "torch.Size([1024])\n",
      "[ 0.00536728 -0.00748825  0.00358391 ... -0.2409668  -0.01968384\n",
      " -0.0043602 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-2.82440186e-02 -1.24572754e-01  7.50122070e-02 ...  3.49426270e-02\n",
      "  -1.96990967e-02  6.44531250e-02]\n",
      " [ 1.18957520e-01  2.52532959e-02 -7.41577148e-02 ... -7.44819641e-04\n",
      "  -2.59399414e-02 -1.86157227e-02]\n",
      " [-4.13513184e-02  3.20434570e-02 -1.07238770e-01 ... -7.51342773e-02\n",
      "  -4.46777344e-02 -1.89685822e-03]\n",
      " ...\n",
      " [-6.19888306e-03  1.40533447e-02 -3.70117188e-01 ...  5.91125488e-02\n",
      "  -5.22994995e-03 -8.45336914e-03]\n",
      " [ 2.63519287e-02 -9.79423523e-04 -1.92749023e-01 ... -2.71453857e-02\n",
      "   5.59616089e-03  5.40161133e-02]\n",
      " [ 1.54018402e-04 -4.59289551e-02 -9.66796875e-02 ...  4.77905273e-02\n",
      "   8.38470459e-03  9.25445557e-03]]\n",
      "torch.Size([1024])\n",
      "[ 0.00016391 -0.00090408  0.00038981 ... -0.0111084   0.00268745\n",
      " -0.00416565]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.08850098 -0.00140953  0.00820923 ...  0.04351807 -0.00560379\n",
      "  -0.00827026]\n",
      " [ 0.02981567  0.10003662 -0.01207733 ... -0.01184845  0.03010559\n",
      "   0.08288574]\n",
      " [ 0.01875305  0.00543976  0.00022459 ... -0.03997803 -0.04251099\n",
      "   0.03271484]\n",
      " ...\n",
      " [-0.0252533  -0.0458374  -0.01506042 ... -0.00510025 -0.01232147\n",
      "   0.05755615]\n",
      " [-0.04003906 -0.04202271  0.02355957 ... -0.01096344 -0.03894043\n",
      "   0.06115723]\n",
      " [ 0.00191593 -0.02493286 -0.00080252 ... -0.03460693  0.0317688\n",
      "   0.02844238]]\n",
      "torch.Size([1024])\n",
      "[ 0.00542068 -0.00717926  0.00026655 ...  0.02926636  0.01577759\n",
      "  0.03158569]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04782104 -0.0254364   0.08551025 ... -0.00119209  0.05023193\n",
      "   0.05325317]\n",
      " [-0.01797485  0.0039444   0.01150513 ... -0.07873535 -0.06561279\n",
      "   0.04946899]\n",
      " [-0.05233765  0.03656006 -0.13293457 ...  0.05725098  0.02587891\n",
      "   0.05215454]\n",
      " ...\n",
      " [ 0.02424622  0.02140808  0.2902832  ... -0.0090332   0.09417725\n",
      "  -0.01869202]\n",
      " [-0.08337402  0.01343536 -0.11022949 ... -0.03369141  0.01243591\n",
      "  -0.02255249]\n",
      " [-0.00671387 -0.00637817 -0.03182983 ... -0.08691406 -0.0018177\n",
      "  -0.08398438]]\n",
      "torch.Size([1024])\n",
      "[ 0.00560379 -0.00509262  0.00247002 ... -0.24121094 -0.01904297\n",
      " -0.00315285]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04754639 -0.0249939   0.08624268 ... -0.00029969  0.05007935\n",
      "   0.05426025]\n",
      " [-0.01779175  0.00398254  0.01176453 ... -0.07806396 -0.06573486\n",
      "   0.04940796]\n",
      " [-0.05343628  0.03640747 -0.13317871 ...  0.05688477  0.0259552\n",
      "   0.05209351]\n",
      " ...\n",
      " [ 0.0246582   0.02078247  0.28979492 ... -0.00928497  0.09356689\n",
      "  -0.0186615 ]\n",
      " [-0.08306885  0.01344299 -0.11004639 ... -0.03393555  0.01303101\n",
      "  -0.02241516]\n",
      " [-0.00570297 -0.00671387 -0.03102112 ... -0.08654785 -0.00174236\n",
      "  -0.08300781]]\n",
      "torch.Size([1024])\n",
      "[ 0.00482559 -0.00546265  0.00259018 ... -0.24072266 -0.01901245\n",
      " -0.00413132]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04647827 -0.02391052  0.08514404 ... -0.0013361   0.04959106\n",
      "   0.05447388]\n",
      " [-0.01776123  0.00370407  0.01273346 ... -0.07696533 -0.0657959\n",
      "   0.04901123]\n",
      " [-0.05255127  0.03695679 -0.13427734 ...  0.05596924  0.0267334\n",
      "   0.05252075]\n",
      " ...\n",
      " [ 0.02488708  0.02095032  0.2902832  ... -0.0099411   0.09393311\n",
      "  -0.01869202]\n",
      " [-0.08288574  0.01361084 -0.10913086 ... -0.03347778  0.01261139\n",
      "  -0.02255249]\n",
      " [-0.00580978 -0.00585938 -0.03091431 ... -0.08746338 -0.00198746\n",
      "  -0.08319092]]\n",
      "torch.Size([1024])\n",
      "[ 0.00608063 -0.00662613  0.00361633 ... -0.24084473 -0.01947021\n",
      " -0.00380135]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04135132 -0.01676941 -0.02104187 ...  0.01832581 -0.00352287\n",
      "  -0.00643539]\n",
      " [-0.04690552  0.01264954 -0.04321289 ... -0.03067017  0.00236511\n",
      "   0.01535034]\n",
      " [-0.04119873 -0.02027893  0.02760315 ...  0.01493835  0.03918457\n",
      "   0.00244522]\n",
      " ...\n",
      " [ 0.01654053 -0.01129913 -0.0402832  ... -0.00974274  0.01560974\n",
      "   0.03012085]\n",
      " [-0.00122166 -0.02911377  0.01979065 ... -0.02476501  0.01834106\n",
      "  -0.01641846]\n",
      " [ 0.00388336  0.03881836  0.04147339 ... -0.00725937 -0.03399658\n",
      "  -0.03039551]]\n",
      "torch.Size([1024])\n",
      "[ 0.02984619 -0.00236893  0.06323242 ... -0.01396179 -0.04193115\n",
      " -0.00739288]\n",
      "torch.Size([1024])\n",
      "[0.9916992  0.9814453  1.0029297  ... 0.9838867  0.98046875 0.9848633 ]\n",
      "torch.Size([1024])\n",
      "[-0.16516113  0.00265503 -0.3046875  ... -0.02902222 -0.14367676\n",
      " -0.03607178]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.07391357 -0.02986145  0.01649475 ... -0.01000977 -0.00592041\n",
      "   0.00894928]\n",
      " [-0.01538086 -0.02877808  0.01783752 ... -0.04229736 -0.03961182\n",
      "  -0.02342224]\n",
      " [-0.04376221 -0.0428772   0.08532715 ...  0.00352669 -0.01997375\n",
      "  -0.02388   ]\n",
      " ...\n",
      " [ 0.01808167 -0.04653931  0.02629089 ... -0.12213135 -0.01647949\n",
      "  -0.0052681 ]\n",
      " [ 0.01890564 -0.05023193  0.01449585 ... -0.04956055 -0.02189636\n",
      "   0.04855347]\n",
      " [ 0.02328491  0.01192474 -0.00558853 ...  0.01663208 -0.02766418\n",
      "  -0.00939178]]\n",
      "torch.Size([4096])\n",
      "[-0.1081543  -0.04019165 -0.00907898 ... -0.12243652 -0.08496094\n",
      " -0.10540771]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.03053284 -0.00233459 -0.07019043 ...  0.02668762  0.02729797\n",
      "  -0.01887512]\n",
      " [-0.01228333  0.02088928  0.0145874  ... -0.02796936  0.00579071\n",
      "  -0.03457642]\n",
      " [ 0.00210762  0.00065088 -0.01489258 ... -0.00396347 -0.02532959\n",
      "   0.00043225]\n",
      " ...\n",
      " [-0.01035309 -0.01077271  0.01646423 ... -0.04260254 -0.01573181\n",
      "  -0.02366638]\n",
      " [-0.02030945 -0.0099411  -0.02003479 ... -0.012146   -0.02922058\n",
      "   0.02079773]\n",
      " [-0.05142212 -0.03399658  0.03216553 ...  0.0073967  -0.00348854\n",
      "  -0.01222992]]\n",
      "torch.Size([1024])\n",
      "[-0.21850586  0.16601562 -0.0793457  ... -0.0086441  -0.07977295\n",
      " -0.12408447]\n",
      "torch.Size([1024])\n",
      "[0.9863281  0.9926758  1.0009766  ... 0.9873047  0.98339844 0.99072266]\n",
      "torch.Size([1024])\n",
      "[ 0.00814819 -0.07928467  0.0836792  ... -0.07000732 -0.0121994\n",
      " -0.06173706]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04669189  0.04989624 -0.04745483 ... -0.0418396   0.04452515\n",
      "  -0.05523682]\n",
      " [-0.02575684 -0.00888824  0.05029297 ...  0.0328064   0.02865601\n",
      "   0.06231689]\n",
      " [-0.00294685 -0.025177    0.00063229 ... -0.03601074 -0.07794189\n",
      "  -0.01028442]\n",
      " ...\n",
      " [ 0.06646729 -0.00657272  0.0291748  ...  0.00562286 -0.01820374\n",
      "  -0.00720978]\n",
      " [-0.0050354  -0.02661133 -0.1427002  ...  0.04412842  0.02072144\n",
      "  -0.02742004]\n",
      " [ 0.05038452  0.05102539 -0.15759277 ...  0.02301025  0.0385437\n",
      "   0.06750488]]\n",
      "torch.Size([1024])\n",
      "[-0.04946899  0.04354858  0.00699615 ...  0.04177856  0.17883301\n",
      "  0.0484314 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02424622  0.06396484 -0.04196167 ... -0.01470184  0.02737427\n",
      "  -0.06933594]\n",
      " [ 0.05618286 -0.00426483  0.07366943 ... -0.03311157 -0.00735474\n",
      "  -0.034729  ]\n",
      " [ 0.01828003  0.06524658 -0.04083252 ...  0.15588379  0.02871704\n",
      "  -0.07928467]\n",
      " ...\n",
      " [-0.04812622 -0.04983521 -0.012146   ... -0.02217102  0.01341248\n",
      "  -0.02642822]\n",
      " [ 0.02212524  0.03039551 -0.2097168  ... -0.02005005 -0.01858521\n",
      "   0.00122547]\n",
      " [-0.03945923  0.04501343 -0.13183594 ...  0.02072144  0.01072693\n",
      "   0.03059387]]\n",
      "torch.Size([1024])\n",
      "[ 0.00670624 -0.00089025  0.00478363 ...  0.00310707  0.00318718\n",
      "  0.00262451]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.05493164  0.06439209 -0.0161438  ...  0.03460693  0.00510406\n",
      "   0.0380249 ]\n",
      " [ 0.01805115  0.05484009  0.00662613 ... -0.03707886 -0.02090454\n",
      "   0.02558899]\n",
      " [-0.00511169  0.04614258 -0.0020504  ... -0.02101135 -0.05731201\n",
      "   0.03808594]\n",
      " ...\n",
      " [ 0.04272461 -0.0723877   0.01812744 ...  0.00039577 -0.01548767\n",
      "  -0.02351379]\n",
      " [-0.00182056 -0.00049829 -0.03912354 ...  0.00997162 -0.10656738\n",
      "  -0.01029205]\n",
      " [-0.04101562 -0.0927124   0.0247345  ...  0.00098801 -0.00723267\n",
      "  -0.01754761]]\n",
      "torch.Size([1024])\n",
      "[ 0.01134491  0.00827789  0.00699234 ... -0.0063591  -0.00731659\n",
      " -0.00093889]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04598999  0.04995728 -0.04782104 ... -0.04229736  0.04537964\n",
      "  -0.05535889]\n",
      " [-0.02522278 -0.0087204   0.05056763 ...  0.03363037  0.03004456\n",
      "   0.06274414]\n",
      " [-0.00260353 -0.02511597  0.00082588 ... -0.03683472 -0.07775879\n",
      "  -0.01042175]\n",
      " ...\n",
      " [ 0.06695557 -0.00802612  0.02922058 ...  0.00543594 -0.01739502\n",
      "  -0.00767136]\n",
      " [-0.00580215 -0.02597046 -0.14343262 ...  0.04296875  0.01992798\n",
      "  -0.02767944]\n",
      " [ 0.05020142  0.05078125 -0.1583252  ...  0.02418518  0.03820801\n",
      "   0.06689453]]\n",
      "torch.Size([1024])\n",
      "[-0.04922485  0.04336548  0.00623322 ...  0.04226685  0.17944336\n",
      "  0.0480957 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 4.5684814e-02  4.8980713e-02 -4.7729492e-02 ... -4.1076660e-02\n",
      "   4.5043945e-02 -5.5938721e-02]\n",
      " [-2.5772095e-02 -8.7661743e-03  4.9743652e-02 ...  3.2806396e-02\n",
      "   2.9464722e-02  6.2927246e-02]\n",
      " [-3.0117035e-03 -2.5070190e-02 -1.3732910e-04 ... -3.6773682e-02\n",
      "  -7.7758789e-02 -1.0719299e-02]\n",
      " ...\n",
      " [ 6.7077637e-02 -6.6223145e-03  2.8182983e-02 ...  4.0321350e-03\n",
      "  -1.7349243e-02 -6.1225891e-03]\n",
      " [-5.7716370e-03 -2.5436401e-02 -1.4306641e-01 ...  4.3975830e-02\n",
      "   1.9882202e-02 -2.7832031e-02]\n",
      " [ 4.9652100e-02  4.9957275e-02 -1.5698242e-01 ...  2.4917603e-02\n",
      "   3.8543701e-02  6.6162109e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.04940796  0.04431152  0.00761032 ...  0.04364014  0.17895508\n",
      "  0.046875  ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04598999  0.04916382 -0.04882812 ... -0.04257202  0.0456543\n",
      "  -0.0557251 ]\n",
      " [-0.02560425 -0.00914001  0.05010986 ...  0.03289795  0.02955627\n",
      "   0.06286621]\n",
      " [-0.00331879 -0.02581787 -0.00028729 ... -0.03665161 -0.07684326\n",
      "  -0.01067352]\n",
      " ...\n",
      " [ 0.0668335  -0.00725174  0.02859497 ...  0.00460434 -0.01727295\n",
      "  -0.00688553]\n",
      " [-0.00526428 -0.02557373 -0.1430664  ...  0.04312134  0.01971436\n",
      "  -0.02774048]\n",
      " [ 0.04946899  0.05050659 -0.15820312 ...  0.0239563   0.03820801\n",
      "   0.06640625]]\n",
      "torch.Size([1024])\n",
      "[-0.04858398  0.04403687  0.00730896 ...  0.04269409  0.17932129\n",
      "  0.04794312]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00118637 -0.03890991  0.03004456 ... -0.04986572  0.00242043\n",
      "   0.10192871]\n",
      " [ 0.00778961  0.00945282 -0.0061264  ...  0.00627136 -0.06896973\n",
      "   0.0446167 ]\n",
      " [-0.00353813 -0.01087189 -0.01791382 ...  0.01600647 -0.01829529\n",
      "  -0.00271034]\n",
      " ...\n",
      " [-0.03933716 -0.00313759 -0.04544067 ...  0.00067377 -0.04223633\n",
      "   0.01847839]\n",
      " [-0.04122925  0.06088257 -0.00317574 ...  0.01473999  0.07678223\n",
      "  -0.02902222]\n",
      " [ 0.00174713  0.00613403  0.0103302  ...  0.01960754  0.03485107\n",
      "   0.04882812]]\n",
      "torch.Size([1024])\n",
      "[-0.04290771  0.04391479 -0.09014893 ...  0.03695679 -0.03341675\n",
      "  0.03408813]\n",
      "torch.Size([1024])\n",
      "[0.97753906 0.9892578  1.0019531  ... 0.98876953 0.9824219  0.9765625 ]\n",
      "torch.Size([1024])\n",
      "[-0.17932129  0.0703125  -0.27172852 ... -0.05984497 -0.11883545\n",
      " -0.0612793 ]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.02171326 -0.02545166  0.01841736 ... -0.03001404 -0.05612183\n",
      "  -0.04724121]\n",
      " [ 0.03256226  0.00153446  0.00897217 ...  0.0496521   0.02435303\n",
      "   0.00136471]\n",
      " [ 0.05831909 -0.04232788  0.05343628 ...  0.11651611 -0.01112366\n",
      "  -0.06072998]\n",
      " ...\n",
      " [ 0.02919006 -0.01451874 -0.0065155  ... -0.01160431  0.03720093\n",
      "   0.0075798 ]\n",
      " [ 0.01406097  0.03985596  0.09490967 ...  0.04806519  0.0397644\n",
      "  -0.03665161]\n",
      " [ 0.03640747 -0.12915039  0.0402832  ...  0.0048027  -0.00092697\n",
      "  -0.07592773]]\n",
      "torch.Size([4096])\n",
      "[-0.13671875 -0.05166626 -0.08905029 ... -0.10296631 -0.03411865\n",
      " -0.03817749]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 6.0638428e-02 -3.4729004e-02 -4.3060303e-02 ... -3.4851074e-02\n",
      "   1.4038086e-02 -8.1481934e-03]\n",
      " [-1.1390686e-02  5.9814453e-03 -5.6060791e-02 ...  8.0718994e-03\n",
      "   2.1621704e-02 -2.4230957e-02]\n",
      " [ 1.2413025e-02  3.7689209e-03  1.7185211e-03 ... -2.6054382e-03\n",
      "   6.1264038e-03 -6.1569214e-03]\n",
      " ...\n",
      " [-2.8533936e-02  3.8482666e-02  4.7531128e-03 ... -3.3843994e-02\n",
      "   1.5281677e-02  3.3081055e-02]\n",
      " [-8.7402344e-02 -2.7877808e-02  3.1112671e-02 ... -1.9165039e-02\n",
      "   5.8624268e-02  1.4472961e-02]\n",
      " [-2.8518677e-02 -3.8480759e-04 -2.4810791e-02 ... -2.4536133e-02\n",
      "  -1.4364719e-05 -4.0710449e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.1071167   0.05679321 -0.07202148 ... -0.02433777 -0.05026245\n",
      " -0.08807373]\n",
      "torch.Size([1024])\n",
      "[0.9848633  0.99121094 1.0009766  ... 0.98828125 0.9873047  0.9921875 ]\n",
      "torch.Size([1024])\n",
      "[ 0.06768799 -0.11749268  0.23852539 ... -0.05407715 -0.00392914\n",
      " -0.04458618]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04400635 -0.06063843  0.00871277 ... -0.1204834  -0.02189636\n",
      "  -0.16003418]\n",
      " [-0.0602417   0.02937317 -0.09667969 ...  0.0375061  -0.01982117\n",
      "  -0.03833008]\n",
      " [-0.0040741  -0.02883911  0.10784912 ... -0.01085663 -0.06060791\n",
      "   0.0385437 ]\n",
      " ...\n",
      " [ 0.06329346  0.00062513  0.02127075 ... -0.03817749 -0.06793213\n",
      "   0.0397644 ]\n",
      " [-0.01734924  0.03897095 -0.01821899 ... -0.09216309 -0.02481079\n",
      "   0.05661011]\n",
      " [-0.06591797  0.02287292  0.00899506 ...  0.05407715  0.03167725\n",
      "   0.03805542]]\n",
      "torch.Size([1024])\n",
      "[ 0.19189453  0.14135742 -0.12390137 ...  0.23400879 -0.11859131\n",
      "  0.0177002 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03518677  0.08105469  0.07098389 ...  0.00907898  0.00448227\n",
      "  -0.00956726]\n",
      " [-0.06628418 -0.00611115 -0.12463379 ... -0.0135498   0.00708008\n",
      "   0.04702759]\n",
      " [-0.02320862  0.02690125  0.04760742 ...  0.01931763 -0.11627197\n",
      "   0.06158447]\n",
      " ...\n",
      " [ 0.07843018 -0.0635376   0.06555176 ... -0.09613037 -0.04507446\n",
      "  -0.0300293 ]\n",
      " [ 0.04672241  0.08691406  0.04373169 ... -0.0758667   0.06567383\n",
      "   0.03881836]\n",
      " [-0.06884766 -0.00519562  0.05584717 ... -0.00342178 -0.04910278\n",
      "  -0.02459717]]\n",
      "torch.Size([1024])\n",
      "[-0.00117874  0.00149059 -0.00641251 ...  0.00057936 -0.0010004\n",
      "  0.00366783]\n",
      "torch.Size([1024, 1024])\n",
      "[[-4.3426514e-02  5.7339668e-05  4.2541504e-02 ... -4.4189453e-02\n",
      "  -5.5236816e-03 -7.8582764e-03]\n",
      " [-2.8247833e-03 -6.8664551e-02 -8.7127686e-03 ...  6.2622070e-02\n",
      "   6.3415527e-02 -5.0537109e-02]\n",
      " [ 2.4673462e-02 -3.5919189e-02 -2.5497437e-02 ... -6.7382812e-02\n",
      "   1.3374329e-02  2.2842407e-02]\n",
      " ...\n",
      " [ 8.0871582e-02  2.5451660e-02 -1.7333984e-02 ...  1.9119263e-02\n",
      "  -2.5955200e-02 -3.3264160e-02]\n",
      " [ 7.1044922e-02  1.5243530e-02 -1.3084412e-02 ... -5.0773621e-03\n",
      "  -2.0507812e-02  2.7557373e-02]\n",
      " [-7.5622559e-02 -4.0191650e-02 -2.3071289e-02 ... -2.8781891e-03\n",
      "   4.7790527e-02 -1.3073730e-01]]\n",
      "torch.Size([1024])\n",
      "[-3.5119057e-04  6.4239502e-03 -1.1985779e-02 ... -9.7513199e-05\n",
      "  5.2490234e-03  1.3374329e-02]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04360962 -0.0602417   0.00911713 ... -0.11914062 -0.02156067\n",
      "  -0.1595459 ]\n",
      " [-0.06072998  0.02922058 -0.09570312 ...  0.03707886 -0.01898193\n",
      "  -0.03808594]\n",
      " [-0.00328827 -0.02893066  0.10821533 ... -0.00974274 -0.06021118\n",
      "   0.03845215]\n",
      " ...\n",
      " [ 0.0625      0.00031495  0.02212524 ... -0.03845215 -0.06799316\n",
      "   0.04052734]\n",
      " [-0.01817322  0.0390625  -0.01821899 ... -0.09338379 -0.02357483\n",
      "   0.05697632]\n",
      " [-0.06616211  0.02272034  0.00801086 ...  0.05377197  0.03286743\n",
      "   0.03775024]]\n",
      "torch.Size([1024])\n",
      "[ 0.19238281  0.13989258 -0.12432861 ...  0.2331543  -0.11907959\n",
      "  0.01828003]\n",
      "torch.Size([1024, 1024])\n",
      "[[-4.41589355e-02 -6.04248047e-02  8.87298584e-03 ... -1.19628906e-01\n",
      "  -2.25067139e-02 -1.59790039e-01]\n",
      " [-6.05468750e-02  3.01055908e-02 -9.69848633e-02 ...  3.66210938e-02\n",
      "  -1.93634033e-02 -3.78417969e-02]\n",
      " [-3.37409973e-03 -2.88085938e-02  1.07666016e-01 ... -1.08108521e-02\n",
      "  -5.99975586e-02  3.82690430e-02]\n",
      " ...\n",
      " [ 6.29272461e-02  5.33461571e-05  2.14233398e-02 ... -3.78723145e-02\n",
      "  -6.62841797e-02  3.96728516e-02]\n",
      " [-1.87225342e-02  3.86352539e-02 -1.75018311e-02 ... -9.28344727e-02\n",
      "  -2.39257812e-02  5.63049316e-02]\n",
      " [-6.70166016e-02  2.28424072e-02  7.77816772e-03 ...  5.24597168e-02\n",
      "   3.15246582e-02  3.84216309e-02]]\n",
      "torch.Size([1024])\n",
      "[ 0.19250488  0.14074707 -0.12384033 ...  0.23339844 -0.11975098\n",
      "  0.01835632]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04333496 -0.05957031  0.00814056 ... -0.11993408 -0.02180481\n",
      "  -0.15942383]\n",
      " [-0.06082153  0.03009033 -0.09680176 ...  0.03704834 -0.01939392\n",
      "  -0.03793335]\n",
      " [-0.00341225 -0.02914429  0.1072998  ... -0.01055145 -0.06008911\n",
      "   0.03811646]\n",
      " ...\n",
      " [ 0.06219482 -0.00062227  0.02244568 ... -0.03817749 -0.06732178\n",
      "   0.03991699]\n",
      " [-0.01800537  0.03918457 -0.01898193 ... -0.09387207 -0.02355957\n",
      "   0.05743408]\n",
      " [-0.06640625  0.02331543  0.00772095 ...  0.05340576  0.03244019\n",
      "   0.03811646]]\n",
      "torch.Size([1024])\n",
      "[ 0.1932373   0.14086914 -0.12359619 ...  0.23242188 -0.11804199\n",
      "  0.01858521]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00564575 -0.02235413  0.04434204 ... -0.04275513 -0.00070524\n",
      "   0.08404541]\n",
      " [ 0.01275635 -0.04391479  0.0451355  ... -0.07318115 -0.04571533\n",
      "  -0.00540543]\n",
      " [ 0.03796387 -0.03436279  0.01194    ...  0.00333405  0.01413727\n",
      "  -0.02018738]\n",
      " ...\n",
      " [ 0.06726074 -0.03509521  0.06829834 ...  0.00971985 -0.00601196\n",
      "  -0.01154327]\n",
      " [-0.00245476 -0.06530762 -0.01902771 ...  0.02709961  0.0057869\n",
      "  -0.0071373 ]\n",
      " [-0.00921631 -0.02664185  0.02360535 ...  0.0657959   0.02308655\n",
      "   0.07196045]]\n",
      "torch.Size([1024])\n",
      "[-0.02305603  0.00199127  0.03222656 ...  0.06390381 -0.04138184\n",
      " -0.00546265]\n",
      "torch.Size([1024])\n",
      "[0.99560547 0.9819336  1.0039062  ... 0.9892578  0.98876953 0.9868164 ]\n",
      "torch.Size([1024])\n",
      "[-0.08691406 -0.01493073 -0.19702148 ... -0.06445312 -0.13793945\n",
      " -0.05328369]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.00747681 -0.00196838  0.03979492 ...  0.00122547 -0.01524353\n",
      "   0.04202271]\n",
      " [ 0.01731873 -0.05053711 -0.0079422  ...  0.05953979 -0.02886963\n",
      "   0.04598999]\n",
      " [ 0.04452515 -0.06726074  0.01237488 ...  0.06829834  0.06842041\n",
      "  -0.05688477]\n",
      " ...\n",
      " [ 0.07049561 -0.03805542  0.01040649 ...  0.00891876 -0.0034771\n",
      "  -0.03213501]\n",
      " [-0.03359985 -0.05493164 -0.01316833 ...  0.02890015  0.01200867\n",
      "   0.01901245]\n",
      " [ 0.03842163 -0.04455566 -0.06781006 ...  0.0355835  -0.0184021\n",
      "   0.00679779]]\n",
      "torch.Size([4096])\n",
      "[-0.10791016 -0.10949707 -0.11169434 ... -0.05764771 -0.07958984\n",
      " -0.08099365]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.021698    0.0294342   0.00870514 ...  0.02841187  0.00888824\n",
      "  -0.06408691]\n",
      " [ 0.00347328 -0.01148224 -0.08660889 ... -0.00772858  0.01565552\n",
      "  -0.06530762]\n",
      " [-0.00965118 -0.02000427  0.03564453 ...  0.00831604  0.00328445\n",
      "   0.01247406]\n",
      " ...\n",
      " [ 0.05734253  0.00701904  0.00952911 ... -0.04458618  0.03530884\n",
      "  -0.03030396]\n",
      " [-0.05255127  0.01280975  0.02709961 ...  0.04556274  0.00318527\n",
      "  -0.03131104]\n",
      " [ 0.02449036  0.00827789 -0.05929565 ... -0.00616455 -0.01664734\n",
      "  -0.06915283]]\n",
      "torch.Size([1024])\n",
      "[-0.10913086  0.04949951 -0.19543457 ... -0.01148224 -0.12915039\n",
      " -0.06878662]\n",
      "torch.Size([1024])\n",
      "[0.9902344  0.99316406 1.0039062  ... 0.98828125 0.9897461  0.9902344 ]\n",
      "torch.Size([1024])\n",
      "[-0.02450562 -0.11004639  0.24768066 ... -0.05203247 -0.01515961\n",
      " -0.0586853 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06201172  0.05728149 -0.13415527 ... -0.02011108  0.04336548\n",
      "   0.02351379]\n",
      " [-0.02067566  0.01638794  0.08184814 ...  0.08892822 -0.02845764\n",
      "  -0.01837158]\n",
      " [ 0.00102711 -0.01849365 -0.02784729 ... -0.05938721  0.046875\n",
      "  -0.07824707]\n",
      " ...\n",
      " [ 0.04907227  0.11749268 -0.02700806 ...  0.02655029 -0.01885986\n",
      "   0.01039124]\n",
      " [-0.01927185  0.08813477  0.03530884 ... -0.00107288 -0.05859375\n",
      "   0.04162598]\n",
      " [-0.06091309 -0.03111267  0.00990295 ... -0.00827026  0.09466553\n",
      "  -0.05477905]]\n",
      "torch.Size([1024])\n",
      "[-0.01303101 -0.07263184 -0.02531433 ... -0.11688232 -0.0904541\n",
      " -0.00383186]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04370117  0.02027893 -0.21899414 ... -0.08428955 -0.00948334\n",
      "  -0.01241302]\n",
      " [ 0.06347656 -0.02267456 -0.05432129 ... -0.01160431  0.00228691\n",
      "  -0.02296448]\n",
      " [-0.03405762  0.08337402 -0.07617188 ... -0.03717041 -0.05981445\n",
      "  -0.0166626 ]\n",
      " ...\n",
      " [ 0.01262665  0.01980591 -0.05474854 ... -0.10583496  0.03567505\n",
      "  -0.01644897]\n",
      " [-0.09436035 -0.01727295 -0.04232788 ... -0.00550079  0.01358795\n",
      "   0.027771  ]\n",
      " [ 0.05426025 -0.03848267  0.02549744 ... -0.03283691  0.04629517\n",
      "   0.05621338]]\n",
      "torch.Size([1024])\n",
      "[ 0.00090599  0.0151062   0.00540543 ... -0.00163269  0.00332069\n",
      " -0.00329399]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.07073975  0.04611206  0.00566483 ...  0.00103474 -0.0218811\n",
      "   0.06140137]\n",
      " [-0.01397705 -0.03013611 -0.03244019 ... -0.03924561  0.04058838\n",
      "  -0.06982422]\n",
      " [-0.00165081 -0.00843048  0.00310898 ... -0.10662842  0.10229492\n",
      "   0.09979248]\n",
      " ...\n",
      " [ 0.01514435 -0.05847168 -0.00052881 ...  0.0378418  -0.01006317\n",
      "   0.07543945]\n",
      " [-0.0451355  -0.08679199  0.00353813 ...  0.05874634  0.01681519\n",
      "   0.01277924]\n",
      " [-0.06100464  0.00258446 -0.01277924 ... -0.07110596 -0.10552979\n",
      "   0.00489044]]\n",
      "torch.Size([1024])\n",
      "[-0.00444412  0.00500107  0.00057745 ...  0.00316429 -0.00435638\n",
      " -0.02122498]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06149292  0.05563354 -0.13391113 ... -0.02081299  0.04248047\n",
      "   0.02368164]\n",
      " [-0.02037048  0.014534    0.0824585  ...  0.08856201 -0.0284729\n",
      "  -0.01727295]\n",
      " [ 0.00210571 -0.01676941 -0.02720642 ... -0.05981445  0.04641724\n",
      "  -0.07775879]\n",
      " ...\n",
      " [ 0.04876709  0.11761475 -0.02694702 ...  0.02587891 -0.02001953\n",
      "   0.01004791]\n",
      " [-0.01965332  0.08782959  0.03503418 ... -0.00015438 -0.05834961\n",
      "   0.04083252]\n",
      " [-0.06167603 -0.03182983  0.00938416 ... -0.00857544  0.09460449\n",
      "  -0.05560303]]\n",
      "torch.Size([1024])\n",
      "[-0.01259613 -0.07312012 -0.02651978 ... -0.11663818 -0.08966064\n",
      " -0.00312424]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 6.08215332e-02  5.61218262e-02 -1.34033203e-01 ... -2.10266113e-02\n",
      "   4.23889160e-02  2.42309570e-02]\n",
      " [-1.97143555e-02  1.51901245e-02  8.29467773e-02 ...  8.83178711e-02\n",
      "  -2.86407471e-02 -1.82495117e-02]\n",
      " [ 1.71852112e-03 -1.76086426e-02 -2.74047852e-02 ... -5.85021973e-02\n",
      "   4.69970703e-02 -7.75146484e-02]\n",
      " ...\n",
      " [ 4.86450195e-02  1.17919922e-01 -2.69317627e-02 ...  2.65960693e-02\n",
      "  -1.91955566e-02  9.83428955e-03]\n",
      " [-1.96533203e-02  8.75854492e-02  3.49426270e-02 ...  1.76429749e-05\n",
      "  -5.85937500e-02  4.13513184e-02]\n",
      " [-6.16760254e-02 -3.24401855e-02  9.79614258e-03 ... -8.01849365e-03\n",
      "   9.45434570e-02 -5.52368164e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.01287079 -0.07373047 -0.02566528 ... -0.11700439 -0.09002686\n",
      " -0.00358009]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.06195068  0.05648804 -0.13293457 ... -0.02079773  0.04211426\n",
      "   0.02442932]\n",
      " [-0.02076721  0.01501465  0.08270264 ...  0.08807373 -0.02932739\n",
      "  -0.0181427 ]\n",
      " [ 0.00072861 -0.01702881 -0.02848816 ... -0.05889893  0.046875\n",
      "  -0.07806396]\n",
      " ...\n",
      " [ 0.04928589  0.11785889 -0.02709961 ...  0.02653503 -0.01986694\n",
      "   0.01042938]\n",
      " [-0.02024841  0.08782959  0.03530884 ... -0.00035    -0.0586853\n",
      "   0.04074097]\n",
      " [-0.06246948 -0.03170776  0.0096283  ... -0.00848389  0.09405518\n",
      "  -0.05569458]]\n",
      "torch.Size([1024])\n",
      "[-0.01348877 -0.07312012 -0.02482605 ... -0.11688232 -0.08984375\n",
      " -0.00322342]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01319885  0.00115204 -0.02032471 ... -0.03320312 -0.02674866\n",
      "   0.02256775]\n",
      " [ 0.00439453  0.02680969 -0.03659058 ... -0.00627518  0.04766846\n",
      "  -0.02331543]\n",
      " [-0.03022766 -0.03591919  0.07263184 ... -0.01663208 -0.01806641\n",
      "  -0.01194763]\n",
      " ...\n",
      " [-0.00051069  0.05819702  0.01442719 ... -0.03424072 -0.00965881\n",
      "   0.0252533 ]\n",
      " [-0.05926514  0.09527588  0.04907227 ... -0.00766373  0.01847839\n",
      "   0.08758545]\n",
      " [ 0.02073669 -0.05426025  0.00818634 ... -0.01237488 -0.03567505\n",
      "  -0.01896667]]\n",
      "torch.Size([1024])\n",
      "[-0.01655579  0.01638794  0.05413818 ...  0.0014782  -0.04779053\n",
      " -0.02864075]\n",
      "torch.Size([1024])\n",
      "[0.98828125 0.9897461  1.0039062  ... 0.98779297 0.9892578  0.98291016]\n",
      "torch.Size([1024])\n",
      "[-0.11114502 -0.01806641 -0.17150879 ... -0.09338379 -0.08074951\n",
      " -0.12438965]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.02145386 -0.01696777  0.02108765 ...  0.01154327  0.04919434\n",
      "  -0.03077698]\n",
      " [ 0.05181885 -0.0553894   0.0037117  ... -0.0226593  -0.04629517\n",
      "  -0.00965118]\n",
      " [-0.03128052  0.04699707  0.02116394 ...  0.09576416  0.00728607\n",
      "   0.02632141]\n",
      " ...\n",
      " [-0.04180908 -0.03900146  0.02050781 ...  0.08093262  0.04162598\n",
      "   0.0274353 ]\n",
      " [-0.03829956  0.0682373   0.05596924 ... -0.00849915  0.02330017\n",
      "  -0.00888062]\n",
      " [ 0.07061768  0.00679016  0.0057106  ...  0.04107666  0.07177734\n",
      "   0.02685547]]\n",
      "torch.Size([4096])\n",
      "[-0.04418945 -0.10705566 -0.07775879 ... -0.03405762  0.01083374\n",
      " -0.08288574]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.02587891  0.0647583  -0.0484314  ... -0.00025797  0.01947021\n",
      "  -0.00523758]\n",
      " [-0.02172852  0.01378632 -0.03338623 ... -0.05599976 -0.00306702\n",
      "  -0.00304985]\n",
      " [-0.01589966 -0.01069641 -0.02368164 ...  0.00033951  0.0148468\n",
      "   0.0125351 ]\n",
      " ...\n",
      " [ 0.00678253  0.02192688  0.05102539 ... -0.00918579  0.00508881\n",
      "   0.00189877]\n",
      " [-0.00222397 -0.00713348  0.06903076 ... -0.04077148 -0.01672363\n",
      "   0.00346375]\n",
      " [-0.04464722  0.01783752  0.02204895 ...  0.0345459  -0.01163483\n",
      "   0.03903198]]\n",
      "torch.Size([1024])\n",
      "[-0.13061523  0.03051758 -0.24804688 ... -0.03201294 -0.08636475\n",
      " -0.10003662]\n",
      "torch.Size([1024])\n",
      "[0.98779297 0.98535156 1.0039062  ... 0.9848633  0.9951172  0.9873047 ]\n",
      "torch.Size([1024])\n",
      "[-0.00821686 -0.06848145  0.17211914 ... -0.01542664 -0.03112793\n",
      " -0.01664734]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01960754  0.00188923 -0.04330444 ... -0.01177979  0.09106445\n",
      "   0.03308105]\n",
      " [-0.0456543  -0.06585693 -0.02471924 ...  0.01316833 -0.02122498\n",
      "  -0.03555298]\n",
      " [ 0.00114059 -0.00637436  0.08270264 ... -0.06719971 -0.05996704\n",
      "  -0.00934601]\n",
      " ...\n",
      " [ 0.0690918  -0.08288574 -0.0294342  ... -0.01635742  0.03762817\n",
      "   0.01933289]\n",
      " [-0.04751587  0.03808594  0.05395508 ... -0.08557129  0.03515625\n",
      "  -0.11181641]\n",
      " [ 0.00991821  0.01250458  0.03567505 ... -0.03384399 -0.08428955\n",
      "  -0.03900146]]\n",
      "torch.Size([1024])\n",
      "[-0.008461   -0.06835938  0.01190186 ... -0.00444794  0.08477783\n",
      "  0.01238251]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.05249023 -0.01612854 -0.03128052 ...  0.0791626  -0.01238251\n",
      "  -0.05221558]\n",
      " [ 0.04867554 -0.01387024 -0.03231812 ...  0.07769775 -0.04470825\n",
      "  -0.02870178]\n",
      " [-0.01673889  0.06933594  0.07855225 ... -0.03320312 -0.06188965\n",
      "   0.03033447]\n",
      " ...\n",
      " [ 0.04925537  0.03411865  0.00494003 ... -0.07543945 -0.0120163\n",
      "  -0.00344849]\n",
      " [ 0.00203896  0.08374023  0.01792908 ... -0.02680969  0.05770874\n",
      "   0.00748062]\n",
      " [ 0.05007935 -0.02172852  0.07568359 ... -0.08825684 -0.03161621\n",
      "   0.04684448]]\n",
      "torch.Size([1024])\n",
      "[-1.5468597e-03 -4.5251846e-04  8.2168579e-03 ... -1.6355515e-03\n",
      " -6.8843365e-05  4.3525696e-03]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04144287 -0.00312805  0.01094818 ...  0.0368042  -0.06097412\n",
      "   0.05136108]\n",
      " [ 0.02774048  0.05935669 -0.03375244 ...  0.00282097  0.02328491\n",
      "   0.08630371]\n",
      " [ 0.01100159  0.00283241 -0.0089798  ... -0.04141235 -0.0536499\n",
      "   0.02798462]\n",
      " ...\n",
      " [-0.05609131 -0.12573242  0.02503967 ... -0.09094238 -0.00777054\n",
      "   0.05526733]\n",
      " [-0.00442886 -0.03231812 -0.03271484 ... -0.02780151  0.00430298\n",
      "   0.12609863]\n",
      " [ 0.03912354  0.12384033 -0.000772   ... -0.0181427   0.01116943\n",
      "  -0.02540588]]\n",
      "torch.Size([1024])\n",
      "[-0.00921631  0.00524139  0.00264931 ... -0.01011658 -0.01451111\n",
      " -0.00952911]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02015686  0.00244141 -0.04330444 ... -0.01140594  0.09002686\n",
      "   0.03323364]\n",
      " [-0.04595947 -0.06640625 -0.02502441 ...  0.01293945 -0.02148438\n",
      "  -0.03549194]\n",
      " [ 0.00115585 -0.00677872  0.08209229 ... -0.06787109 -0.05969238\n",
      "  -0.00872803]\n",
      " ...\n",
      " [ 0.06884766 -0.08355713 -0.02914429 ... -0.01626587  0.03646851\n",
      "   0.01948547]\n",
      " [-0.04751587  0.0383606   0.05343628 ... -0.08551025  0.03567505\n",
      "  -0.11193848]\n",
      " [ 0.01053619  0.01126099  0.03543091 ... -0.03408813 -0.08380127\n",
      "  -0.03952026]]\n",
      "torch.Size([1024])\n",
      "[-0.00758362 -0.06787109  0.01243591 ... -0.00434113  0.08441162\n",
      "  0.01317596]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02072144  0.00218773 -0.04379272 ... -0.01190186  0.09057617\n",
      "   0.03439331]\n",
      " [-0.04650879 -0.06604004 -0.02572632 ...  0.01239777 -0.02145386\n",
      "  -0.03497314]\n",
      " [ 0.00136757 -0.00628662  0.08300781 ... -0.06738281 -0.06033325\n",
      "  -0.00975037]\n",
      " ...\n",
      " [ 0.06890869 -0.0838623  -0.02839661 ... -0.01596069  0.03710938\n",
      "   0.01885986]\n",
      " [-0.04751587  0.03857422  0.05352783 ... -0.08587646  0.0357666\n",
      "  -0.1114502 ]\n",
      " [ 0.01138306  0.01205444  0.03610229 ... -0.03314209 -0.08453369\n",
      "  -0.03991699]]\n",
      "torch.Size([1024])\n",
      "[-0.00716782 -0.06774902  0.0116272  ... -0.00527573  0.0847168\n",
      "  0.01193237]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02032471  0.00269508 -0.04440308 ... -0.01193237  0.0904541\n",
      "   0.03347778]\n",
      " [-0.04592896 -0.06573486 -0.02571106 ...  0.01257324 -0.02107239\n",
      "  -0.03591919]\n",
      " [ 0.00141144 -0.00677109  0.08300781 ... -0.06762695 -0.05996704\n",
      "  -0.0088501 ]\n",
      " ...\n",
      " [ 0.06878662 -0.08306885 -0.02890015 ... -0.01644897  0.03677368\n",
      "   0.01911926]\n",
      " [-0.04745483  0.03829956  0.05380249 ... -0.08508301  0.03533936\n",
      "  -0.11199951]\n",
      " [ 0.01042938  0.01190186  0.03570557 ... -0.03363037 -0.08355713\n",
      "  -0.03933716]]\n",
      "torch.Size([1024])\n",
      "[-0.00664902 -0.06744385  0.0115509  ... -0.00480652  0.08441162\n",
      "  0.01264954]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04031372 -0.04202271 -0.01070404 ...  0.00437546 -0.01635742\n",
      "   0.00751114]\n",
      " [ 0.00062275  0.02090454  0.01098633 ...  0.02954102 -0.06292725\n",
      "  -0.02038574]\n",
      " [ 0.05560303 -0.0715332   0.0199585  ... -0.01058197 -0.03019714\n",
      "   0.0324707 ]\n",
      " ...\n",
      " [ 0.0178833   0.00938416 -0.05929565 ...  0.08477783  0.03637695\n",
      "   0.00564957]\n",
      " [-0.05136108 -0.03588867 -0.02337646 ...  0.02081299 -0.07409668\n",
      "   0.03027344]\n",
      " [ 0.00405121 -0.01260376 -0.00503159 ... -0.06817627 -0.06216431\n",
      "  -0.03915405]]\n",
      "torch.Size([1024])\n",
      "[-0.00253677 -0.02250671  0.08233643 ... -0.05987549  0.03076172\n",
      " -0.06744385]\n",
      "torch.Size([1024])\n",
      "[0.9980469  0.9941406  1.0078125  ... 0.99121094 0.9951172  0.9975586 ]\n",
      "torch.Size([1024])\n",
      "[-0.07940674 -0.04391479 -0.21081543 ... -0.06298828 -0.0680542\n",
      " -0.0668335 ]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.07641602 -0.02601624  0.04727173 ...  0.0425415   0.01077271\n",
      "  -0.03277588]\n",
      " [ 0.01695251  0.04406738  0.02217102 ...  0.06311035 -0.07269287\n",
      "   0.00358009]\n",
      " [ 0.01628113  0.01622009 -0.01248932 ...  0.12481689 -0.00814819\n",
      "  -0.01331329]\n",
      " ...\n",
      " [-0.07861328 -0.06219482  0.01574707 ...  0.0252533   0.03001404\n",
      "  -0.02128601]\n",
      " [-0.03570557 -0.02043152  0.04327393 ...  0.01023102 -0.04721069\n",
      "  -0.04681396]\n",
      " [-0.01280975 -0.08935547  0.03945923 ...  0.0269165  -0.04980469\n",
      "   0.03137207]]\n",
      "torch.Size([4096])\n",
      "[-0.07904053 -0.05877686 -0.10021973 ... -0.0635376  -0.07873535\n",
      " -0.08746338]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.01086426  0.03277588  0.0647583  ... -0.01707458 -0.00119305\n",
      "   0.00484848]\n",
      " [-0.01303864 -0.00457764  0.01221466 ... -0.03707886 -0.06665039\n",
      "  -0.02496338]\n",
      " [ 0.00680542 -0.00154495 -0.01631165 ...  0.00154114  0.00154686\n",
      "   0.00616455]\n",
      " ...\n",
      " [-0.01443481  0.04125977  0.00553513 ...  0.00388527 -0.03475952\n",
      "  -0.0574646 ]\n",
      " [-0.05578613 -0.0397644   0.04354858 ... -0.01023102 -0.03038025\n",
      "   0.01282501]\n",
      " [-0.00372696  0.01928711 -0.00892639 ... -0.0357666   0.00881195\n",
      "   0.03503418]]\n",
      "torch.Size([1024])\n",
      "[-0.08166504  0.01289368 -0.20031738 ... -0.03970337 -0.06384277\n",
      " -0.10394287]\n",
      "torch.Size([1024])\n",
      "[0.97802734 0.99609375 1.0058594  ... 0.9741211  0.99121094 0.98779297]\n",
      "torch.Size([1024])\n",
      "[-0.02003479 -0.04852295  0.17797852 ... -0.0254364  -0.03092957\n",
      " -0.03005981]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00253868 -0.01439667  0.06121826 ...  0.03915405 -0.02606201\n",
      "   0.05908203]\n",
      " [ 0.02627563  0.01107788 -0.0266571  ...  0.0824585  -0.03161621\n",
      "   0.05010986]\n",
      " [ 0.14038086  0.0713501   0.03134155 ... -0.08795166 -0.03713989\n",
      "  -0.00430679]\n",
      " ...\n",
      " [-0.02709961 -0.04309082  0.07470703 ... -0.12103271  0.05426025\n",
      "  -0.07305908]\n",
      " [ 0.04473877 -0.00823975  0.04727173 ... -0.00520706 -0.04406738\n",
      "   0.02978516]\n",
      " [ 0.01290894  0.09484863 -0.02868652 ...  0.00134182  0.01371002\n",
      "  -0.02085876]]\n",
      "torch.Size([1024])\n",
      "[-0.17553711  0.05895996  0.02377319 ... -0.04827881  0.03918457\n",
      "  0.01296234]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03013611 -0.01039886  0.05331421 ... -0.06176758  0.04214478\n",
      "   0.02523804]\n",
      " [ 0.04696655  0.01371765  0.03585815 ...  0.0914917  -0.0418396\n",
      "   0.02233887]\n",
      " [ 0.01602173  0.03439331 -0.03479004 ... -0.06420898  0.08056641\n",
      "  -0.00160789]\n",
      " ...\n",
      " [ 0.01515198  0.06121826  0.02589417 ...  0.0211792   0.0423584\n",
      "  -0.07391357]\n",
      " [ 0.03295898  0.05456543  0.04992676 ...  0.05136108  0.01791382\n",
      "   0.02044678]\n",
      " [-0.08355713  0.00657272 -0.02378845 ...  0.05252075  0.00556564\n",
      "   0.06228638]]\n",
      "torch.Size([1024])\n",
      "[ 0.00753403 -0.01806641  0.01585388 ... -0.00468445  0.01216888\n",
      " -0.00418854]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01526642  0.00319481 -0.00808716 ...  0.01129913  0.0057373\n",
      "   0.00086069]\n",
      " [-0.01893616  0.0218811  -0.01036072 ...  0.02723694  0.01579285\n",
      "   0.02825928]\n",
      " [ 0.01192474  0.01081848 -0.01021576 ...  0.0194397  -0.00497055\n",
      "  -0.07366943]\n",
      " ...\n",
      " [-0.02406311  0.03244019  0.00482941 ... -0.02914429 -0.0848999\n",
      "  -0.10949707]\n",
      " [ 0.01820374 -0.09613037 -0.02911377 ...  0.00667572 -0.03112793\n",
      "   0.09625244]\n",
      " [ 0.06134033 -0.06524658  0.01031494 ... -0.11340332  0.04956055\n",
      "  -0.04418945]]\n",
      "torch.Size([1024])\n",
      "[ 0.00801849 -0.00184822 -0.00046372 ...  0.00187588  0.00868225\n",
      "  0.00547409]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00242424 -0.01431274  0.06231689 ...  0.03945923 -0.02529907\n",
      "   0.05947876]\n",
      " [ 0.02584839  0.01072693 -0.02630615 ...  0.08288574 -0.03045654\n",
      "   0.050354  ]\n",
      " [ 0.14025879  0.07098389  0.03204346 ... -0.08843994 -0.03808594\n",
      "  -0.00380898]\n",
      " ...\n",
      " [-0.02737427 -0.04373169  0.07470703 ... -0.12103271  0.05535889\n",
      "  -0.07220459]\n",
      " [ 0.04483032 -0.00866699  0.04644775 ... -0.00583267 -0.04440308\n",
      "   0.02937317]\n",
      " [ 0.01260376  0.09436035 -0.02919006 ...  0.00041747  0.0127182\n",
      "  -0.02259827]]\n",
      "torch.Size([1024])\n",
      "[-0.1763916   0.05819702  0.02371216 ... -0.04849243  0.03909302\n",
      "  0.01429749]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00211143 -0.0153656   0.06280518 ...  0.03988647 -0.0247345\n",
      "   0.05886841]\n",
      " [ 0.02632141  0.01150513 -0.02619934 ...  0.08282471 -0.03056335\n",
      "   0.05014038]\n",
      " [ 0.14086914  0.07122803  0.03234863 ... -0.08843994 -0.03741455\n",
      "  -0.00376511]\n",
      " ...\n",
      " [-0.02726746 -0.04400635  0.07470703 ... -0.12115479  0.05435181\n",
      "  -0.07281494]\n",
      " [ 0.04495239 -0.00826263  0.04711914 ... -0.0054245  -0.04397583\n",
      "   0.02915955]\n",
      " [ 0.01340485  0.09484863 -0.02824402 ...  0.00076199  0.01331329\n",
      "  -0.02215576]]\n",
      "torch.Size([1024])\n",
      "[-0.17700195  0.05792236  0.0234375  ... -0.04833984  0.03857422\n",
      "  0.01365662]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00259209 -0.01461029  0.06256104 ...  0.03933716 -0.02534485\n",
      "   0.059021  ]\n",
      " [ 0.02641296  0.01039886 -0.02639771 ...  0.08282471 -0.03131104\n",
      "   0.05062866]\n",
      " [ 0.14099121  0.07104492  0.03207397 ... -0.08856201 -0.0378418\n",
      "  -0.00383949]\n",
      " ...\n",
      " [-0.02758789 -0.04394531  0.07427979 ... -0.12207031  0.0546875\n",
      "  -0.07275391]\n",
      " [ 0.0453186  -0.00774002  0.04721069 ... -0.0051651  -0.04379272\n",
      "   0.02952576]\n",
      " [ 0.01322174  0.09509277 -0.02868652 ...  0.00120926  0.01332092\n",
      "  -0.02192688]]\n",
      "torch.Size([1024])\n",
      "[-0.17626953  0.05831909  0.02394104 ... -0.04736328  0.03808594\n",
      "  0.01351929]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00088072 -0.02656555 -0.01722717 ... -0.02107239 -0.0329895\n",
      "   0.05380249]\n",
      " [ 0.02761841  0.00791931  0.01065826 ...  0.07159424 -0.046875\n",
      "   0.06323242]\n",
      " [ 0.00255394  0.00944519 -0.00500488 ...  0.01436615 -0.03347778\n",
      "  -0.00832367]\n",
      " ...\n",
      " [ 0.03244019  0.01229858 -0.04199219 ...  0.02804565  0.03076172\n",
      "   0.02250671]\n",
      " [-0.02885437  0.02832031 -0.00784302 ... -0.043396    0.06103516\n",
      "  -0.0329895 ]\n",
      " [ 0.0229187  -0.0193634  -0.05841064 ... -0.00387383 -0.02764893\n",
      "   0.01820374]]\n",
      "torch.Size([1024])\n",
      "[-0.0239563   0.03778076  0.03076172 ... -0.00872803 -0.04898071\n",
      " -0.01728821]\n",
      "torch.Size([1024])\n",
      "[0.9868164  0.99853516 1.0039062  ... 0.984375   0.984375   0.9848633 ]\n",
      "torch.Size([1024])\n",
      "[-0.09667969 -0.06311035 -0.21813965 ... -0.08288574 -0.06756592\n",
      " -0.08453369]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.00780106 -0.04360962  0.02418518 ... -0.05276489 -0.03863525\n",
      "  -0.01954651]\n",
      " [ 0.08496094 -0.02947998  0.01982117 ...  0.02250671 -0.05984497\n",
      "  -0.00735092]\n",
      " [-0.00683212  0.01315308  0.01065063 ...  0.02374268  0.03086853\n",
      "   0.01785278]\n",
      " ...\n",
      " [ 0.07312012 -0.06103516 -0.03598022 ... -0.00743866  0.03286743\n",
      "   0.00404358]\n",
      " [-0.00602722  0.09710693  0.01298523 ... -0.04806519 -0.06536865\n",
      "   0.01216125]\n",
      " [-0.05050659 -0.02256775 -0.00330353 ... -0.0255127   0.00268364\n",
      "   0.02566528]]\n",
      "torch.Size([4096])\n",
      "[-0.04425049 -0.090271   -0.0246582  ...  0.02037048 -0.11230469\n",
      " -0.04553223]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.0262146   0.06799316 -0.01399994 ...  0.00363731 -0.02493286\n",
      "  -0.05947876]\n",
      " [ 0.00684738 -0.00527573  0.02098083 ...  0.00451279  0.00365448\n",
      "  -0.00682068]\n",
      " [-0.01931763 -0.02377319 -0.00039363 ...  0.01325226  0.03164673\n",
      "  -0.01634216]\n",
      " ...\n",
      " [ 0.0141449   0.09814453 -0.01465607 ...  0.01582336 -0.03399658\n",
      "   0.00191307]\n",
      " [ 0.00841522  0.00904846 -0.0236969  ...  0.01672363  0.04046631\n",
      "   0.00012887]\n",
      " [-0.02166748 -0.03573608 -0.01564026 ...  0.00917816 -0.02044678\n",
      "   0.01506042]]\n",
      "torch.Size([1024])\n",
      "[-0.06921387  0.01580811 -0.15234375 ... -0.01573181 -0.08795166\n",
      " -0.05093384]\n",
      "torch.Size([1024])\n",
      "[0.9848633  0.9916992  1.0029297  ... 0.98095703 0.98583984 0.9848633 ]\n",
      "torch.Size([1024])\n",
      "[-0.00410461 -0.0271759   0.12237549 ... -0.01326752 -0.03787231\n",
      " -0.00703812]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0309906  -0.00328636  0.13867188 ...  0.02250671  0.0680542\n",
      "  -0.01435852]\n",
      " [ 0.03369141  0.02154541  0.01242065 ... -0.14331055 -0.05014038\n",
      "  -0.04214478]\n",
      " [-0.05252075  0.05783081  0.18713379 ...  0.04000854 -0.025177\n",
      "  -0.02345276]\n",
      " ...\n",
      " [-0.05160522 -0.00283623 -0.02827454 ...  0.02160645 -0.0191803\n",
      "  -0.03213501]\n",
      " [-0.06274414  0.03259277 -0.01390076 ...  0.01603699  0.05252075\n",
      "   0.10906982]\n",
      " [-0.01672363  0.04125977  0.1418457  ... -0.03234863  0.01361084\n",
      "  -0.05245972]]\n",
      "torch.Size([1024])\n",
      "[-0.2758789  -0.01184082 -0.14465332 ...  0.00943756 -0.00580597\n",
      "  0.02128601]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.05984497 -0.01741028  0.05096436 ...  0.01119232 -0.00728607\n",
      "   0.04541016]\n",
      " [-0.02400208  0.08166504  0.11175537 ... -0.01747131 -0.00408936\n",
      "  -0.05966187]\n",
      " [ 0.06921387  0.04907227  0.25708008 ... -0.02571106  0.00654602\n",
      "   0.01029968]\n",
      " ...\n",
      " [-0.05392456 -0.03065491 -0.01463318 ... -0.0362854   0.06378174\n",
      "   0.02526855]\n",
      " [ 0.06195068 -0.01576233 -0.02062988 ... -0.0181427  -0.04360962\n",
      "  -0.00356674]\n",
      " [-0.01927185 -0.01669312  0.14404297 ...  0.03451538 -0.01444244\n",
      "   0.07849121]]\n",
      "torch.Size([1024])\n",
      "[ 0.00017333  0.00032163  0.0021534  ... -0.00429535  0.00193691\n",
      "  0.00609589]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02568054  0.01991272 -0.00196266 ...  0.01246643  0.00156593\n",
      "   0.00714111]\n",
      " [-0.03457642  0.05957031  0.01678467 ...  0.01012421  0.00370407\n",
      "   0.02461243]\n",
      " [ 0.01094055 -0.04052734 -0.03265381 ...  0.10327148 -0.02796936\n",
      "   0.00140572]\n",
      " ...\n",
      " [ 0.0122757  -0.00558472  0.0165863  ...  0.02336121 -0.02638245\n",
      "  -0.03509521]\n",
      " [ 0.0362854  -0.00366974 -0.04348755 ...  0.0091629   0.03186035\n",
      "   0.00161552]\n",
      " [ 0.02587891  0.06860352 -0.01586914 ... -0.04226685  0.01757812\n",
      "   0.00263596]]\n",
      "torch.Size([1024])\n",
      "[-0.00752258  0.00492096 -0.01696777 ... -0.00636673  0.00301743\n",
      " -0.01199341]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0308075  -0.00155449  0.1381836  ...  0.02246094  0.06750488\n",
      "  -0.01444244]\n",
      " [ 0.03256226  0.02055359  0.01184082 ... -0.14453125 -0.05007935\n",
      "  -0.04244995]\n",
      " [-0.05267334  0.05783081  0.18640137 ...  0.03933716 -0.02493286\n",
      "  -0.02409363]\n",
      " ...\n",
      " [-0.05163574 -0.00311279 -0.02763367 ...  0.0214386  -0.0199585\n",
      "  -0.03062439]\n",
      " [-0.06280518  0.03213501 -0.01333618 ...  0.01516724  0.05279541\n",
      "   0.10900879]\n",
      " [-0.01670837  0.04092407  0.14294434 ... -0.03253174  0.01465607\n",
      "  -0.05233765]]\n",
      "torch.Size([1024])\n",
      "[-0.27490234 -0.01136017 -0.14379883 ...  0.00937653 -0.00613785\n",
      "  0.01997375]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03123474 -0.00204849  0.1373291  ...  0.02153015  0.06787109\n",
      "  -0.01493835]\n",
      " [ 0.03253174  0.02064514  0.01235199 ... -0.14367676 -0.04992676\n",
      "  -0.04193115]\n",
      " [-0.05358887  0.05819702  0.18615723 ...  0.03964233 -0.02510071\n",
      "  -0.02355957]\n",
      " ...\n",
      " [-0.05142212 -0.00301361 -0.02738953 ...  0.02149963 -0.02033997\n",
      "  -0.03137207]\n",
      " [-0.06451416  0.03259277 -0.01272583 ...  0.01573181  0.05197144\n",
      "   0.109375  ]\n",
      " [-0.0181427   0.04147339  0.14257812 ... -0.03106689  0.01348877\n",
      "  -0.05252075]]\n",
      "torch.Size([1024])\n",
      "[-0.27441406 -0.01193237 -0.14318848 ...  0.00935364 -0.00582123\n",
      "  0.02044678]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03071594 -0.00159264  0.13769531 ...  0.02230835  0.06774902\n",
      "  -0.01483154]\n",
      " [ 0.03308105  0.02049255  0.01264191 ... -0.14404297 -0.04980469\n",
      "  -0.04205322]\n",
      " [-0.05300903  0.05789185  0.1862793  ...  0.03942871 -0.02520752\n",
      "  -0.02371216]\n",
      " ...\n",
      " [-0.05130005 -0.00358009 -0.02702332 ...  0.02163696 -0.01954651\n",
      "  -0.03149414]\n",
      " [-0.06378174  0.03274536 -0.01351166 ...  0.01552582  0.05227661\n",
      "   0.10931396]\n",
      " [-0.01823425  0.04190063  0.14233398 ... -0.03170776  0.01296997\n",
      "  -0.05245972]]\n",
      "torch.Size([1024])\n",
      "[-0.2746582  -0.012146   -0.14343262 ...  0.00913239 -0.00516891\n",
      "  0.02096558]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.03668213 -0.02255249 -0.06002808 ... -0.02581787 -0.008255\n",
      "  -0.037323  ]\n",
      " [-0.02085876  0.07000732 -0.05163574 ... -0.0004735  -0.02360535\n",
      "   0.01499939]\n",
      " [-0.03778076  0.01802063 -0.00593185 ...  0.00904846 -0.02401733\n",
      "  -0.00207901]\n",
      " ...\n",
      " [ 0.03286743  0.00919342  0.0703125  ... -0.00549698  0.02505493\n",
      "   0.01856995]\n",
      " [-0.00489807  0.02047729  0.02290344 ... -0.01554871  0.0012331\n",
      "   0.01281738]\n",
      " [ 0.00029063  0.01003265 -0.00086784 ... -0.00074625  0.02661133\n",
      "   0.02316284]]\n",
      "torch.Size([1024])\n",
      "[-0.01560974  0.07897949  0.02903748 ...  0.07122803  0.03704834\n",
      "  0.00108242]\n",
      "torch.Size([1024])\n",
      "[0.984375   0.98583984 1.0068359  ... 0.98876953 0.97753906 0.98828125]\n",
      "torch.Size([1024])\n",
      "[-0.09667969 -0.02348328 -0.25463867 ... -0.07269287 -0.06256104\n",
      " -0.06787109]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.05307007 -0.0236969   0.03326416 ...  0.02648926  0.00556946\n",
      "  -0.02658081]\n",
      " [ 0.06414795 -0.04095459  0.00743103 ... -0.01303101  0.00099182\n",
      "  -0.0475769 ]\n",
      " [ 0.01818848 -0.03070068 -0.02963257 ... -0.03686523  0.00977325\n",
      "  -0.02445984]\n",
      " ...\n",
      " [ 0.01760864  0.06103516  0.04171753 ...  0.02859497  0.03005981\n",
      "   0.0031147 ]\n",
      " [-0.03143311 -0.05273438  0.00348473 ...  0.03668213 -0.02783203\n",
      "   0.00629807]\n",
      " [ 0.04046631  0.05462646 -0.06298828 ...  0.00545502  0.00964355\n",
      "  -0.00223351]]\n",
      "torch.Size([4096])\n",
      "[-0.07281494 -0.10198975 -0.00559998 ... -0.04693604 -0.09735107\n",
      " -0.0814209 ]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.03964233  0.00198936  0.01815796 ...  0.02069092 -0.02874756\n",
      "  -0.03448486]\n",
      " [-0.03921509 -0.03671265 -0.02107239 ...  0.04342651 -0.02880859\n",
      "  -0.00791168]\n",
      " [ 0.01519775 -0.00460434 -0.00804901 ... -0.01030731 -0.00413895\n",
      "  -0.0163269 ]\n",
      " ...\n",
      " [ 0.01768494  0.01795959  0.04031372 ... -0.00370789 -0.00164795\n",
      "  -0.01089478]\n",
      " [-0.01087952 -0.01290131 -0.00115108 ... -0.0042038   0.05056763\n",
      "   0.01183319]\n",
      " [-0.02989197 -0.01432037  0.04248047 ...  0.00276947 -0.05682373\n",
      "  -0.02288818]]\n",
      "torch.Size([1024])\n",
      "[-0.07714844  0.0002954  -0.1595459  ...  0.04272461 -0.04153442\n",
      " -0.04226685]\n",
      "torch.Size([1024])\n",
      "[0.9824219  0.99853516 1.0058594  ... 0.98095703 0.9873047  0.97998047]\n",
      "torch.Size([1024])\n",
      "[-0.00764847 -0.04925537  0.12139893 ... -0.01838684 -0.02688599\n",
      " -0.02885437]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04937744 -0.02572632 -0.0153656  ... -0.0723877   0.05841064\n",
      "  -0.13977051]\n",
      " [ 0.03445435  0.01570129 -0.13256836 ...  0.03219604  0.04492188\n",
      "   0.07458496]\n",
      " [-0.02397156 -0.01552582  0.04473877 ... -0.06384277 -0.07733154\n",
      "   0.01626587]\n",
      " ...\n",
      " [-0.00463486 -0.01248932 -0.19677734 ...  0.08917236 -0.00895691\n",
      "  -0.03323364]\n",
      " [-0.12597656  0.05880737  0.05426025 ... -0.01067352  0.05889893\n",
      "  -0.08654785]\n",
      " [-0.02882385  0.05712891  0.06106567 ...  0.10009766  0.0637207\n",
      "  -0.01425934]]\n",
      "torch.Size([1024])\n",
      "[-0.01348877 -0.06137085 -0.01174927 ... -0.0227356   0.03881836\n",
      " -0.02067566]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02253723  0.00942993 -0.00192833 ...  0.03793335 -0.08514404\n",
      "  -0.00894928]\n",
      " [ 0.06216431  0.05844116 -0.0960083  ...  0.06088257 -0.0430603\n",
      "   0.05999756]\n",
      " [-0.05291748 -0.01437378  0.03915405 ...  0.02438354  0.10961914\n",
      "  -0.04837036]\n",
      " ...\n",
      " [-0.07781982 -0.02178955 -0.25878906 ...  0.01284027  0.06469727\n",
      "   0.0309906 ]\n",
      " [-0.01561737  0.00665665  0.16296387 ...  0.0239563   0.08618164\n",
      "   0.01455688]\n",
      " [ 0.01340485 -0.0760498   0.12609863 ... -0.04711914 -0.01702881\n",
      "   0.07275391]]\n",
      "torch.Size([1024])\n",
      "[ 0.00696945 -0.00760651  0.01737976 ... -0.01006317 -0.01895142\n",
      "  0.01771545]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02650452  0.01441193  0.03134155 ...  0.02932739  0.01835632\n",
      "   0.02574158]\n",
      " [-0.01210022  0.00827789 -0.003479   ...  0.03924561  0.027771\n",
      "  -0.02246094]\n",
      " [-0.03747559 -0.0091629   0.01540375 ...  0.03164673 -0.02178955\n",
      "  -0.03262329]\n",
      " ...\n",
      " [ 0.01448059  0.01687622  0.01087952 ... -0.02246094 -0.01262665\n",
      "  -0.01780701]\n",
      " [ 0.02638245  0.02604675 -0.037323   ...  0.02659607 -0.02006531\n",
      "  -0.04504395]\n",
      " [-0.02011108  0.05963135 -0.02449036 ...  0.03536987  0.02583313\n",
      "  -0.00632095]]\n",
      "torch.Size([1024])\n",
      "[ 3.0174255e-03  6.9274902e-02  3.5071373e-04 ... -3.7097931e-03\n",
      "  6.0617924e-05 -1.7593384e-02]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04998779 -0.02523804 -0.01502228 ... -0.0725708   0.05819702\n",
      "  -0.13964844]\n",
      " [ 0.03405762  0.01550293 -0.13220215 ...  0.03198242  0.04528809\n",
      "   0.07385254]\n",
      " [-0.02407837 -0.01643372  0.04388428 ... -0.06311035 -0.07672119\n",
      "   0.01646423]\n",
      " ...\n",
      " [-0.00449371 -0.01311493 -0.19702148 ...  0.08898926 -0.00891876\n",
      "  -0.03347778]\n",
      " [-0.12597656  0.05841064  0.0539856  ... -0.01111603  0.05889893\n",
      "  -0.08618164]\n",
      " [-0.02745056  0.05603027  0.06063843 ...  0.09924316  0.0645752\n",
      "  -0.01577759]]\n",
      "torch.Size([1024])\n",
      "[-0.01364136 -0.06100464 -0.01107025 ... -0.02354431  0.03900146\n",
      " -0.02177429]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.05029297 -0.02505493 -0.01537323 ... -0.07202148  0.05804443\n",
      "  -0.13952637]\n",
      " [ 0.03390503  0.0147934  -0.13183594 ...  0.03289795  0.0456543\n",
      "   0.07409668]\n",
      " [-0.02355957 -0.01608276  0.04394531 ... -0.06341553 -0.0760498\n",
      "   0.01612854]\n",
      " ...\n",
      " [-0.00437546 -0.01306915 -0.19665527 ...  0.09014893 -0.00941467\n",
      "  -0.03302002]\n",
      " [-0.1262207   0.05776978  0.05429077 ... -0.01170349  0.05963135\n",
      "  -0.08648682]\n",
      " [-0.027771    0.05651855  0.06161499 ...  0.09985352  0.06433105\n",
      "  -0.01524353]]\n",
      "torch.Size([1024])\n",
      "[-0.0135498  -0.06173706 -0.01123047 ... -0.02380371  0.03890991\n",
      " -0.0219574 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04983521 -0.02561951 -0.01520538 ... -0.07208252  0.05831909\n",
      "  -0.13928223]\n",
      " [ 0.03366089  0.01620483 -0.13317871 ...  0.03164673  0.04501343\n",
      "   0.07452393]\n",
      " [-0.02456665 -0.01576233  0.04330444 ... -0.06414795 -0.07714844\n",
      "   0.0161438 ]\n",
      " ...\n",
      " [-0.00432587 -0.01275635 -0.19689941 ...  0.08984375 -0.00942993\n",
      "  -0.03302002]\n",
      " [-0.12609863  0.0579834   0.05413818 ... -0.01155853  0.05957031\n",
      "  -0.08660889]\n",
      " [-0.0269928   0.05651855  0.06149292 ...  0.10021973  0.06433105\n",
      "  -0.01517487]]\n",
      "torch.Size([1024])\n",
      "[-0.01363373 -0.06021118 -0.01038361 ... -0.02320862  0.03845215\n",
      " -0.0219574 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00270653  0.02583313 -0.02120972 ...  0.02433777  0.0151062\n",
      "  -0.00463486]\n",
      " [ 0.00626373 -0.03186035 -0.04458618 ... -0.00436401  0.03866577\n",
      "   0.00271034]\n",
      " [ 0.00103378 -0.04806519 -0.02912903 ...  0.03845215 -0.02549744\n",
      "   0.01366425]\n",
      " ...\n",
      " [-0.06192017 -0.06057739 -0.03051758 ...  0.00193691 -0.00078821\n",
      "   0.01513672]\n",
      " [-0.01960754  0.0453186   0.00749969 ...  0.01302338  0.01971436\n",
      "  -0.00745392]\n",
      " [-0.02407837 -0.03634644  0.00727463 ... -0.00782013 -0.02668762\n",
      "  -0.04418945]]\n",
      "torch.Size([1024])\n",
      "[ 0.00303078  0.06018066  0.07940674 ... -0.00110531  0.02540588\n",
      "  0.0067749 ]\n",
      "torch.Size([1024])\n",
      "[0.9785156  0.9892578  1.0078125  ... 0.97314453 0.9873047  0.9926758 ]\n",
      "torch.Size([1024])\n",
      "[-0.08148193 -0.03842163 -0.21777344 ... -0.06384277 -0.0836792\n",
      " -0.06268311]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.05007935 -0.03964233  0.01327515 ...  0.08508301  0.07592773\n",
      "   0.15441895]\n",
      " [ 0.05160522 -0.00935364  0.05361938 ...  0.02160645  0.02818298\n",
      "   0.02374268]\n",
      " [ 0.02015686  0.01441956  0.03546143 ... -0.01704407 -0.00370789\n",
      "   0.00418472]\n",
      " ...\n",
      " [ 0.07769775 -0.02345276  0.02348328 ... -0.00449371 -0.0512085\n",
      "   0.04040527]\n",
      " [ 0.02397156 -0.01024628 -0.03872681 ... -0.01649475  0.03393555\n",
      "  -0.08410645]\n",
      " [ 0.01515198  0.04248047  0.03442383 ... -0.03253174 -0.01344299\n",
      "   0.03518677]]\n",
      "torch.Size([4096])\n",
      "[-0.10253906  0.01200867 -0.04141235 ... -0.1159668   0.00416183\n",
      " -0.01754761]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.01626587 -0.01670837 -0.02388    ... -0.03982544 -0.00579834\n",
      "   0.00930786]\n",
      " [-0.05688477 -0.03762817  0.00959015 ...  0.05151367 -0.01316833\n",
      "   0.01991272]\n",
      " [ 0.01329041 -0.01435089  0.00238609 ... -0.01623535  0.008461\n",
      "  -0.00070381]\n",
      " ...\n",
      " [ 0.0079422  -0.00948334  0.02568054 ... -0.0508728   0.01464844\n",
      "   0.02180481]\n",
      " [ 0.02688599 -0.01025391 -0.03170776 ... -0.02156067 -0.00564194\n",
      "  -0.00682449]\n",
      " [ 0.00634766  0.01313019 -0.00231934 ...  0.03601074  0.03967285\n",
      "   0.03164673]]\n",
      "torch.Size([1024])\n",
      "[-0.03961182  0.02662659 -0.04980469 ...  0.11157227 -0.0567627\n",
      "  0.00308609]\n",
      "torch.Size([1024])\n",
      "[0.9628906  0.9946289  1.0048828  ... 0.97753906 0.99121094 0.98291016]\n",
      "torch.Size([1024])\n",
      "[-0.01148224 -0.03375244  0.07507324 ... -0.02061462 -0.01541901\n",
      " -0.0063324 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01348877  0.01412964 -0.01031494 ...  0.00317955 -0.05285645\n",
      "   0.01831055]\n",
      " [-0.07165527 -0.07543945  0.02877808 ... -0.02926636 -0.0355835\n",
      "  -0.00320053]\n",
      " [-0.02035522 -0.0227356   0.00075054 ...  0.03097534  0.04177856\n",
      "  -0.00271797]\n",
      " ...\n",
      " [ 0.09368896 -0.00940704 -0.03010559 ...  0.07080078 -0.02258301\n",
      "   0.01976013]\n",
      " [ 0.00229645  0.00272751  0.19470215 ... -0.02308655  0.02571106\n",
      "   0.00192928]\n",
      " [-0.02583313  0.01576233 -0.11730957 ... -0.04714966 -0.03704834\n",
      "  -0.04785156]]\n",
      "torch.Size([1024])\n",
      "[-0.02653503  0.02586365  0.01357269 ...  0.09210205 -0.03475952\n",
      "  0.05148315]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01439667 -0.07250977 -0.02352905 ... -0.10693359 -0.02243042\n",
      "  -0.08654785]\n",
      " [-0.00433731 -0.00147057  0.03771973 ... -0.01913452  0.00177383\n",
      "  -0.00904083]\n",
      " [ 0.02700806  0.05133057 -0.0859375  ...  0.10760498  0.02444458\n",
      "   0.03634644]\n",
      " ...\n",
      " [-0.04000854 -0.0552063  -0.10949707 ... -0.0243988  -0.01177216\n",
      "   0.02929688]\n",
      " [-0.02548218  0.05215454  0.22314453 ...  0.02430725 -0.06109619\n",
      "   0.02786255]\n",
      " [-0.01879883  0.02114868 -0.04745483 ... -0.09240723 -0.01443481\n",
      "   0.01519012]]\n",
      "torch.Size([1024])\n",
      "[-0.00537491 -0.00484848  0.00364494 ... -0.01184845  0.01552582\n",
      " -0.0161438 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04858398 -0.00688171  0.02688599 ... -0.02479553 -0.00119686\n",
      "   0.06118774]\n",
      " [-0.01589966 -0.00316238 -0.01870728 ... -0.02600098  0.1050415\n",
      "   0.01971436]\n",
      " [ 0.00074005  0.03295898 -0.01161957 ... -0.06872559 -0.07879639\n",
      "   0.01489258]\n",
      " ...\n",
      " [-0.06176758  0.03137207  0.02175903 ...  0.07012939  0.01065826\n",
      "   0.01954651]\n",
      " [ 0.090271    0.00672531  0.05984497 ... -0.00471497  0.01480865\n",
      "  -0.04971313]\n",
      " [ 0.01853943  0.03945923 -0.01212311 ... -0.02810669 -0.00606537\n",
      "  -0.07159424]]\n",
      "torch.Size([1024])\n",
      "[ 0.00010073  0.00574493  0.02029419 ...  0.00182343  0.00260162\n",
      " -0.00549698]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01325226  0.01462555 -0.00950623 ...  0.00442123 -0.05282593\n",
      "   0.01832581]\n",
      " [-0.07061768 -0.07531738  0.03013611 ... -0.02879333 -0.03533936\n",
      "  -0.00435638]\n",
      " [-0.02085876 -0.02378845 -0.000525   ...  0.0309906   0.04107666\n",
      "  -0.00253105]\n",
      " ...\n",
      " [ 0.09387207 -0.008255   -0.02932739 ...  0.07354736 -0.02185059\n",
      "   0.02084351]\n",
      " [ 0.00164604  0.00305367  0.19482422 ... -0.02322388  0.02586365\n",
      "   0.00265503]\n",
      " [-0.02511597  0.01485443 -0.11730957 ... -0.04840088 -0.03707886\n",
      "  -0.04803467]]\n",
      "torch.Size([1024])\n",
      "[-0.02677917  0.02520752  0.01469421 ...  0.09130859 -0.03430176\n",
      "  0.05102539]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.01325226  0.0147934  -0.00967407 ...  0.00418091 -0.05307007\n",
      "   0.01821899]\n",
      " [-0.07147217 -0.07415771  0.02955627 ... -0.02880859 -0.0369873\n",
      "  -0.00399017]\n",
      " [-0.02029419 -0.02409363  0.00025439 ...  0.03102112  0.04269409\n",
      "  -0.00186443]\n",
      " ...\n",
      " [ 0.09442139 -0.00801086 -0.02804565 ...  0.07409668 -0.02243042\n",
      "   0.02008057]\n",
      " [ 0.00226593  0.00269127  0.19555664 ... -0.0241394   0.02584839\n",
      "   0.00208282]\n",
      " [-0.02558899  0.01467133 -0.11804199 ... -0.0475769  -0.03692627\n",
      "  -0.04696655]]\n",
      "torch.Size([1024])\n",
      "[-0.02639771  0.0259552   0.01377869 ...  0.09014893 -0.03436279\n",
      "  0.05133057]\n",
      "torch.Size([1024, 1024])\n",
      "[[-1.3809204e-02  1.5686035e-02 -1.0017395e-02 ...  3.9482117e-03\n",
      "  -5.3375244e-02  1.8295288e-02]\n",
      " [-7.1411133e-02 -7.4096680e-02  2.9403687e-02 ... -2.9205322e-02\n",
      "  -3.5736084e-02 -4.2762756e-03]\n",
      " [-2.0996094e-02 -2.3773193e-02  2.3782253e-05 ...  3.1204224e-02\n",
      "   4.1503906e-02 -1.9779205e-03]\n",
      " ...\n",
      " [ 9.3811035e-02 -8.9721680e-03 -2.9235840e-02 ...  7.2814941e-02\n",
      "  -2.2338867e-02  2.0401001e-02]\n",
      " [ 1.6937256e-03  2.2144318e-03  1.9470215e-01 ... -2.4597168e-02\n",
      "   2.5741577e-02  2.0771027e-03]\n",
      " [-2.5222778e-02  1.5930176e-02 -1.1755371e-01 ... -4.6813965e-02\n",
      "  -3.6987305e-02 -4.7393799e-02]]\n",
      "torch.Size([1024])\n",
      "[-0.02613831  0.02584839  0.01396179 ...  0.09100342 -0.03417969\n",
      "  0.0512085 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01406097 -0.06072998 -0.05062866 ...  0.05670166 -0.05334473\n",
      "  -0.01541901]\n",
      " [ 0.01195526  0.04415894  0.01325989 ... -0.01686096 -0.01042938\n",
      "  -0.05563354]\n",
      " [ 0.02586365  0.0087204   0.00635529 ... -0.01564026 -0.05300903\n",
      "  -0.00234985]\n",
      " ...\n",
      " [ 0.04064941 -0.02656555 -0.04989624 ... -0.07397461 -0.02282715\n",
      "   0.03598022]\n",
      " [ 0.01759338  0.00379181  0.00660706 ... -0.02043152 -0.01383209\n",
      "   0.03089905]\n",
      " [ 0.01137543  0.00192356 -0.01377869 ...  0.01907349  0.01381683\n",
      "   0.03427124]]\n",
      "torch.Size([1024])\n",
      "[-0.01170349  0.07769775  0.06106567 ...  0.07250977  0.0869751\n",
      "  0.02215576]\n",
      "torch.Size([1024])\n",
      "[0.97021484 0.99560547 1.0078125  ... 0.9794922  0.9868164  0.9916992 ]\n",
      "torch.Size([1024])\n",
      "[-0.03164673 -0.03512573 -0.16015625 ... -0.04510498 -0.0892334\n",
      " -0.04690552]\n",
      "torch.Size([4096, 1024])\n",
      "[[ 0.00885773 -0.00977325  0.05697632 ...  0.00771713  0.01006317\n",
      "   0.00767899]\n",
      " [ 0.0178833  -0.01538086  0.00162315 ...  0.01030731 -0.06488037\n",
      "   0.06774902]\n",
      " [-0.01171112 -0.02047729 -0.05667114 ... -0.0199585  -0.03439331\n",
      "  -0.03790283]\n",
      " ...\n",
      " [ 0.00596619 -0.0304718   0.00151157 ...  0.04058838  0.09069824\n",
      "   0.02049255]\n",
      " [ 0.05957031  0.04650879  0.05914307 ... -0.04846191 -0.00803375\n",
      "  -0.03143311]\n",
      " [-0.01791382 -0.04281616  0.04702759 ... -0.00855255  0.00348091\n",
      "  -0.00751114]]\n",
      "torch.Size([4096])\n",
      "[-0.02171326 -0.03530884 -0.04724121 ... -0.02656555 -0.01873779\n",
      " -0.025177  ]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.01546478  0.06610107  0.01805115 ...  0.06195068 -0.00850677\n",
      "  -0.01152039]\n",
      " [ 0.00879669  0.03114319  0.0506897  ...  0.00396347  0.01392365\n",
      "  -0.03744507]\n",
      " [-0.01348877 -0.00229263 -0.0087738  ... -0.00883484 -0.0087738\n",
      "  -0.01292419]\n",
      " ...\n",
      " [ 0.01191711  0.00919342  0.05084229 ... -0.01646423  0.01416779\n",
      "  -0.00535202]\n",
      " [-0.02017212 -0.04846191  0.02336121 ...  0.0296936   0.059021\n",
      "   0.02056885]\n",
      " [-0.03268433  0.00597382  0.03607178 ...  0.01902771  0.03939819\n",
      "  -0.00535583]]\n",
      "torch.Size([1024])\n",
      "[-0.05667114  0.00441742 -0.00767899 ...  0.06240845 -0.09466553\n",
      "  0.04870605]\n",
      "torch.Size([1024])\n",
      "[0.96240234 0.99072266 1.0048828  ... 0.9785156  0.98535156 0.9760742 ]\n",
      "torch.Size([1024])\n",
      "[-0.03213501 -0.03155518  0.07818604 ... -0.0300293  -0.02301025\n",
      " -0.01391602]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03131104 -0.08154297 -0.21203613 ... -0.01131439 -0.00810242\n",
      "  -0.03988647]\n",
      " [-0.02767944 -0.08282471  0.05160522 ... -0.02346802  0.0214386\n",
      "   0.00255775]\n",
      " [ 0.05905151  0.0350647   0.05786133 ...  0.03117371 -0.04412842\n",
      "  -0.07110596]\n",
      " ...\n",
      " [ 0.00603104  0.01326752 -0.14880371 ...  0.07141113  0.0657959\n",
      "   0.05368042]\n",
      " [-0.06311035  0.01229095  0.0345459  ...  0.00685883  0.01179504\n",
      "   0.00639725]\n",
      " [-0.04275513 -0.04138184  0.04544067 ...  0.01759338 -0.02441406\n",
      "   0.06573486]]\n",
      "torch.Size([1024])\n",
      "[ 0.16516113 -0.0307312  -0.01579285 ... -0.06817627  0.04257202\n",
      " -0.04647827]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.01400757  0.05230713 -0.15563965 ...  0.07202148  0.03013611\n",
      "   0.00965881]\n",
      " [ 0.04718018  0.04544067  0.06793213 ...  0.01046753  0.12890625\n",
      "  -0.03720093]\n",
      " [ 0.00105381 -0.00273895 -0.00035429 ... -0.078125    0.01448059\n",
      "  -0.00919342]\n",
      " ...\n",
      " [-0.05584717 -0.03967285 -0.12341309 ...  0.02642822 -0.05377197\n",
      "   0.03146362]\n",
      " [ 0.08331299 -0.01763916  0.06970215 ... -0.09686279  0.02914429\n",
      "  -0.0070076 ]\n",
      " [-0.02844238  0.01856995  0.07946777 ... -0.04199219  0.0088501\n",
      "  -0.00563431]]\n",
      "torch.Size([1024])\n",
      "[-0.0617981  -0.00948334  0.00285339 ... -0.0011673   0.00026751\n",
      "  0.00611496]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0319519  -0.03314209 -0.05395508 ... -0.03170776  0.01395416\n",
      "  -0.02757263]\n",
      " [ 0.03924561 -0.04986572 -0.00095844 ...  0.0255127  -0.05670166\n",
      "   0.07019043]\n",
      " [ 0.01498413 -0.040802   -0.01226044 ...  0.00836182 -0.03955078\n",
      "   0.02584839]\n",
      " ...\n",
      " [ 0.02474976 -0.06982422 -0.01086426 ... -0.03149414 -0.07446289\n",
      "  -0.03192139]\n",
      " [ 0.0282135  -0.03204346 -0.04205322 ...  0.0715332  -0.01600647\n",
      "   0.02766418]\n",
      " [-0.02258301 -0.00014591  0.09564209 ... -0.03173828 -0.02197266\n",
      "   0.02360535]]\n",
      "torch.Size([1024])\n",
      "[ 0.00714874 -0.00356483 -0.00044727 ... -0.0107193  -0.02546692\n",
      " -0.01293182]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03134155 -0.08099365 -0.2109375  ... -0.01064301 -0.00856018\n",
      "  -0.04037476]\n",
      " [-0.02778625 -0.08270264  0.05249023 ... -0.02209473  0.02142334\n",
      "   0.0026207 ]\n",
      " [ 0.059021    0.03579712  0.05865479 ...  0.03244019 -0.04281616\n",
      "  -0.0715332 ]\n",
      " ...\n",
      " [ 0.00688553  0.0117569  -0.14990234 ...  0.07165527  0.0670166\n",
      "   0.05227661]\n",
      " [-0.06304932  0.01243591  0.03482056 ...  0.00726318  0.01116943\n",
      "   0.00610352]\n",
      " [-0.04364014 -0.04055786  0.04547119 ...  0.01730347 -0.02540588\n",
      "   0.06555176]]\n",
      "torch.Size([1024])\n",
      "[ 0.16455078 -0.03173828 -0.01664734 ... -0.06762695  0.04290771\n",
      " -0.04455566]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03131104 -0.08129883 -0.2121582  ... -0.01171875 -0.00889587\n",
      "  -0.04046631]\n",
      " [-0.0272522  -0.08203125  0.05157471 ... -0.02325439  0.02151489\n",
      "   0.00206757]\n",
      " [ 0.05844116  0.03488159  0.05944824 ...  0.0333252  -0.04299927\n",
      "  -0.07110596]\n",
      " ...\n",
      " [ 0.00688553  0.01200104 -0.14929199 ...  0.07147217  0.0668335\n",
      "   0.05380249]\n",
      " [-0.06246948  0.01316071  0.03494263 ...  0.0070343   0.01187897\n",
      "   0.00682449]\n",
      " [-0.04370117 -0.04016113  0.04580688 ...  0.01789856 -0.02572632\n",
      "   0.06622314]]\n",
      "torch.Size([1024])\n",
      "[ 0.16577148 -0.03125    -0.01722717 ... -0.06817627  0.04214478\n",
      " -0.04568481]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.03149414 -0.0814209  -0.2109375  ... -0.01073456 -0.00844574\n",
      "  -0.03985596]\n",
      " [-0.02734375 -0.08319092  0.05325317 ... -0.02191162  0.02180481\n",
      "   0.00269318]\n",
      " [ 0.0585022   0.03610229  0.05825806 ...  0.03240967 -0.04333496\n",
      "  -0.07226562]\n",
      " ...\n",
      " [ 0.00636292  0.0116272  -0.14953613 ...  0.07171631  0.06713867\n",
      "   0.0526123 ]\n",
      " [-0.06414795  0.01235199  0.03491211 ...  0.00714111  0.01132202\n",
      "   0.0064621 ]\n",
      " [-0.04321289 -0.04119873  0.04519653 ...  0.0171814  -0.02496338\n",
      "   0.06567383]]\n",
      "torch.Size([1024])\n",
      "[ 0.16491699 -0.03222656 -0.01635742 ... -0.06854248  0.04257202\n",
      " -0.04571533]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.00245857  0.04580688 -0.03118896 ... -0.02256775  0.00554657\n",
      "   0.03656006]\n",
      " [ 0.0350647   0.01628113 -0.02990723 ...  0.00842285  0.02708435\n",
      "  -0.0189209 ]\n",
      " [ 0.01170349 -0.04168701 -0.00547409 ... -0.01307678  0.01533508\n",
      "  -0.04162598]\n",
      " ...\n",
      " [ 0.01823425  0.04214478 -0.00539017 ...  0.02006531 -0.02067566\n",
      "   0.04962158]\n",
      " [-0.04837036  0.07391357 -0.06549072 ... -0.00182819 -0.04376221\n",
      "  -0.01791382]\n",
      " [ 0.01473999  0.01300049 -0.05767822 ...  0.05532837 -0.02397156\n",
      "  -0.02571106]]\n",
      "torch.Size([1024])\n",
      "[-0.02676392  0.08947754  0.04577637 ...  0.03533936  0.17687988\n",
      "  0.03125   ]\n",
      "torch.Size([1024])\n",
      "[0.96728516 0.9897461  1.0058594  ... 0.97753906 0.9921875  0.9892578 ]\n",
      "torch.Size([1024])\n",
      "[-0.04840088 -0.06045532 -0.13806152 ... -0.05032349 -0.10125732\n",
      " -0.03567505]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.01245117 -0.03469849  0.03918457 ...  0.05151367  0.02127075\n",
      "  -0.0267334 ]\n",
      " [ 0.00266838  0.00220871 -0.0748291  ...  0.02601624  0.00109196\n",
      "   0.05459595]\n",
      " [ 0.00024092  0.03948975 -0.04568481 ... -0.00365067  0.00849152\n",
      "   0.00967407]\n",
      " ...\n",
      " [-0.00794983 -0.01831055  0.02619934 ... -0.02177429 -0.07049561\n",
      "  -0.02485657]\n",
      " [ 0.00788879 -0.07061768  0.01507568 ... -0.02259827  0.00907898\n",
      "  -0.0209198 ]\n",
      " [ 0.00235176 -0.00134563  0.01872253 ... -0.01080322  0.03378296\n",
      "   0.03695679]]\n",
      "torch.Size([4096])\n",
      "[-0.02677917 -0.04547119  0.02024841 ... -0.02848816 -0.00212479\n",
      " -0.01434326]\n",
      "torch.Size([1024, 4096])\n",
      "[[-1.44500732e-02 -2.05636024e-05 -4.22286987e-03 ...  3.77197266e-02\n",
      "  -2.16217041e-02 -3.84216309e-02]\n",
      " [ 2.34794617e-03  1.01318359e-02 -3.68652344e-02 ...  1.49536133e-02\n",
      "  -3.39965820e-02  5.36804199e-02]\n",
      " [-1.46865845e-02  3.77845764e-03  4.29534912e-03 ...  1.04598999e-02\n",
      "   7.30514526e-03  1.37176514e-02]\n",
      " ...\n",
      " [-2.87322998e-02  1.13677979e-02  2.61840820e-02 ... -1.78222656e-02\n",
      "  -1.14135742e-02 -4.92095947e-04]\n",
      " [-3.31726074e-02  1.65581703e-04 -3.98254395e-02 ... -3.50036621e-02\n",
      "  -1.04614258e-01  3.95965576e-03]\n",
      " [-9.44519043e-03  6.19888306e-05  3.22151184e-03 ... -3.34548950e-03\n",
      "  -2.97393799e-02  2.54440308e-03]]\n",
      "torch.Size([1024])\n",
      "[-0.0096817   0.00595474 -0.07208252 ...  0.09106445 -0.12133789\n",
      "  0.01451874]\n",
      "torch.Size([1024])\n",
      "[0.9682617  0.9892578  1.0019531  ... 0.98291016 0.9863281  0.9916992 ]\n",
      "torch.Size([1024])\n",
      "[-0.04458618 -0.01478577  0.03668213 ... -0.03967285 -0.05755615\n",
      " -0.01715088]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00270844  0.03793335  0.08447266 ...  0.01409912  0.02148438\n",
      "   0.06268311]\n",
      " [ 0.01473999 -0.04034424  0.00554276 ... -0.10113525  0.05282593\n",
      "   0.01202393]\n",
      " [ 0.10003662 -0.02481079  0.18395996 ...  0.00997925  0.05789185\n",
      "  -0.00620651]\n",
      " ...\n",
      " [-0.00861359 -0.010849   -0.08184814 ... -0.07220459 -0.01026917\n",
      "   0.06915283]\n",
      " [-0.04223633  0.07476807 -0.01306915 ...  0.0585022  -0.03726196\n",
      "  -0.03179932]\n",
      " [ 0.03311157  0.05786133  0.10021973 ...  0.02664185 -0.02198792\n",
      "  -0.0791626 ]]\n",
      "torch.Size([1024])\n",
      "[-0.00432205  0.00632477  0.15197754 ...  0.00347519  0.1005249\n",
      " -0.05664062]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06896973 -0.04998779  0.0703125  ... -0.00084162 -0.0574646\n",
      "   0.04553223]\n",
      " [ 0.02476501 -0.02532959  0.0254364  ...  0.02986145 -0.01428223\n",
      "   0.01277161]\n",
      " [ 0.00582886  0.03050232  0.09057617 ...  0.01678467 -0.02098083\n",
      "   0.01329041]\n",
      " ...\n",
      " [ 0.08355713 -0.00332069 -0.10174561 ... -0.05841064 -0.05343628\n",
      "  -0.09112549]\n",
      " [ 0.02415466  0.06665039 -0.0609436  ...  0.03417969  0.03823853\n",
      "  -0.03500366]\n",
      " [-0.04864502  0.01716614 -0.02966309 ... -0.00024045  0.01927185\n",
      "  -0.01021576]]\n",
      "torch.Size([1024])\n",
      "[-0.00277328  0.00072718 -0.00286865 ...  0.00486755 -0.00111961\n",
      " -0.00032449]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.02467346  0.03527832  0.04440308 ...  0.04553223 -0.02172852\n",
      "   0.05056763]\n",
      " [-0.04672241 -0.01390839 -0.01495361 ...  0.0508728  -0.07458496\n",
      "   0.05725098]\n",
      " [-0.02009583  0.02929688  0.00695038 ... -0.00358772 -0.01705933\n",
      "   0.01773071]\n",
      " ...\n",
      " [-0.043396    0.0020504  -0.01396179 ... -0.03207397  0.02902222\n",
      "  -0.04742432]\n",
      " [ 0.01340485  0.0120697   0.03564453 ...  0.0076561   0.00518036\n",
      "  -0.03625488]\n",
      " [-0.02125549 -0.01693726 -0.0397644  ... -0.0292511   0.01525879\n",
      "   0.021698  ]]\n",
      "torch.Size([1024])\n",
      "[ 0.00828552 -0.01322174  0.01374054 ... -0.01193237 -0.00508499\n",
      " -0.00744247]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00266457  0.03765869  0.08520508 ...  0.01423645  0.02120972\n",
      "   0.06182861]\n",
      " [ 0.01480103 -0.03961182  0.00443268 ... -0.10113525  0.05224609\n",
      "   0.01166534]\n",
      " [ 0.10095215 -0.02322388  0.1850586  ...  0.01065063  0.05838013\n",
      "  -0.00729752]\n",
      " ...\n",
      " [-0.00754166 -0.01067352 -0.08166504 ... -0.07171631 -0.0110321\n",
      "   0.06976318]\n",
      " [-0.04211426  0.07525635 -0.01257324 ...  0.0585022  -0.03778076\n",
      "  -0.03100586]\n",
      " [ 0.03295898  0.05776978  0.09954834 ...  0.02616882 -0.0226593\n",
      "  -0.07788086]]\n",
      "torch.Size([1024])\n",
      "[-0.00475693  0.00694275  0.1508789  ...  0.00283051  0.10009766\n",
      " -0.05581665]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.00258827  0.03759766  0.08544922 ...  0.01488495  0.021698\n",
      "   0.06137085]\n",
      " [ 0.01483917 -0.03985596  0.00488663 ... -0.10021973  0.05264282\n",
      "   0.01183319]\n",
      " [ 0.10113525 -0.02355957  0.18493652 ...  0.00997925  0.05764771\n",
      "  -0.0077858 ]\n",
      " ...\n",
      " [-0.00733185 -0.01041412 -0.08117676 ... -0.07165527 -0.01031494\n",
      "   0.06915283]\n",
      " [-0.04180908  0.07452393 -0.01261902 ...  0.05892944 -0.03704834\n",
      "  -0.03179932]\n",
      " [ 0.03320312  0.05892944  0.1003418  ...  0.02622986 -0.02194214\n",
      "  -0.07891846]]\n",
      "torch.Size([1024])\n",
      "[-0.00455475  0.00640106  0.15075684 ...  0.00266838  0.09960938\n",
      " -0.05645752]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.0025692   0.03765869  0.08605957 ...  0.0154953   0.02107239\n",
      "   0.06137085]\n",
      " [ 0.01473999 -0.03936768  0.00432587 ... -0.10083008  0.05184937\n",
      "   0.01191711]\n",
      " [ 0.10089111 -0.02336121  0.18493652 ...  0.01005554  0.05831909\n",
      "  -0.00717545]\n",
      " ...\n",
      " [-0.00782013 -0.01033783 -0.08166504 ... -0.07177734 -0.01119232\n",
      "   0.06982422]\n",
      " [-0.04187012  0.0748291  -0.01295471 ...  0.05886841 -0.03704834\n",
      "  -0.03158569]\n",
      " [ 0.03271484  0.05810547  0.10040283 ...  0.02642822 -0.02258301\n",
      "  -0.07818604]]\n",
      "torch.Size([1024])\n",
      "[-0.00496292  0.00670624  0.15136719 ...  0.00317764  0.09960938\n",
      " -0.05639648]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.04064941  0.05151367 -0.00493622 ... -0.03259277 -0.03369141\n",
      "  -0.01203918]\n",
      " [ 0.00621033  0.02368164  0.0296936  ... -0.04760742  0.00510788\n",
      "   0.02973938]\n",
      " [ 0.01966858  0.00318527 -0.02609253 ... -0.01913452  0.0526123\n",
      "  -0.00317955]\n",
      " ...\n",
      " [ 0.03167725  0.02259827 -0.02027893 ...  0.01160431 -0.02328491\n",
      "  -0.0104599 ]\n",
      " [ 0.04388428 -0.01583862  0.02005005 ... -0.01733398 -0.00748444\n",
      "  -0.04302979]\n",
      " [ 0.03009033  0.04177856  0.03768921 ... -0.03509521  0.00575256\n",
      "  -0.00320625]]\n",
      "torch.Size([1024])\n",
      "[ 0.07531738  0.09490967  0.06768799 ...  0.00817108  0.14526367\n",
      " -0.03005981]\n",
      "torch.Size([1024])\n",
      "[0.95214844 0.98583984 0.9995117  ... 0.9741211  0.99365234 0.98535156]\n",
      "torch.Size([1024])\n",
      "[-0.04977417 -0.01412964 -0.12426758 ... -0.03823853 -0.10302734\n",
      "  0.03344727]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.00058746 -0.06988525 -0.04855347 ... -0.00944519  0.01348114\n",
      "   0.08154297]\n",
      " [-0.01937866 -0.02009583  0.0625     ...  0.00300598  0.04397583\n",
      "   0.00084496]\n",
      " [-0.02818298 -0.06616211  0.07434082 ...  0.01255798 -0.01448059\n",
      "  -0.04922485]\n",
      " ...\n",
      " [-0.03210449  0.01902771  0.04431152 ...  0.04986572  0.01223755\n",
      "   0.0395813 ]\n",
      " [ 0.06274414  0.01576233  0.04507446 ...  0.02172852 -0.00205421\n",
      "   0.0066452 ]\n",
      " [ 0.00540924 -0.07733154 -0.06091309 ... -0.00818634  0.01890564\n",
      "  -0.04736328]]\n",
      "torch.Size([4096])\n",
      "[ 0.01823425 -0.00806427 -0.0125885  ... -0.04611206  0.01499939\n",
      " -0.02880859]\n",
      "torch.Size([1024, 4096])\n",
      "[[-0.02626038  0.03479004 -0.02589417 ...  0.00712204 -0.00606537\n",
      "  -0.08526611]\n",
      " [ 0.01406097 -0.02536011  0.02320862 ... -0.00682449 -0.02970886\n",
      "   0.0171051 ]\n",
      " [-0.01564026 -0.01228333 -0.00447083 ...  0.00073862 -0.00336456\n",
      "   0.01233673]\n",
      " ...\n",
      " [-0.01236725 -0.02838135  0.01286316 ... -0.02178955 -0.00544739\n",
      "   0.05731201]\n",
      " [ 0.01664734 -0.03701782  0.04077148 ... -0.01113129 -0.02589417\n",
      "  -0.02766418]\n",
      " [-0.00751114  0.07019043  0.0308075  ... -0.02148438  0.00507355\n",
      "  -0.02467346]]\n",
      "torch.Size([1024])\n",
      "[ 0.02380371  0.04663086 -0.07452393 ...  0.02406311 -0.13183594\n",
      "  0.04608154]\n",
      "torch.Size([1024])\n",
      "[0.9609375  0.9951172  1.0009766  ... 0.9819336  0.9902344  0.98095703]\n",
      "torch.Size([1024])\n",
      "[-0.02256775  0.03890991  0.04763794 ... -0.03250122 -0.01206207\n",
      "  0.01757812]\n",
      "torch.Size([1024, 1024])\n",
      "[[-4.03137207e-02  1.95007324e-02  9.33227539e-02 ... -8.64257812e-02\n",
      "   8.31909180e-02  6.05468750e-02]\n",
      " [-4.33654785e-02  1.86309814e-02  1.01135254e-01 ... -7.40051270e-03\n",
      "  -1.58996582e-02 -2.06184387e-03]\n",
      " [ 3.97644043e-02  4.39147949e-02  3.14331055e-02 ... -8.62884521e-03\n",
      "  -8.45947266e-02 -3.32031250e-02]\n",
      " ...\n",
      " [ 9.99755859e-02 -5.02014160e-02  1.27197266e-01 ...  7.97271729e-04\n",
      "  -7.83538818e-03  6.50024414e-02]\n",
      " [-5.16357422e-02 -6.22868538e-05 -9.32693481e-04 ... -4.93164062e-02\n",
      "  -1.05743408e-02 -1.50299072e-02]\n",
      " [-3.72886658e-03 -4.93469238e-02 -5.70983887e-02 ...  4.66308594e-02\n",
      "  -6.21643066e-02  1.49917603e-02]]\n",
      "torch.Size([1024])\n",
      "[ 0.07794189  0.27392578  0.03013611 ... -0.2006836   0.11437988\n",
      "  0.08056641]\n",
      "torch.Size([1024, 1024])\n",
      "[[ 0.05664062 -0.02586365  0.2133789  ... -0.01318359  0.02523804\n",
      "   0.02301025]\n",
      " [ 0.07189941 -0.0682373   0.07446289 ...  0.0134201  -0.03979492\n",
      "   0.01049042]\n",
      " [-0.11157227 -0.02932739 -0.03646851 ... -0.12597656  0.04064941\n",
      "  -0.02938843]\n",
      " ...\n",
      " [ 0.04760742  0.01036835  0.06921387 ... -0.04379272  0.00124264\n",
      "   0.05471802]\n",
      " [ 0.02220154  0.01222992 -0.0670166  ... -0.02026367  0.03582764\n",
      "   0.0352478 ]\n",
      " [-0.01429749 -0.00948334 -0.01579285 ...  0.10919189  0.00348091\n",
      "   0.06420898]]\n",
      "torch.Size([1024])\n",
      "[-0.01655579 -0.00155163 -0.01494598 ...  0.08660889 -0.01345062\n",
      "  0.0021553 ]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.06726074 -0.06463623 -0.01300812 ... -0.03500366  0.00114536\n",
      "   0.01132965]\n",
      " [ 0.02165222  0.0051918   0.0397644  ... -0.02493286  0.00172329\n",
      "  -0.04977417]\n",
      " [-0.0486145   0.06665039 -0.01415253 ...  0.00618362 -0.04788208\n",
      "  -0.01215363]\n",
      " ...\n",
      " [ 0.05130005  0.02679443 -0.02824402 ... -0.00978088 -0.02494812\n",
      "   0.0137558 ]\n",
      " [ 0.00057936 -0.03375244  0.02555847 ... -0.01537323 -0.00064707\n",
      "   0.0146637 ]\n",
      " [ 0.01040649 -0.02311707  0.02537537 ... -0.00059319  0.01986694\n",
      "   0.01672363]]\n",
      "torch.Size([1024])\n",
      "[-0.01512909  0.0174408   0.0116806  ...  0.00801086  0.00704575\n",
      "  0.01396179]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04052734  0.01870728  0.09356689 ... -0.08575439  0.08361816\n",
      "   0.05938721]\n",
      " [-0.04336548  0.0176239   0.10131836 ... -0.00613022 -0.01531982\n",
      "  -0.00344086]\n",
      " [ 0.04016113  0.043396    0.0307312  ... -0.00889587 -0.08532715\n",
      "  -0.03201294]\n",
      " ...\n",
      " [ 0.10089111 -0.04910278  0.1274414  ...  0.00089455 -0.00811768\n",
      "   0.06439209]\n",
      " [-0.05096436 -0.00077343  0.00138664 ... -0.04742432 -0.01160431\n",
      "  -0.01483154]\n",
      " [-0.00457001 -0.05023193 -0.05563354 ...  0.0484314  -0.06292725\n",
      "   0.01571655]]\n",
      "torch.Size([1024])\n",
      "[ 0.07720947  0.27246094  0.03109741 ... -0.20141602  0.11297607\n",
      "  0.07989502]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04086304  0.01907349  0.09368896 ... -0.08630371  0.08392334\n",
      "   0.05987549]\n",
      " [-0.04321289  0.01815796  0.10229492 ... -0.00689697 -0.01568604\n",
      "  -0.00300026]\n",
      " [ 0.04040527  0.04379272  0.03053284 ... -0.00948334 -0.0848999\n",
      "  -0.03271484]\n",
      " ...\n",
      " [ 0.10089111 -0.0496521   0.12817383 ...  0.000947   -0.00808716\n",
      "   0.06433105]\n",
      " [-0.05160522 -0.00056791  0.00040531 ... -0.04815674 -0.0115509\n",
      "  -0.0151062 ]\n",
      " [-0.00512314 -0.05007935 -0.05645752 ...  0.04788208 -0.06298828\n",
      "   0.01525116]]\n",
      "torch.Size([1024])\n",
      "[ 0.07739258  0.27270508  0.03108215 ... -0.20141602  0.11297607\n",
      "  0.07983398]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.04086304  0.01907349  0.09368896 ... -0.08630371  0.08392334\n",
      "   0.05987549]\n",
      " [-0.04321289  0.01815796  0.10229492 ... -0.00689697 -0.01568604\n",
      "  -0.00300026]\n",
      " [ 0.04040527  0.04379272  0.03053284 ... -0.00948334 -0.0848999\n",
      "  -0.03271484]\n",
      " ...\n",
      " [ 0.10089111 -0.0496521   0.12817383 ...  0.000947   -0.00808716\n",
      "   0.06433105]\n",
      " [-0.05160522 -0.00056791  0.00040531 ... -0.04815674 -0.0115509\n",
      "  -0.0151062 ]\n",
      " [-0.00512314 -0.05007935 -0.05645752 ...  0.04788208 -0.06298828\n",
      "   0.01525116]]\n",
      "torch.Size([1024])\n",
      "[ 0.07739258  0.27270508  0.03108215 ... -0.20141602  0.11297607\n",
      "  0.07983398]\n",
      "torch.Size([1024, 1024])\n",
      "[[-0.02203369 -0.00839233 -0.00238609 ...  0.04208374 -0.02998352\n",
      "   0.03268433]\n",
      " [-0.04159546 -0.00881195  0.02467346 ...  0.04931641 -0.00928497\n",
      "  -0.04580688]\n",
      " [-0.02009583  0.00629807  0.00865936 ... -0.01019287  0.01136017\n",
      "  -0.03213501]\n",
      " ...\n",
      " [-0.00053024 -0.05108643 -0.01293945 ... -0.0213623   0.00066805\n",
      "  -0.00293732]\n",
      " [ 0.01511383  0.04315186  0.01329803 ...  0.01065826  0.00444794\n",
      "   0.00399399]\n",
      " [ 0.037323   -0.01483154 -0.02755737 ... -0.01483917  0.01501465\n",
      "   0.01228333]]\n",
      "torch.Size([1024])\n",
      "[ 0.06268311  0.07128906 -0.00597    ...  0.03131104  0.02072144\n",
      "  0.1619873 ]\n",
      "torch.Size([1024])\n",
      "[0.9604492 0.9790039 0.9916992 ... 0.9765625 0.9897461 0.9604492]\n",
      "torch.Size([1024])\n",
      "[-0.13696289  0.02940369 -0.16369629 ... -0.06561279 -0.14416504\n",
      " -0.09204102]\n",
      "torch.Size([4096, 1024])\n",
      "[[-0.01121521 -0.08587646 -0.01196289 ... -0.01268768  0.00962067\n",
      "  -0.02392578]\n",
      " [-0.01660156 -0.02435303 -0.0120697  ... -0.01243591  0.01841736\n",
      "  -0.05786133]\n",
      " [-0.00056553 -0.09307861 -0.00343513 ...  0.03396606  0.03265381\n",
      "  -0.01809692]\n",
      " ...\n",
      " [-0.03735352  0.02011108  0.01229858 ...  0.00533295 -0.03979492\n",
      "  -0.00839996]\n",
      " [ 0.04269409  0.00105286 -0.00738525 ... -0.01864624  0.06292725\n",
      "   0.04376221]\n",
      " [ 0.04064941 -0.02224731 -0.02929688 ...  0.04827881  0.02955627\n",
      "   0.0447998 ]]\n",
      "torch.Size([4096])\n",
      "[ 0.01008606 -0.06744385 -0.12792969 ... -0.04055786 -0.09368896\n",
      " -0.01235199]\n",
      "torch.Size([1024, 4096])\n",
      "[[ 0.02523804 -0.0401001  -0.01901245 ...  0.01461792  0.02679443\n",
      "  -0.00520706]\n",
      " [ 0.01161957  0.0637207  -0.02316284 ... -0.0174408  -0.04003906\n",
      "   0.02636719]\n",
      " [-0.00186634 -0.00965118  0.00512314 ...  0.01046753 -0.02597046\n",
      "  -0.01519775]\n",
      " ...\n",
      " [ 0.01480865 -0.03262329  0.07843018 ...  0.02780151 -0.01834106\n",
      "   0.0428772 ]\n",
      " [ 0.01021576 -0.01421356  0.04763794 ...  0.00563812  0.02630615\n",
      "  -0.00894928]\n",
      " [-0.03970337  0.01078796  0.00059557 ...  0.03396606  0.01525116\n",
      "  -0.01609802]]\n",
      "torch.Size([1024])\n",
      "[-0.07574463 -0.0241394  -0.0949707  ...  0.07611084 -0.15881348\n",
      "  0.07977295]\n",
      "torch.Size([1024])\n",
      "[0.98046875 0.99316406 0.9951172  ... 0.97558594 1.0009766  0.98535156]\n",
      "torch.Size([1024])\n",
      "[-0.03579712 -0.03439331 -0.01200867 ... -0.04693604  0.00065517\n",
      " -0.01837158]\n",
      "torch.Size([1024, 1024])\n",
      "[[-2.13470459e-02 -6.30187988e-03 -2.88238525e-02 ...  9.42993164e-03\n",
      "  -7.88116455e-03  1.55181885e-02]\n",
      " [-2.56156921e-03 -1.53961182e-02  5.11932373e-03 ... -4.00695801e-02\n",
      "  -1.03073120e-02 -4.01000977e-02]\n",
      " [ 7.88879395e-03  1.98974609e-02 -1.42574310e-03 ...  5.34057617e-03\n",
      "  -1.07040405e-02  1.60026550e-03]\n",
      " ...\n",
      " [ 1.47819519e-05 -7.47299194e-03 -1.65710449e-02 ... -2.60467529e-02\n",
      "  -7.80105591e-04 -6.76345825e-03]\n",
      " [-8.01849365e-03 -1.46942139e-02 -2.60314941e-02 ... -3.07617188e-02\n",
      "  -1.13372803e-02  2.31628418e-02]\n",
      " [-6.01196289e-03  2.79235840e-02 -4.34875488e-02 ...  2.19726562e-02\n",
      "   1.41620636e-03 -1.33743286e-02]]\n",
      "torch.Size([1024])\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "torch.Size([50265, 1024])\n",
      "[[-0.14099121 -0.00894928  0.0383606  ...  0.05111694 -0.00687408\n",
      "  -0.03741455]\n",
      " [ 0.00891113 -0.01418304  0.01279449 ... -0.01542664  0.0242157\n",
      "   0.01373291]\n",
      " [-0.07897949  0.00053406 -0.11676025 ...  0.10913086  0.06585693\n",
      "  -0.03863525]\n",
      " ...\n",
      " [ 0.0395813   0.00103474  0.04776001 ... -0.02496338 -0.04998779\n",
      "   0.0352478 ]\n",
      " [ 0.04812622  0.02618408  0.0423584  ... -0.03707886 -0.00624847\n",
      "   0.00845337]\n",
      " [-0.01303864 -0.01062775 -0.02287292 ...  0.04510498  0.01077271\n",
      "  -0.03579712]]\n",
      "torch.Size([514, 1024])\n",
      "[[-0.00381279  0.025177   -0.00918579 ...  0.01765442  0.00617599\n",
      "  -0.01608276]\n",
      " [ 0.01277161 -0.00048232 -0.02929688 ...  0.00626373 -0.01789856\n",
      "   0.02441406]\n",
      " [ 0.02984619  0.01522064 -0.0552063  ... -0.07073975 -0.04653931\n",
      "   0.04504395]\n",
      " ...\n",
      " [-0.02078247 -0.00632095  0.04727173 ... -0.03872681  0.04483032\n",
      "   0.05380249]\n",
      " [-0.02818298  0.1192627   0.04541016 ...  0.02059937 -0.11883545\n",
      "   0.04980469]\n",
      " [ 0.0958252  -0.07531738  0.05166626 ... -0.11505127 -0.10528564\n",
      "   0.04885864]]\n",
      "torch.Size([1, 1024])\n",
      "[[-0.00088692  0.00033689  0.00063467 ... -0.00023806 -0.00042081\n",
      "  -0.00111485]]\n",
      "torch.Size([1024])\n",
      "[0.9316406  0.92333984 0.91259766 ... 0.9394531  0.9135742  0.90185547]\n",
      "torch.Size([1024])\n",
      "[ 0.029953    0.04220581  0.19360352 ... -0.22521973 -0.08947754\n",
      "  0.12457275]\n",
      "torch.Size([500000, 256])\n",
      "[[-0.04199219 -0.06100464 -0.04818726 ... -0.03359985 -0.05334473\n",
      "  -0.0461731 ]\n",
      " [ 0.06988525  0.06213379  0.08544922 ...  0.05511475  0.04660034\n",
      "   0.07769775]\n",
      " [ 0.00736618 -0.00665283  0.00145912 ... -0.0110321  -0.00521851\n",
      "  -0.00029135]\n",
      " ...\n",
      " [-0.07800293 -0.05435181 -0.06347656 ...  0.00606155 -0.09075928\n",
      "  -0.08013916]\n",
      " [-0.09130859 -0.06915283 -0.01226044 ... -0.13842773 -0.03399658\n",
      "  -0.06201172]\n",
      " [ 0.01237488 -0.02178955 -0.00234795 ... -0.13305664 -0.07214355\n",
      "  -0.09527588]]\n",
      "torch.Size([1024, 256])\n",
      "[[-0.19812012  0.00070715 -0.02018738 ...  0.06439209 -0.04174805\n",
      "  -0.03970337]\n",
      " [-0.07446289  0.0541687  -0.06188965 ...  0.04681396  0.22839355\n",
      "   0.12072754]\n",
      " [-0.10247803  0.02705383  0.03884888 ...  0.1439209   0.04171753\n",
      "  -0.02601624]\n",
      " ...\n",
      " [ 0.06219482  0.02380371  0.07080078 ... -0.02850342 -0.04333496\n",
      "  -0.01858521]\n",
      " [-0.1015625   0.01934814  0.09320068 ... -0.18664551 -0.1315918\n",
      "   0.04898071]\n",
      " [-0.00860596 -0.04336548  0.02851868 ... -0.03167725  0.00383186\n",
      "   0.01863098]]\n",
      "torch.Size([514, 1024])\n",
      "[[-0.02030945 -0.01771545 -0.01237488 ... -0.01872253  0.02352905\n",
      "   0.01004028]\n",
      " [-0.05096436  0.01364899 -0.05950928 ... -0.20349121 -0.02737427\n",
      "  -0.05996704]\n",
      " [-0.02708435 -0.1048584  -0.00720215 ... -0.10388184  0.01968384\n",
      "  -0.06982422]\n",
      " ...\n",
      " [ 0.0191803   0.00892639  0.00978851 ... -0.01629639 -0.00247955\n",
      "  -0.01139832]\n",
      " [-0.00926971  0.00561523  0.00434494 ... -0.00496292 -0.02194214\n",
      "   0.00917053]\n",
      " [ 0.00040841  0.0029335  -0.00442123 ... -0.01570129 -0.00133991\n",
      "  -0.01715088]]\n",
      "torch.Size([1, 1024])\n",
      "[[ 0.02012634  0.06402588  0.04711914 ... -0.06451416 -0.04608154\n",
      "   0.05041504]]\n",
      "torch.Size([1024])\n",
      "[1.0410156  1.0244141  1.0097656  ... 1.0058594  1.0859375  0.98876953]\n",
      "torch.Size([1024])\n",
      "[ 0.35302734 -0.1463623   0.07421875 ...  0.5566406   0.06118774\n",
      " -0.20422363]\n",
      "torch.Size([2, 1024])\n",
      "[[-0.0027504  -0.00932312  0.01831055 ...  0.02409363 -0.04522705\n",
      "  -0.02876282]\n",
      " [-0.01753235  0.01861572  0.02708435 ... -0.01815796  0.0148468\n",
      "   0.00082541]]\n",
      "torch.Size([2])\n",
      "[0.00021732 0.00048757]\n"
     ]
    }
   ],
   "source": [
    " for weight_name, weight_value in torch_model.items():\n",
    "        print(weight_value.shape)\n",
    "        y=weight_value.numpy()\n",
    "        print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mindspore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context\n",
    "from model.luke import LukeModel, EntityAwareEncoder\n",
    "import numpy as np\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from model.bert_model import BertOutput\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "import math\n",
    "from mindspore.ops import composite as C\n",
    "import mindspore\n",
    "from mindspore.ops import operations as P\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.layer.0.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.0.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.0.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.0.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.0.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.0.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.0.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.0.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.0.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.0.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.0.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.0.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.1.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.1.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.1.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.1.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.1.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.1.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.1.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.1.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.1.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.1.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.1.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.2.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.2.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.2.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.2.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.2.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.2.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.2.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.2.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.2.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.2.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.2.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.3.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.3.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.3.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.3.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.3.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.3.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.3.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.3.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.3.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.3.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.3.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.4.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.4.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.4.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.4.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.4.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.4.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.4.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.4.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.4.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.4.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.4.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.5.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.5.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.5.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.5.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.5.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.5.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.5.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.5.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.5.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.5.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.5.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.6.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.6.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.6.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.6.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.6.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.6.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.6.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.6.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.6.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.6.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.6.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.7.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.7.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.7.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.7.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.7.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.7.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.7.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.7.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.7.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.7.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.7.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.8.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.8.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.8.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.8.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.8.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.8.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.8.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.8.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.8.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.8.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.8.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.9.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.9.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.9.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.9.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.9.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.9.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.9.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.9.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.9.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.9.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.9.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.10.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.10.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.10.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.10.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.10.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.10.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.10.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.10.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.10.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.10.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.10.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.11.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.11.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.11.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.11.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.11.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.11.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.11.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.11.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.11.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.11.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.11.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.12.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.12.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.12.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.12.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.12.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.12.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.12.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.12.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.12.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.12.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.12.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.13.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.13.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.13.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.13.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.13.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.13.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.13.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.13.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.13.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.13.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.13.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.14.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.14.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.14.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.14.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.14.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.14.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.14.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.14.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.14.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.14.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.14.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.15.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.15.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.15.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.15.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.15.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.15.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.15.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.15.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.15.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.15.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.15.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.16.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.16.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.16.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.16.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.16.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.16.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.16.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.16.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.16.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.16.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.16.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.17.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.17.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.17.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.17.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.17.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.17.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.17.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.17.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.17.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.17.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.17.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.18.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.18.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.18.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.18.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.18.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.18.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.18.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.18.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.18.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.18.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.18.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.19.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.19.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.19.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.19.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.19.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.19.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.19.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.19.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.19.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.19.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.19.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.20.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.20.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.20.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.20.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.20.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.20.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.20.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.20.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.20.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.20.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.20.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.21.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.21.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.21.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.21.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.21.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.21.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.21.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.21.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.21.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.21.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.21.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.22.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.22.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.22.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.22.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.22.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.22.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.22.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.22.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.22.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.22.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.22.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.query.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.query.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.key.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.key.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.key.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.key.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.value.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.value.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.value.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.value.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.w2e_query.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.w2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.w2e_query.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.w2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.e2w_query.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.e2w_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.e2w_query.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.e2w_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.e2e_query.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.self.e2e_query.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.self.e2e_query.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.self.e2e_query.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.23.attention.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.23.attention.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.23.attention.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.attention.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.23.attention.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.intermediate.weight',\n",
       "              Parameter (name=encoder.layer.23.intermediate.weight, shape=(4096, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.intermediate.bias',\n",
       "              Parameter (name=encoder.layer.23.intermediate.bias, shape=(4096,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.output.dense.weight',\n",
       "              Parameter (name=encoder.layer.23.output.dense.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.output.dense.bias',\n",
       "              Parameter (name=encoder.layer.23.output.dense.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.output.layernorm.gamma',\n",
       "              Parameter (name=encoder.layer.23.output.layernorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('encoder.layer.23.output.layernorm.beta',\n",
       "              Parameter (name=encoder.layer.23.output.layernorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('pooler.weight',\n",
       "              Parameter (name=pooler.weight, shape=(1024, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('pooler.bias',\n",
       "              Parameter (name=pooler.bias, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('embeddings.word_embeddings.embedding_table',\n",
       "              Parameter (name=embeddings.word_embeddings.embedding_table, shape=(50267, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('embeddings.position_embeddings.embedding_table',\n",
       "              Parameter (name=embeddings.position_embeddings.embedding_table, shape=(514, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('embeddings.token_type_embeddings.embedding_table',\n",
       "              Parameter (name=embeddings.token_type_embeddings.embedding_table, shape=(16, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('embeddings.LayerNorm.gamma',\n",
       "              Parameter (name=embeddings.LayerNorm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('embeddings.LayerNorm.beta',\n",
       "              Parameter (name=embeddings.LayerNorm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.entity_embeddings.embedding_table',\n",
       "              Parameter (name=entity_embeddings.entity_embeddings.embedding_table, shape=(500000, 256), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.entity_embedding_dense.weight',\n",
       "              Parameter (name=entity_embeddings.entity_embedding_dense.weight, shape=(1024, 256), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.position_embeddings.embedding_table',\n",
       "              Parameter (name=entity_embeddings.position_embeddings.embedding_table, shape=(514, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.token_type_embeddings.embedding_table',\n",
       "              Parameter (name=entity_embeddings.token_type_embeddings.embedding_table, shape=(16, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.layer_norm.gamma',\n",
       "              Parameter (name=entity_embeddings.layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('entity_embeddings.layer_norm.beta',\n",
       "              Parameter (name=entity_embeddings.layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)),\n",
       "             ('qa_outputs.weight',\n",
       "              Parameter (name=qa_outputs.weight, shape=(2, 1024), dtype=Float32, requires_grad=True)),\n",
       "             ('qa_outputs.bias',\n",
       "              Parameter (name=qa_outputs.bias, shape=(2,), dtype=Float32, requires_grad=True))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "model = LukeForReadingComprehension(config)\n",
    "ms_model = model.parameters_dict()\n",
    "ms_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter (name=embeddings.word_embeddings.embedding_table, shape=(50267, 1024), dtype=Float32, requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_model['embeddings.word_embeddings.embedding_table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch2ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "from mindspore import log as logger\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_params_map(attention_num=16):\n",
    "    \"\"\"\n",
    "    build params map from torch's LUKE to mindspore's LUKE\n",
    "    map=> key：value，torch_name：ms_name\n",
    "    键：torch权重名称，值：mindspore权重名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    weight_map = collections.OrderedDict({\n",
    "        'embeddings.word_embeddings.weight': \"embeddings.word_embeddings.embedding_table\",\n",
    "        'embeddings.position_embeddings.weight': \"embeddings.position_embeddings.embedding_table\",\n",
    "        'embeddings.token_type_embeddings.weight': \"embeddings.token_type_embeddings.embedding_table\",\n",
    "        'embeddings.LayerNorm.weight': 'embeddings.LayerNorm.gamma',\n",
    "        'embeddings.LayerNorm.bias': 'embeddings.LayerNorm.beta',\n",
    "        'entity_embeddings.entity_embeddings.weight':'entity_embeddings.entity_embeddings.embedding_table',\n",
    "        'entity_embeddings.entity_embedding_dense.weight':'entity_embeddings.entity_embedding_dense.weight',\n",
    "        'entity_embeddings.position_embeddings.weight':'entity_embeddings.position_embeddings.embedding_table',\n",
    "        'entity_embeddings.token_type_embeddings.weight':'entity_embeddings.token_type_embeddings.embedding_table',\n",
    "        'entity_embeddings.LayerNorm.weight':'entity_embeddings.layer_norm.gamma',\n",
    "        'entity_embeddings.LayerNorm.bias':'entity_embeddings.layer_norm.beta',\n",
    "        'qa_outputs.weight':'qa_outputs.weight',\n",
    "        'qa_outputs.bias':'qa_outputs.bias',\n",
    "        'pooler.dense.weight':'pooler.weight',\n",
    "        'pooler.dense.bias':'pooler.bias'\n",
    "        \n",
    "    })\n",
    "    \n",
    "    # add attention layers\n",
    "    for i in range(attention_num):\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.query.weight'] = \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.query.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.query.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.query.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.key.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.key.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.key.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.key.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.value.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.value.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.value.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.value.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.w2e_query.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.w2e_query.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.w2e_query.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.w2e_query.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.e2w_query.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.e2w_query.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.e2w_query.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.e2w_query.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.e2e_query.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.e2e_query.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.self.e2e_query.bias']= \\\n",
    "            f'encoder.layer.{i}.attention.self_attention.e2e_query.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.output.dense.weight']= \\\n",
    "            f'encoder.layer.{i}.attention.output.dense.weight'\n",
    "        weight_map[f'encoder.layer.{i}.attention.output.dense.bias'] = \\\n",
    "            f'encoder.layer.{i}.attention.output.dense.bias'\n",
    "        weight_map[f'encoder.layer.{i}.attention.output.LayerNorm.weight'] = \\\n",
    "            f'encoder.layer.{i}.attention.output.LayerNorm.gamma'\n",
    "        weight_map[f'encoder.layer.{i}.attention.output.LayerNorm.bias'] = \\\n",
    "            f'encoder.layer.{i}.attention.output.LayerNorm.beta'\n",
    "        weight_map[f'encoder.layer.{i}.intermediate.dense.weight'] = \\\n",
    "            f'encoder.layer.{i}.intermediate.weight'\n",
    "        weight_map[f'encoder.layer.{i}.intermediate.dense.bias'] = \\\n",
    "            f'encoder.layer.{i}.intermediate.bias'\n",
    "        weight_map[f'encoder.layer.{i}.output.dense.weight'] = \\\n",
    "            f'encoder.layer.{i}.output.dense.weight'\n",
    "        weight_map[f'encoder.layer.{i}.output.dense.bias'] = \\\n",
    "            f'encoder.layer.{i}.output.dense.bias'\n",
    "        weight_map[f'encoder.layer.{i}.output.LayerNorm.weight'] = \\\n",
    "            f'encoder.layer.{i}.output.layernorm.gamma'\n",
    "        weight_map[f'encoder.layer.{i}.output.LayerNorm.bias'] = \\\n",
    "            f'encoder.layer.{i}.output.layernorm.beta'\n",
    "    # add pooler\n",
    "#     weight_map.update(\n",
    "#         {\n",
    "#             'pooled_fc.w_0': 'ernie.ernie.dense.weight',\n",
    "#             'pooled_fc.b_0': 'ernie.ernie.dense.bias',\n",
    "#             'cls_out_w': 'ernie.dense_1.weight',\n",
    "#             'cls_out_b': 'ernie.dense_1.bias'\n",
    "#         }\n",
    "#    )\n",
    "    return weight_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_convert(torch_model, ms_model):\n",
    "    \"\"\"extract weights and convert to mindspore\"\"\"\n",
    "    print('=' * 20 + 'extract weights' + '=' * 20)\n",
    "    state_dict = []\n",
    "    weight_map = build_params_map(attention_num=config.num_attention_heads)\n",
    "    \n",
    "    for weight_name, weight_value in torch_model.items():\n",
    "        if weight_name not in weight_map.keys():\n",
    "            continue\n",
    "       \n",
    "        state_dict.append({'name': weight_map[weight_name], 'data': Tensor(weight_value.numpy())})\n",
    "        print(weight_name, '->', weight_map[weight_name], weight_value.shape)\n",
    "    save_checkpoint(state_dict, os.path.join(\"./luke-large-qa.ckpt\"))\n",
    "    print('=' * 20 + 'extract weights finished' + '=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================extract weights====================\n",
      "encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.self.w2e_query.weight -> encoder.layer.0.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.w2e_query.bias -> encoder.layer.0.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.self.e2w_query.weight -> encoder.layer.0.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.e2w_query.bias -> encoder.layer.0.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.self.e2e_query.weight -> encoder.layer.0.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.self.e2e_query.bias -> encoder.layer.0.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.0.intermediate.dense.weight -> encoder.layer.0.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.0.intermediate.dense.bias -> encoder.layer.0.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.0.output.dense.weight -> encoder.layer.0.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.0.output.dense.bias -> encoder.layer.0.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.0.output.LayerNorm.weight -> encoder.layer.0.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.0.output.LayerNorm.bias -> encoder.layer.0.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.1.attention.self.query.weight -> encoder.layer.1.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.query.bias -> encoder.layer.1.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.self.key.weight -> encoder.layer.1.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.key.bias -> encoder.layer.1.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.self.value.weight -> encoder.layer.1.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.value.bias -> encoder.layer.1.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.self.w2e_query.weight -> encoder.layer.1.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.w2e_query.bias -> encoder.layer.1.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.self.e2w_query.weight -> encoder.layer.1.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.e2w_query.bias -> encoder.layer.1.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.self.e2e_query.weight -> encoder.layer.1.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.self.e2e_query.bias -> encoder.layer.1.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.output.dense.weight -> encoder.layer.1.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.1.attention.output.dense.bias -> encoder.layer.1.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.1.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.1.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.1.intermediate.dense.weight -> encoder.layer.1.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.1.intermediate.dense.bias -> encoder.layer.1.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.1.output.dense.weight -> encoder.layer.1.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.1.output.dense.bias -> encoder.layer.1.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.1.output.LayerNorm.weight -> encoder.layer.1.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.1.output.LayerNorm.bias -> encoder.layer.1.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.2.attention.self.query.weight -> encoder.layer.2.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.query.bias -> encoder.layer.2.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.self.key.weight -> encoder.layer.2.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.key.bias -> encoder.layer.2.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.self.value.weight -> encoder.layer.2.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.value.bias -> encoder.layer.2.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.self.w2e_query.weight -> encoder.layer.2.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.w2e_query.bias -> encoder.layer.2.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.self.e2w_query.weight -> encoder.layer.2.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.e2w_query.bias -> encoder.layer.2.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.self.e2e_query.weight -> encoder.layer.2.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.self.e2e_query.bias -> encoder.layer.2.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.output.dense.weight -> encoder.layer.2.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.2.attention.output.dense.bias -> encoder.layer.2.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.2.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.2.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.2.intermediate.dense.weight -> encoder.layer.2.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.2.intermediate.dense.bias -> encoder.layer.2.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.2.output.dense.weight -> encoder.layer.2.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.2.output.dense.bias -> encoder.layer.2.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.2.output.LayerNorm.weight -> encoder.layer.2.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.2.output.LayerNorm.bias -> encoder.layer.2.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.3.attention.self.query.weight -> encoder.layer.3.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.query.bias -> encoder.layer.3.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.self.key.weight -> encoder.layer.3.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.key.bias -> encoder.layer.3.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.self.value.weight -> encoder.layer.3.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.value.bias -> encoder.layer.3.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.self.w2e_query.weight -> encoder.layer.3.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.w2e_query.bias -> encoder.layer.3.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.self.e2w_query.weight -> encoder.layer.3.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.e2w_query.bias -> encoder.layer.3.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.self.e2e_query.weight -> encoder.layer.3.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.self.e2e_query.bias -> encoder.layer.3.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.output.dense.weight -> encoder.layer.3.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.3.attention.output.dense.bias -> encoder.layer.3.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.3.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.3.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.3.intermediate.dense.weight -> encoder.layer.3.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.3.intermediate.dense.bias -> encoder.layer.3.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.3.output.dense.weight -> encoder.layer.3.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.3.output.dense.bias -> encoder.layer.3.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.3.output.LayerNorm.weight -> encoder.layer.3.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.3.output.LayerNorm.bias -> encoder.layer.3.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.4.attention.self.query.weight -> encoder.layer.4.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.query.bias -> encoder.layer.4.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.self.key.weight -> encoder.layer.4.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.key.bias -> encoder.layer.4.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.self.value.weight -> encoder.layer.4.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.value.bias -> encoder.layer.4.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.self.w2e_query.weight -> encoder.layer.4.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.w2e_query.bias -> encoder.layer.4.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.self.e2w_query.weight -> encoder.layer.4.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.e2w_query.bias -> encoder.layer.4.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.self.e2e_query.weight -> encoder.layer.4.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.self.e2e_query.bias -> encoder.layer.4.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.output.dense.weight -> encoder.layer.4.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.4.attention.output.dense.bias -> encoder.layer.4.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.4.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.4.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.4.intermediate.dense.weight -> encoder.layer.4.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.4.intermediate.dense.bias -> encoder.layer.4.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.4.output.dense.weight -> encoder.layer.4.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.4.output.dense.bias -> encoder.layer.4.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.4.output.LayerNorm.weight -> encoder.layer.4.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.4.output.LayerNorm.bias -> encoder.layer.4.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.5.attention.self.query.weight -> encoder.layer.5.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.query.bias -> encoder.layer.5.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.self.key.weight -> encoder.layer.5.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.key.bias -> encoder.layer.5.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.self.value.weight -> encoder.layer.5.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.value.bias -> encoder.layer.5.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.self.w2e_query.weight -> encoder.layer.5.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.w2e_query.bias -> encoder.layer.5.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.self.e2w_query.weight -> encoder.layer.5.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.e2w_query.bias -> encoder.layer.5.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.self.e2e_query.weight -> encoder.layer.5.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.self.e2e_query.bias -> encoder.layer.5.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.output.dense.weight -> encoder.layer.5.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.5.attention.output.dense.bias -> encoder.layer.5.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.5.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.5.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.5.intermediate.dense.weight -> encoder.layer.5.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.5.intermediate.dense.bias -> encoder.layer.5.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.5.output.dense.weight -> encoder.layer.5.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.5.output.dense.bias -> encoder.layer.5.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.5.output.LayerNorm.weight -> encoder.layer.5.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.5.output.LayerNorm.bias -> encoder.layer.5.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.6.attention.self.query.weight -> encoder.layer.6.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.query.bias -> encoder.layer.6.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.self.key.weight -> encoder.layer.6.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.key.bias -> encoder.layer.6.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.self.value.weight -> encoder.layer.6.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.value.bias -> encoder.layer.6.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.self.w2e_query.weight -> encoder.layer.6.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.w2e_query.bias -> encoder.layer.6.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.self.e2w_query.weight -> encoder.layer.6.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.e2w_query.bias -> encoder.layer.6.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.self.e2e_query.weight -> encoder.layer.6.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.self.e2e_query.bias -> encoder.layer.6.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.output.dense.weight -> encoder.layer.6.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.6.attention.output.dense.bias -> encoder.layer.6.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.6.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.6.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.6.intermediate.dense.weight -> encoder.layer.6.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.6.intermediate.dense.bias -> encoder.layer.6.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.6.output.dense.weight -> encoder.layer.6.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.6.output.dense.bias -> encoder.layer.6.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.6.output.LayerNorm.weight -> encoder.layer.6.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.6.output.LayerNorm.bias -> encoder.layer.6.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.7.attention.self.query.weight -> encoder.layer.7.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.query.bias -> encoder.layer.7.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.self.key.weight -> encoder.layer.7.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.key.bias -> encoder.layer.7.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.self.value.weight -> encoder.layer.7.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.value.bias -> encoder.layer.7.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.self.w2e_query.weight -> encoder.layer.7.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.w2e_query.bias -> encoder.layer.7.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.self.e2w_query.weight -> encoder.layer.7.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.e2w_query.bias -> encoder.layer.7.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.self.e2e_query.weight -> encoder.layer.7.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.self.e2e_query.bias -> encoder.layer.7.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.output.dense.weight -> encoder.layer.7.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.7.attention.output.dense.bias -> encoder.layer.7.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.7.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.7.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.7.intermediate.dense.weight -> encoder.layer.7.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.7.intermediate.dense.bias -> encoder.layer.7.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.7.output.dense.weight -> encoder.layer.7.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.7.output.dense.bias -> encoder.layer.7.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.7.output.LayerNorm.weight -> encoder.layer.7.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.7.output.LayerNorm.bias -> encoder.layer.7.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.8.attention.self.query.weight -> encoder.layer.8.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.query.bias -> encoder.layer.8.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.self.key.weight -> encoder.layer.8.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.key.bias -> encoder.layer.8.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.self.value.weight -> encoder.layer.8.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.value.bias -> encoder.layer.8.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.self.w2e_query.weight -> encoder.layer.8.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.w2e_query.bias -> encoder.layer.8.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.self.e2w_query.weight -> encoder.layer.8.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.e2w_query.bias -> encoder.layer.8.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.self.e2e_query.weight -> encoder.layer.8.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.self.e2e_query.bias -> encoder.layer.8.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.output.dense.weight -> encoder.layer.8.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.8.attention.output.dense.bias -> encoder.layer.8.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.8.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.8.attention.output.LayerNorm.beta torch.Size([1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layer.8.intermediate.dense.weight -> encoder.layer.8.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.8.intermediate.dense.bias -> encoder.layer.8.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.8.output.dense.weight -> encoder.layer.8.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.8.output.dense.bias -> encoder.layer.8.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.8.output.LayerNorm.weight -> encoder.layer.8.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.8.output.LayerNorm.bias -> encoder.layer.8.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.9.attention.self.query.weight -> encoder.layer.9.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.query.bias -> encoder.layer.9.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.self.key.weight -> encoder.layer.9.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.key.bias -> encoder.layer.9.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.self.value.weight -> encoder.layer.9.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.value.bias -> encoder.layer.9.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.self.w2e_query.weight -> encoder.layer.9.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.w2e_query.bias -> encoder.layer.9.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.self.e2w_query.weight -> encoder.layer.9.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.e2w_query.bias -> encoder.layer.9.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.self.e2e_query.weight -> encoder.layer.9.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.self.e2e_query.bias -> encoder.layer.9.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.output.dense.weight -> encoder.layer.9.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.9.attention.output.dense.bias -> encoder.layer.9.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.9.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.9.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.9.intermediate.dense.weight -> encoder.layer.9.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.9.intermediate.dense.bias -> encoder.layer.9.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.9.output.dense.weight -> encoder.layer.9.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.9.output.dense.bias -> encoder.layer.9.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.9.output.LayerNorm.weight -> encoder.layer.9.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.9.output.LayerNorm.bias -> encoder.layer.9.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.10.attention.self.query.weight -> encoder.layer.10.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.query.bias -> encoder.layer.10.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.self.key.weight -> encoder.layer.10.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.key.bias -> encoder.layer.10.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.self.value.weight -> encoder.layer.10.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.value.bias -> encoder.layer.10.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.self.w2e_query.weight -> encoder.layer.10.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.w2e_query.bias -> encoder.layer.10.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.self.e2w_query.weight -> encoder.layer.10.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.e2w_query.bias -> encoder.layer.10.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.self.e2e_query.weight -> encoder.layer.10.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.self.e2e_query.bias -> encoder.layer.10.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.output.dense.weight -> encoder.layer.10.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.10.attention.output.dense.bias -> encoder.layer.10.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.10.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.10.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.10.intermediate.dense.weight -> encoder.layer.10.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.10.intermediate.dense.bias -> encoder.layer.10.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.10.output.dense.weight -> encoder.layer.10.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.10.output.dense.bias -> encoder.layer.10.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.10.output.LayerNorm.weight -> encoder.layer.10.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.10.output.LayerNorm.bias -> encoder.layer.10.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.11.attention.self.query.weight -> encoder.layer.11.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.query.bias -> encoder.layer.11.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.self.key.weight -> encoder.layer.11.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.key.bias -> encoder.layer.11.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.self.value.weight -> encoder.layer.11.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.value.bias -> encoder.layer.11.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.self.w2e_query.weight -> encoder.layer.11.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.w2e_query.bias -> encoder.layer.11.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.self.e2w_query.weight -> encoder.layer.11.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.e2w_query.bias -> encoder.layer.11.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.self.e2e_query.weight -> encoder.layer.11.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.self.e2e_query.bias -> encoder.layer.11.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.output.dense.weight -> encoder.layer.11.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.11.attention.output.dense.bias -> encoder.layer.11.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.11.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.11.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.11.intermediate.dense.weight -> encoder.layer.11.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.11.intermediate.dense.bias -> encoder.layer.11.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.11.output.dense.weight -> encoder.layer.11.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.11.output.dense.bias -> encoder.layer.11.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.11.output.LayerNorm.weight -> encoder.layer.11.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.11.output.LayerNorm.bias -> encoder.layer.11.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.12.attention.self.query.weight -> encoder.layer.12.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.query.bias -> encoder.layer.12.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.self.key.weight -> encoder.layer.12.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.key.bias -> encoder.layer.12.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.self.value.weight -> encoder.layer.12.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.value.bias -> encoder.layer.12.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.self.w2e_query.weight -> encoder.layer.12.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.w2e_query.bias -> encoder.layer.12.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.self.e2w_query.weight -> encoder.layer.12.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.e2w_query.bias -> encoder.layer.12.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.self.e2e_query.weight -> encoder.layer.12.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.self.e2e_query.bias -> encoder.layer.12.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.output.dense.weight -> encoder.layer.12.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.12.attention.output.dense.bias -> encoder.layer.12.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.12.attention.output.LayerNorm.weight -> encoder.layer.12.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.12.attention.output.LayerNorm.bias -> encoder.layer.12.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.12.intermediate.dense.weight -> encoder.layer.12.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.12.intermediate.dense.bias -> encoder.layer.12.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.12.output.dense.weight -> encoder.layer.12.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.12.output.dense.bias -> encoder.layer.12.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.12.output.LayerNorm.weight -> encoder.layer.12.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.12.output.LayerNorm.bias -> encoder.layer.12.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.13.attention.self.query.weight -> encoder.layer.13.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.query.bias -> encoder.layer.13.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.self.key.weight -> encoder.layer.13.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.key.bias -> encoder.layer.13.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.self.value.weight -> encoder.layer.13.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.value.bias -> encoder.layer.13.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.self.w2e_query.weight -> encoder.layer.13.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.w2e_query.bias -> encoder.layer.13.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.self.e2w_query.weight -> encoder.layer.13.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.e2w_query.bias -> encoder.layer.13.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.self.e2e_query.weight -> encoder.layer.13.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.self.e2e_query.bias -> encoder.layer.13.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.output.dense.weight -> encoder.layer.13.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.13.attention.output.dense.bias -> encoder.layer.13.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.13.attention.output.LayerNorm.weight -> encoder.layer.13.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.13.attention.output.LayerNorm.bias -> encoder.layer.13.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.13.intermediate.dense.weight -> encoder.layer.13.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.13.intermediate.dense.bias -> encoder.layer.13.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.13.output.dense.weight -> encoder.layer.13.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.13.output.dense.bias -> encoder.layer.13.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.13.output.LayerNorm.weight -> encoder.layer.13.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.13.output.LayerNorm.bias -> encoder.layer.13.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.14.attention.self.query.weight -> encoder.layer.14.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.query.bias -> encoder.layer.14.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.self.key.weight -> encoder.layer.14.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.key.bias -> encoder.layer.14.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.self.value.weight -> encoder.layer.14.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.value.bias -> encoder.layer.14.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.self.w2e_query.weight -> encoder.layer.14.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.w2e_query.bias -> encoder.layer.14.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.self.e2w_query.weight -> encoder.layer.14.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.e2w_query.bias -> encoder.layer.14.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.self.e2e_query.weight -> encoder.layer.14.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.self.e2e_query.bias -> encoder.layer.14.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.output.dense.weight -> encoder.layer.14.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.14.attention.output.dense.bias -> encoder.layer.14.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.14.attention.output.LayerNorm.weight -> encoder.layer.14.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.14.attention.output.LayerNorm.bias -> encoder.layer.14.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.14.intermediate.dense.weight -> encoder.layer.14.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.14.intermediate.dense.bias -> encoder.layer.14.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.14.output.dense.weight -> encoder.layer.14.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.14.output.dense.bias -> encoder.layer.14.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.14.output.LayerNorm.weight -> encoder.layer.14.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.14.output.LayerNorm.bias -> encoder.layer.14.output.layernorm.beta torch.Size([1024])\n",
      "encoder.layer.15.attention.self.query.weight -> encoder.layer.15.attention.self_attention.query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.query.bias -> encoder.layer.15.attention.self_attention.query.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.self.key.weight -> encoder.layer.15.attention.self_attention.key.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.key.bias -> encoder.layer.15.attention.self_attention.key.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.self.value.weight -> encoder.layer.15.attention.self_attention.value.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.value.bias -> encoder.layer.15.attention.self_attention.value.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.self.w2e_query.weight -> encoder.layer.15.attention.self_attention.w2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.w2e_query.bias -> encoder.layer.15.attention.self_attention.w2e_query.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.self.e2w_query.weight -> encoder.layer.15.attention.self_attention.e2w_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.e2w_query.bias -> encoder.layer.15.attention.self_attention.e2w_query.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.self.e2e_query.weight -> encoder.layer.15.attention.self_attention.e2e_query.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.self.e2e_query.bias -> encoder.layer.15.attention.self_attention.e2e_query.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.output.dense.weight -> encoder.layer.15.attention.output.dense.weight torch.Size([1024, 1024])\n",
      "encoder.layer.15.attention.output.dense.bias -> encoder.layer.15.attention.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.15.attention.output.LayerNorm.weight -> encoder.layer.15.attention.output.LayerNorm.gamma torch.Size([1024])\n",
      "encoder.layer.15.attention.output.LayerNorm.bias -> encoder.layer.15.attention.output.LayerNorm.beta torch.Size([1024])\n",
      "encoder.layer.15.intermediate.dense.weight -> encoder.layer.15.intermediate.weight torch.Size([4096, 1024])\n",
      "encoder.layer.15.intermediate.dense.bias -> encoder.layer.15.intermediate.bias torch.Size([4096])\n",
      "encoder.layer.15.output.dense.weight -> encoder.layer.15.output.dense.weight torch.Size([1024, 4096])\n",
      "encoder.layer.15.output.dense.bias -> encoder.layer.15.output.dense.bias torch.Size([1024])\n",
      "encoder.layer.15.output.LayerNorm.weight -> encoder.layer.15.output.layernorm.gamma torch.Size([1024])\n",
      "encoder.layer.15.output.LayerNorm.bias -> encoder.layer.15.output.layernorm.beta torch.Size([1024])\n",
      "pooler.dense.weight -> pooler.weight torch.Size([1024, 1024])\n",
      "pooler.dense.bias -> pooler.bias torch.Size([1024])\n",
      "embeddings.word_embeddings.weight -> embeddings.word_embeddings.embedding_table torch.Size([50265, 1024])\n",
      "embeddings.position_embeddings.weight -> embeddings.position_embeddings.embedding_table torch.Size([514, 1024])\n",
      "embeddings.token_type_embeddings.weight -> embeddings.token_type_embeddings.embedding_table torch.Size([1, 1024])\n",
      "embeddings.LayerNorm.weight -> embeddings.LayerNorm.gamma torch.Size([1024])\n",
      "embeddings.LayerNorm.bias -> embeddings.LayerNorm.beta torch.Size([1024])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity_embeddings.entity_embeddings.weight -> entity_embeddings.entity_embeddings.embedding_table torch.Size([500000, 256])\n",
      "entity_embeddings.entity_embedding_dense.weight -> entity_embeddings.entity_embedding_dense.weight torch.Size([1024, 256])\n",
      "entity_embeddings.position_embeddings.weight -> entity_embeddings.position_embeddings.embedding_table torch.Size([514, 1024])\n",
      "entity_embeddings.token_type_embeddings.weight -> entity_embeddings.token_type_embeddings.embedding_table torch.Size([1, 1024])\n",
      "entity_embeddings.LayerNorm.weight -> entity_embeddings.layer_norm.gamma torch.Size([1024])\n",
      "entity_embeddings.LayerNorm.bias -> entity_embeddings.layer_norm.beta torch.Size([1024])\n",
      "qa_outputs.weight -> qa_outputs.weight torch.Size([2, 1024])\n",
      "qa_outputs.bias -> qa_outputs.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "extract_and_convert(torch_model,ms_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
