{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed97a075",
   "metadata": {},
   "source": [
    "# 数据集创建&处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd48864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modelarts.session import Session\n",
    "# session = Session()\n",
    "# session.obs.download_file(src_obs_file=\"obs://llddy/LUKE_mindspore/data/dev_data.npy\", dst_local_dir=\"./dev_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d203bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.build_dataset import build_dataset\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeeacb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建mindrecord\n",
    "\n",
    "FEATURES_FILE = \"./data/dev_data.npy\"\n",
    "#FEATURES_FILE = \"./data/json_features.npy\"\n",
    "features = np.load(FEATURES_FILE)\n",
    "list_dict = []\n",
    "for item in features:\n",
    "    dict_temp = json.loads(item)\n",
    "    list_dict.append(dict_temp)\n",
    "SQUAD_MINDRECORD_FILE = \"./data/dev_features.mindrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1a376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSRStatus.SUCCESS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = lambda a,i : a[0:i] if len(a) > i else a + [0] * (i-len(a))\n",
    "pad_entity = lambda a,i : a[0:i] if len(a) > i else np.append(a,[-1] * (i-len(a)))\n",
    "\n",
    "for slist in list_dict:\n",
    "    slist[\"entity_attention_mask\"] = pad(slist[\"entity_attention_mask\"], 24)\n",
    "    slist[\"entity_ids\"] = pad(slist[\"entity_attention_mask\"], 24)\n",
    "    slist[\"entity_segment_ids\"] = pad(slist[\"entity_segment_ids\"], 24)\n",
    "    \n",
    "    slist[\"word_ids\"] = pad(slist[\"word_ids\"], 256)\n",
    "    slist[\"word_segment_ids\"] = pad(slist[\"word_segment_ids\"], 256)\n",
    "    slist[\"word_attention_mask\"] = pad(slist[\"word_attention_mask\"], 256)\n",
    "    slist[\"entity_position_ids\"] = np.array(slist[\"entity_position_ids\"]).flatten()\n",
    "    slist[\"entity_position_ids\"] = pad_entity(slist[\"entity_position_ids\"], 256)\n",
    "\n",
    "\n",
    "if os.path.exists(SQUAD_MINDRECORD_FILE):\n",
    "    os.remove(SQUAD_MINDRECORD_FILE)\n",
    "    os.remove(SQUAD_MINDRECORD_FILE + \".db\")\n",
    "\n",
    "writer = FileWriter(file_name=SQUAD_MINDRECORD_FILE, shard_num=1)\n",
    "\n",
    "data_schema = {\n",
    "    \"unique_id\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_position_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    #\"start_positions\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    #\"end_positions\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "}\n",
    "writer.add_schema(data_schema, \"it is a preprocessed squad dataset\")\n",
    "\n",
    "data = []\n",
    "i = 0\n",
    "for item in list_dict:\n",
    "    i += 1\n",
    "    sample = {\n",
    "        \"unique_id\": np.array(item[\"unique_id\"], dtype=np.int32),\n",
    "        \"word_ids\": np.array(item[\"word_ids\"], dtype=np.int32),\n",
    "        \"word_segment_ids\": np.array(item[\"word_segment_ids\"], dtype=np.int32),\n",
    "        \"word_attention_mask\": np.array(item[\"word_attention_mask\"], dtype=np.int32),\n",
    "        \"entity_ids\": np.array(item[\"entity_ids\"], dtype=np.int32),\n",
    "        \"entity_position_ids\": np.array(item[\"entity_position_ids\"], dtype=np.int32),\n",
    "        \"entity_segment_ids\": np.array(item[\"entity_segment_ids\"], dtype=np.int32),\n",
    "        \"entity_attention_mask\": np.array(item[\"entity_attention_mask\"], dtype=np.int32),\n",
    "        #\"start_positions\": np.array(item[\"start_positions\"], dtype=np.int32),\n",
    "        #\"end_positions\": np.array(item[\"end_positions\"], dtype=np.int32),\n",
    "    }\n",
    "\n",
    "    data.append(sample)\n",
    "    #print(sample)\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633673b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQUAD_MINDRECORD_FILE = \"./data/dev_features.mindrecord\"\n",
    "data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)\n",
    "# count = 0\n",
    "# for item in data_set.create_dict_iterator():\n",
    "#     #print(item)\n",
    "#     count += 1\n",
    "# print(\"Got {} samples\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c7ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_attention_mask': Tensor(shape=[24, 24], dtype=Int32, value=\n",
       " [[0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [1, 0, 0 ... 0, 0, 0],\n",
       "  ...\n",
       "  [1, 1, 0 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0]]),\n",
       " 'entity_ids': Tensor(shape=[24, 24], dtype=Int32, value=\n",
       " [[0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [1, 0, 0 ... 0, 0, 0],\n",
       "  ...\n",
       "  [1, 1, 0 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0]]),\n",
       " 'entity_position_ids': Tensor(shape=[24, 256], dtype=Int32, value=\n",
       " [[-1, -1, -1 ... -1, -1, -1],\n",
       "  [-1, -1, -1 ... -1, -1, -1],\n",
       "  [11, 12, -1 ... -1, -1, -1],\n",
       "  ...\n",
       "  [29, 30, 31 ... -1, -1, -1],\n",
       "  [11, 12, -1 ... -1, -1, -1],\n",
       "  [77, -1, -1 ... -1, -1, -1]]),\n",
       " 'entity_segment_ids': Tensor(shape=[24, 24], dtype=Int32, value=\n",
       " [[0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  ...\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0]]),\n",
       " 'unique_id': Tensor(shape=[24, 1], dtype=Int32, value=\n",
       " [[1000005274],\n",
       "  [1000007694],\n",
       "  [1000000280],\n",
       "  ...\n",
       "  [1000005355],\n",
       "  [1000000170],\n",
       "  [1000002811]]),\n",
       " 'word_attention_mask': Tensor(shape=[24, 256], dtype=Int32, value=\n",
       " [[1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 1, 1, 1],\n",
       "  ...\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 0, 0, 0],\n",
       "  [1, 1, 1 ... 1, 1, 1]]),\n",
       " 'word_ids': Tensor(shape=[24, 256], dtype=Int32, value=\n",
       " [[    0,  1301,  6909 ...     0,     0,     0],\n",
       "  [    0, 13841,   473 ...     0,     0,     0],\n",
       "  [    0,  2264,   704 ...    90,  4352,  1116],\n",
       "  ...\n",
       "  [    0,  1779,    21 ...     0,     0,     0],\n",
       "  [    0,  1779,    21 ...     0,     0,     0],\n",
       "  [    0,  2264,   761 ... 29972,  1116, 35984]]),\n",
       " 'word_segment_ids': Tensor(shape=[24, 256], dtype=Int32, value=\n",
       " [[0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  ...\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0],\n",
       "  [0, 0, 0 ... 0, 0, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = data_set.batch(24)\n",
    "data_sample = next(data_set.create_dict_iterator())\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a162b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = data_sample[\"word_ids\"]\n",
    "word_segment_ids= data_sample[\"word_segment_ids\"]\n",
    "word_attention_mask= data_sample[\"word_attention_mask\"]\n",
    "entity_ids= data_sample[\"entity_ids\"]\n",
    "entity_position_ids= data_sample[\"entity_position_ids\"]\n",
    "entity_segment_ids= data_sample[\"entity_segment_ids\"]\n",
    "entity_attention_mask= data_sample[\"entity_attention_mask\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3a90b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f96564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension, LukeEntityAwareAttentionModel\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context\n",
    "from model.luke import LukeModel, EntityAwareEncoder\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from model.bert_model import BertOutput\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "from mindspore.ops import composite as C\n",
    "import mindspore\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.train.model import Model\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd591be1",
   "metadata": {},
   "source": [
    "## 简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854db906",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()\n",
    "Luke_model = LukeForReadingComprehension(config)\n",
    "model = Model(Luke_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2018a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.predict(word_ids,word_segment_ids,word_attention_mask,entity_ids,entity_position_ids,entity_segment_ids,entity_attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb18c97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[24, 256], dtype=Float32, value=\n",
       " [[ 2.92592585e-01,  2.70484447e-01,  2.65146255e-01 ...  2.63161600e-01,  2.59273797e-01,  2.95242786e-01],\n",
       "  [ 3.18681479e-01,  2.97804475e-01,  2.70562023e-01 ...  2.99310863e-01,  2.90683925e-01,  3.07460636e-01],\n",
       "  [ 2.56083131e-01,  2.35625535e-01,  2.13921010e-01 ...  2.38565832e-01,  2.26389676e-01,  2.43567199e-01],\n",
       "  ...\n",
       "  [ 2.66339034e-01,  2.45516524e-01,  2.45532036e-01 ...  2.48828977e-01,  2.38703132e-01,  2.56241202e-01],\n",
       "  [ 3.29715371e-01,  3.08946311e-01,  3.06750625e-01 ...  3.09931695e-01,  3.09648693e-01,  2.97910243e-01],\n",
       "  [ 2.54786551e-01,  2.23702818e-01,  2.21459359e-01 ...  2.36167192e-01,  2.27386415e-01,  2.43492305e-01]]),\n",
       " Tensor(shape=[24, 256], dtype=Float32, value=\n",
       " [[-4.45168614e-01, -4.17687595e-01, -4.18160260e-01 ... -4.17240530e-01, -4.13319558e-01, -4.30681825e-01],\n",
       "  [-4.23104525e-01, -3.96651030e-01, -3.95476073e-01 ... -3.96843135e-01, -3.93367976e-01, -4.17906284e-01],\n",
       "  [-4.35993910e-01, -4.09789205e-01, -4.17405427e-01 ... -4.08947974e-01, -4.02795613e-01, -4.31634933e-01],\n",
       "  ...\n",
       "  [-4.21840847e-01, -3.94027650e-01, -3.76842052e-01 ... -3.94310832e-01, -3.91166568e-01, -4.16604161e-01],\n",
       "  [-4.15894836e-01, -3.93932432e-01, -3.69493723e-01 ... -3.72763693e-01, -3.88462126e-01, -4.17109966e-01],\n",
       "  [-4.32556689e-01, -4.23182189e-01, -4.05571908e-01 ... -4.07639861e-01, -4.03096080e-01, -4.28082407e-01]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f966b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "032a9cc9",
   "metadata": {},
   "source": [
    "# do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5b87da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://100.125.0.87:32021/repository/pypi/simple\n",
      "Requirement already satisfied: tqdm in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (4.62.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e45fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.model import Model\n",
    "import collections\n",
    "def do_eval(dataset=None, load_checkpoint_path=\"\", eval_batch_size=1):\n",
    "    config = BertConfig()\n",
    "    Luke_model = LukeForReadingComprehension(config)\n",
    "    Luke_model.set_train(False)\n",
    "    model = Model(Luke_model)\n",
    "    param_dict = load_checkpoint(load_checkpoint_path)\n",
    "    load_param_into_net(Luke_model, param_dict)\n",
    "    output = []\n",
    "    #model = Model(Luke_model)\n",
    "    \n",
    "    RawResult = collections.namedtuple(\"RawResult\", [\"unique_id\", \"start_logits\", \"end_logits\"])\n",
    "    columns_list = [\"unique_id\", \"word_ids\", \"word_segment_ids\", \"word_attention_mask\", \"entity_ids\", \"entity_position_ids\", \"entity_segment_ids\", \"entity_attention_mask\"]\n",
    "    data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)\n",
    "    data_set = data_set.batch(eval_batch_size,drop_remainder=True)\n",
    "    for data in tqdm(data_set.create_dict_iterator(num_epochs=1)):\n",
    "        input_data = []\n",
    "        for i in columns_list:\n",
    "            input_data.append(data[i])\n",
    "\n",
    "        unique_id, word_ids,word_segment_ids,word_attention_mask,entity_ids,entity_position_ids,entity_segment_ids,entity_attention_mask = input_data\n",
    "        #print(unique_id)\n",
    "        logits = model.predict(word_ids,word_segment_ids,word_attention_mask,entity_ids,entity_position_ids,entity_segment_ids,entity_attention_mask)\n",
    "        ids = unique_id.asnumpy()\n",
    "        start = logits[0].asnumpy()\n",
    "        end = logits[1].asnumpy()\n",
    "\n",
    "        for i in range(eval_batch_size):\n",
    "            unique_id = int(ids[i])\n",
    "            start_logits = [float(x) for x in start[i].flat]\n",
    "            end_logits = [float(x) for x in end[i].flat]\n",
    "            output.append(RawResult(\n",
    "                unique_id=unique_id,\n",
    "                start_logits=start_logits,\n",
    "                end_logits=end_logits))\n",
    "        #print(word_ids.shape)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4caaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0b9779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10779"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834007e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [21:43, 18.29s/it]"
     ]
    }
   ],
   "source": [
    "outputs = do_eval(dev_dataset, load_checkpoint_path = \"./luke-large-qa.ckpt\", eval_batch_size = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('dev_outputs.npy',outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b2383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c291b3f",
   "metadata": {},
   "source": [
    "# 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b195514",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_features = np.load(\"./data/dev_data.npy\")\n",
    "eval_examples = read_squad_examples(args_opt.eval_json_path, False)\n",
    "all_predictions = write_predictions(eval_examples, eval_features, outputs, 20, 30, True)\n",
    "SQuad_postprocess(args_opt.eval_json_path, all_predictions, output_metrics=\"output.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore-python3.7-aarch64",
   "language": "python",
   "name": "mindspore-python3.7-aarch64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
