{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07fc48b",
   "metadata": {},
   "source": [
    "# 数据集创建&处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28555a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.build_dataset import build_dataset\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a41b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建mindrecord\n",
    "\n",
    "# FEATURES_FILE = \"./data/json_features.npy\"\n",
    "# features = np.load(FEATURES_FILE)\n",
    "# list_dict = []\n",
    "# for item in features:\n",
    "#     dict_temp = json.loads(item)\n",
    "#     list_dict.append(dict_temp)\n",
    "# SQUAD_MINDRECORD_FILE = \"./data/squad_features.mindrecord\"\n",
    "\n",
    "# if os.path.exists(SQUAD_MINDRECORD_FILE):\n",
    "#     os.remove(SQUAD_MINDRECORD_FILE)\n",
    "#     os.remove(SQUAD_MINDRECORD_FILE + \".db\")\n",
    "\n",
    "# writer = FileWriter(file_name=SQUAD_MINDRECORD_FILE, shard_num=1)\n",
    "\n",
    "# data_schema = {\n",
    "#     \"word_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"word_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"word_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"entity_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"entity_position_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"entity_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"entity_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"start_positions\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "#     \"end_positions\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "# }\n",
    "# writer.add_schema(data_schema, \"it is a preprocessed squad dataset\")\n",
    "\n",
    "# data = []\n",
    "# i = 0\n",
    "# for item in list_dict:\n",
    "#     i += 1\n",
    "#     sample = {\n",
    "#         \"word_ids\": np.array(item[\"word_ids\"], dtype=np.int32),\n",
    "#         \"word_segment_ids\": np.array(item[\"word_segment_ids\"], dtype=np.int32),\n",
    "#         \"word_attention_mask\": np.array(item[\"word_attention_mask\"], dtype=np.int32),\n",
    "#         \"entity_ids\": np.array(item[\"entity_ids\"], dtype=np.int32),\n",
    "#         \"entity_position_ids\": np.array(item[\"entity_position_ids\"], dtype=np.int32),\n",
    "#         \"entity_segment_ids\": np.array(item[\"entity_segment_ids\"], dtype=np.int32),\n",
    "#         \"entity_attention_mask\": np.array(item[\"entity_attention_mask\"], dtype=np.int32),\n",
    "#         \"start_positions\": np.array(item[\"start_positions\"], dtype=np.int32),\n",
    "#         \"end_positions\": np.array(item[\"end_positions\"], dtype=np.int32),\n",
    "#     }\n",
    "\n",
    "#     data.append(sample)\n",
    "#     #print(sample)\n",
    "#     if i % 10 == 0:\n",
    "#         writer.write_raw_data(data)\n",
    "#         data = []\n",
    "\n",
    "# if data:\n",
    "#     writer.write_raw_data(data)\n",
    "\n",
    "# writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4565ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 269 samples\n"
     ]
    }
   ],
   "source": [
    "SQUAD_MINDRECORD_FILE = \"./data/squad_features.mindrecord\"\n",
    "data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE)\n",
    "count = 0\n",
    "for item in data_set.create_dict_iterator():\n",
    "    #print(item)\n",
    "    count += 1\n",
    "print(\"Got {} samples\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a54a51a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_positions': Tensor(shape=[1], dtype=Int32, value= [88]),\n",
       " 'entity_attention_mask': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'entity_position_ids': Tensor(shape=[60], dtype=Int32, value= [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, \n",
       "  -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]),\n",
       " 'entity_segment_ids': Tensor(shape=[2], dtype=Int32, value= [0, 0]),\n",
       " 'start_positions': Tensor(shape=[1], dtype=Int32, value= [83]),\n",
       " 'word_attention_mask': Tensor(shape=[158], dtype=Int32, value= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n",
       "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'word_ids': Tensor(shape=[158], dtype=Int32, value= [    0, 32251, 10014,   222, 10579,  9038,  6198,     7,  1119,    10,  2932,  3184,   751,     9,  2344,  7180,   852, 10271,   116,     2,     2,   133,  9502, 35483, \n",
       "   1116,   717, 16134,   219, 24265, 33479,  1790,     6,   102,  1629, 24355,  4416, 27013,   462, 23283, 41587, 20936,   560,   627, 29972,  1116,  7199,   241,   495, \n",
       "   4344, 28135,   463, 11856,  1409,   627,   879, 31104,     6,  7450,  1071, 13981,   261, 11983,   246,     6, 27418,     4,   133,   717, 16134,   219, 24265, 33479, \n",
       "   1790,   417, 10461, 18988, 36299, 10092, 14746, 16941,   298,  7651,  1409,   627, 15075,  1116, 10050,   387,  1397,   560, 42843,   627, 15110, 15129,   154,  6276, \n",
       "   1580,   642,  8638,   196,   627, 22891,  6014, 11953, 10669,   102, 31938,   368,   298,  7651, 13424,    12, 18988, 16941,     4,   133, 34335,   254,     6,   530, \n",
       "   1459, 17105,  2553,   995,  1116, 25767, 20048,     6,  7333,  7078,  1073, 39510,  5632, 25430, 11535, 42433, 37615,  5652, 18076, 11880,   293,     6,   102, 30191, \n",
       "   6025,  7333,  1329,   560, 35031, 24966,  7761,   337, 28709,   463, 26302,  4189,     4,     2]),\n",
       " 'word_segment_ids': Tensor(shape=[158], dtype=Int32, value= [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
       "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = next(data_set.create_dict_iterator())\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2cc2a8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1f52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension, LukeEntityAwareAttentionModel\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context\n",
    "from model.luke import LukeModel, EntityAwareEncoder\n",
    "import numpy as np\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from model.bert_model import BertOutput\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "import math\n",
    "from mindspore.ops import composite as C\n",
    "import mindspore\n",
    "from mindspore.ops import operations as P\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513cf6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()\n",
    "Luke_model = LukeForReadingComprehension(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4502ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_stack = ops.Stack()\n",
    "word_ids = op_stack([data_sample[\"word_ids\"], data_sample[\"word_ids\"]])\n",
    "word_segment_ids = op_stack([data_sample[\"word_segment_ids\"], data_sample[\"word_segment_ids\"]])\n",
    "word_attention_mask = op_stack([data_sample[\"word_attention_mask\"], data_sample[\"word_attention_mask\"]])\n",
    "entity_ids = op_stack([data_sample[\"entity_ids\"], data_sample[\"entity_ids\"]])\n",
    "entity_position_ids = op_stack([data_sample[\"entity_position_ids\"], data_sample[\"entity_position_ids\"]])\n",
    "entity_segment_ids = op_stack([data_sample[\"entity_segment_ids\"], data_sample[\"entity_segment_ids\"]])\n",
    "entity_attention_mask = op_stack([data_sample[\"entity_attention_mask\"], data_sample[\"entity_attention_mask\"]])\n",
    "start_positions = op_stack([data_sample[\"start_positions\"], data_sample[\"start_positions\"]])\n",
    "end_positions = op_stack([data_sample[\"end_positions\"], data_sample[\"end_positions\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475677b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[2], dtype=Float32, value= [5.05253887e+000, 5.05253887e+000]),\n",
       " Tensor(shape=[2, 158], dtype=Float32, value=\n",
       " [[-5.26331216e-002, -2.64509231e-001, -7.99690187e-002 ... -2.11217716e-001, -2.47879758e-001, -2.57167041e-001],\n",
       "  [-5.26331216e-002, -2.64509231e-001, -7.99690187e-002 ... -2.11217716e-001, -2.47879758e-001, -2.57167041e-001]]),\n",
       " Tensor(shape=[2, 158], dtype=Float32, value=\n",
       " [[-5.26331216e-002, -2.64509231e-001, -7.99690187e-002 ... -2.11217716e-001, -2.47879758e-001, -2.57167041e-001],\n",
       "  [-5.26331216e-002, -2.64509231e-001, -7.99690187e-002 ... -2.11217716e-001, -2.47879758e-001, -2.57167041e-001]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LukeForReadingComprehension(config)\n",
    "model.construct(word_ids,\n",
    "                word_segment_ids,\n",
    "                word_attention_mask,\n",
    "                entity_ids,\n",
    "                entity_position_ids,\n",
    "                entity_segment_ids,\n",
    "                entity_attention_mask,\n",
    "                start_positions,\n",
    "                end_positions\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
