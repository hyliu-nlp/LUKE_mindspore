{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(11347:139803871401792,MainProcess):2021-10-25-16:48:38.145.184 [mindspore/run_check/_check_version.py:181] Cuda ['10.1', '11.1'] version(need by mindspore-gpu) is not found, please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, please refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(11347:139803871401792,MainProcess):2021-10-25-16:48:38.154.442 [mindspore/run_check/_check_version.py:181] Cuda ['10.1', '11.1'] version(need by mindspore-gpu) is not found, please confirm that the path of cuda is set to the env LD_LIBRARY_PATH, please refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "from dataset.build_dataset import build_dataset\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FILE = \"./data/train_data.npy\"\n",
    "\n",
    "features = np.load(FEATURES_FILE)\n",
    "list_dict = []\n",
    "for item in features:\n",
    "    dict_temp = json.loads(item)\n",
    "    list_dict.append(dict_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dict[0]['word_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 598,\n",
       " 2661,\n",
       " 222,\n",
       " 5,\n",
       " 9880,\n",
       " 2708,\n",
       " 2346,\n",
       " 2082,\n",
       " 11,\n",
       " 504,\n",
       " 4432,\n",
       " 11,\n",
       " 226,\n",
       " 2126,\n",
       " 10067,\n",
       " 1470,\n",
       " 116,\n",
       " 2,\n",
       " 2,\n",
       " 29474,\n",
       " 28108,\n",
       " 6,\n",
       " 5,\n",
       " 334,\n",
       " 34,\n",
       " 10,\n",
       " 4019,\n",
       " 2048,\n",
       " 4,\n",
       " 497,\n",
       " 1517,\n",
       " 5,\n",
       " 4326,\n",
       " 6919,\n",
       " 18,\n",
       " 1637,\n",
       " 31346,\n",
       " 16,\n",
       " 10,\n",
       " 9030,\n",
       " 9577,\n",
       " 9,\n",
       " 5,\n",
       " 9880,\n",
       " 2708,\n",
       " 4,\n",
       " 29261,\n",
       " 11,\n",
       " 760,\n",
       " 9,\n",
       " 5,\n",
       " 4326,\n",
       " 6919,\n",
       " 8,\n",
       " 2114,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 10,\n",
       " 7621,\n",
       " 9577,\n",
       " 9,\n",
       " 4845,\n",
       " 19,\n",
       " 3701,\n",
       " 62,\n",
       " 33161,\n",
       " 19,\n",
       " 5,\n",
       " 7875,\n",
       " 22,\n",
       " 39043,\n",
       " 1459,\n",
       " 1614,\n",
       " 1464,\n",
       " 13292,\n",
       " 4977,\n",
       " 845,\n",
       " 4130,\n",
       " 7,\n",
       " 5,\n",
       " 4326,\n",
       " 6919,\n",
       " 16,\n",
       " 5,\n",
       " 26429,\n",
       " 2426,\n",
       " 9,\n",
       " 5,\n",
       " 25095,\n",
       " 6924,\n",
       " 4,\n",
       " 29261,\n",
       " 639,\n",
       " 5,\n",
       " 32394,\n",
       " 2426,\n",
       " 16,\n",
       " 5,\n",
       " 7461,\n",
       " 26187,\n",
       " 6,\n",
       " 10,\n",
       " 19035,\n",
       " 317,\n",
       " 9,\n",
       " 9621,\n",
       " 8,\n",
       " 12456,\n",
       " 4,\n",
       " 85,\n",
       " 16,\n",
       " 10,\n",
       " 24633,\n",
       " 9,\n",
       " 5,\n",
       " 11491,\n",
       " 26187,\n",
       " 23,\n",
       " 226,\n",
       " 2126,\n",
       " 10067,\n",
       " 6,\n",
       " 1470,\n",
       " 147,\n",
       " 5,\n",
       " 9880,\n",
       " 2708,\n",
       " 2851,\n",
       " 13735,\n",
       " 352,\n",
       " 1382,\n",
       " 7,\n",
       " 6130,\n",
       " 6552,\n",
       " 625,\n",
       " 3398,\n",
       " 208,\n",
       " 22895,\n",
       " 853,\n",
       " 1827,\n",
       " 11,\n",
       " 504,\n",
       " 4432,\n",
       " 4,\n",
       " 497,\n",
       " 5,\n",
       " 253,\n",
       " 9,\n",
       " 5,\n",
       " 1049,\n",
       " 1305,\n",
       " 36,\n",
       " 463,\n",
       " 11,\n",
       " 10,\n",
       " 2228,\n",
       " 516,\n",
       " 14,\n",
       " 15230,\n",
       " 149,\n",
       " 155,\n",
       " 19638,\n",
       " 8,\n",
       " 5,\n",
       " 2610,\n",
       " 25336,\n",
       " 238,\n",
       " 16,\n",
       " 10,\n",
       " 2007,\n",
       " 6,\n",
       " 2297,\n",
       " 7326,\n",
       " 9577,\n",
       " 9,\n",
       " 2708,\n",
       " 4,\n",
       " 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict[0]['word_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUAD_MINDRECORD_FILE = \"./data/train_features.mindrecord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_ids': array([    0,  1740,    99,   343,   473,  1586,  1071, 19252,   904,\n",
      "         786,  8287,  4871,     7, 15359, 14785,   257,   116,     2,\n",
      "           2,    20,  1049,   758,  3062,  2754, 15359, 14785,   257,\n",
      "           8,  4634, 15377,    16,     5, 24311,  6455,  9965,  1016,\n",
      "        4414,     6,  2034,    59,   411,  8130,    36,   401,  6301,\n",
      "          36,   246,     4,   406, 11163, 35122,    31,     5,   343,\n",
      "        2100,     4, 23701,  1070,    30,     5,  5280, 10333,  4305,\n",
      "           9, 15377,    24,    34,    80, 20531,     6,    65,  1897,\n",
      "           8,    65,   758,     4,   497,  1455,     6,    59,   820,\n",
      "         758,  8537,  4686, 15377,     7,    97, 11633,    11,  1005,\n",
      "           6,  1817,     8,     5,  2367,   953,     6,     7,  1947,\n",
      "         215,    25, 12275,     6,  3534,     6,   229, 14024,  2186,\n",
      "           6,  2920,     6, 15398,     6, 18959, 19193,     6,  8086,\n",
      "        5870,     6, 12600,     6,  2884,   139,     6,   226,  7333,\n",
      "         102,     6, 23481,  6588,     6,     8, 21105, 18604,     4,\n",
      "          83,   485,  5064,     7,     5,   758,  9632,    34,   156,\n",
      "           5,  4472,     7,     5, 27236, 10941,     8,    11,   779,\n",
      "        2338,    24,  1059,   678,     7,  3598,  2024,     7, 15359,\n",
      "       14785,   257,    31, 16342,    19,  1586,  1071, 19252,     4,\n",
      "        1773,  1014,     6,  4423,  6503, 15230, 12275,     7, 15359,\n",
      "       14785,   257,     4,  6131,  2368,     6,   484, 27139,  3644,\n",
      "        8537,  4303,    31,     5,   343,     6,   217,  3303,  5107,\n",
      "        1754,     6, 37714,  1754,     6, 43898,  1754,     6, 15377,\n",
      "        6503,     8,  3507,   118,  6503,     6,     7,    97,   538,\n",
      "        6815,   420, 15377,     4,     2,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1],\n",
      "      dtype=int32), 'word_segment_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32), 'word_attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0], dtype=int32), 'entity_ids': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0], dtype=int32), 'entity_position_ids': array([[ 29,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ 32,  33,  34,  35,  36,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ 64,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ 84,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ 91,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ 94,  95,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [103,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [105, 106, 107,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [109,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [111,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [113, 114,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [116, 117,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [119,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [124, 125, 126,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [128, 129,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [132, 133,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [165,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [206, 207,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
      "       [ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1]],\n",
      "      dtype=int32), 'entity_segment_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0], dtype=int32), 'entity_attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0], dtype=int32), 'start_positions': array([165], dtype=int32), 'end_positions': array([165], dtype=int32)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MSRStatus.SUCCESS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = lambda a,i : a[0:i] if len(a) > i else a + [0] * (i-len(a))\n",
    "pad1 = lambda a,i : a[0:i] if len(a) > i else a + [1] * (i-len(a))\n",
    "pad_entity = lambda a,i : a[0:i] if len(a) > i else np.append(a,[-1] * (i-len(a)))\n",
    "\n",
    "for slist in list_dict:\n",
    "    slist[\"entity_attention_mask\"] = pad(slist[\"entity_attention_mask\"], 24)\n",
    "    slist[\"entity_ids\"] = pad(slist[\"entity_attention_mask\"], 24)\n",
    "    slist[\"entity_segment_ids\"] = pad(slist[\"entity_segment_ids\"], 24)\n",
    "    \n",
    "    slist[\"word_ids\"] = pad1(slist[\"word_ids\"], 512)\n",
    "    slist[\"word_segment_ids\"] = pad(slist[\"word_segment_ids\"], 512)\n",
    "    slist[\"word_attention_mask\"] = pad(slist[\"word_attention_mask\"], 512)\n",
    "    # entity padding 1\n",
    "    entity_size = len(slist[\"entity_position_ids\"])\n",
    "    slist[\"entity_position_ids\"] = np.array(slist[\"entity_position_ids\"])\n",
    "    temp = [[-1]*24 for i in range(24)]\n",
    "    for i in range(24):\n",
    "        if i < entity_size-1:\n",
    "            temp[i]=(pad_entity(slist[\"entity_position_ids\"][i], 24))\n",
    "\n",
    "\n",
    "    slist[\"entity_position_ids\"] =temp\n",
    "    # entity_padding 2\n",
    "    #slist[\"entity_position_ids\"] = np.array(slist[\"entity_position_ids\"]).flatten()\n",
    "    #slist[\"entity_position_ids\"] = pad_entity(slist[\"entity_position_ids\"], 24)\n",
    "\n",
    "\n",
    "if os.path.exists(SQUAD_MINDRECORD_FILE):\n",
    "    os.remove(SQUAD_MINDRECORD_FILE)\n",
    "    os.remove(SQUAD_MINDRECORD_FILE + \".db\")\n",
    "\n",
    "writer = FileWriter(file_name=SQUAD_MINDRECORD_FILE, shard_num=1)\n",
    "\n",
    "data_schema = {\n",
    "    #\"unique_id\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"word_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_position_ids\": {\"type\": \"int32\", \"shape\": [24,24]}, # \n",
    "    \"entity_segment_ids\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"entity_attention_mask\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"start_positions\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    \"end_positions\": {\"type\": \"int32\", \"shape\": [-1]}\n",
    "}\n",
    "writer.add_schema(data_schema, \"it is a preprocessed squad dataset\")\n",
    "\n",
    "data = []\n",
    "i = 0\n",
    "for item in list_dict:\n",
    "    i += 1\n",
    "    sample = {\n",
    "        #\"unique_id\": np.array(item[\"unique_id\"], dtype=np.int32),\n",
    "        \"word_ids\": np.array(item[\"word_ids\"], dtype=np.int32),\n",
    "        \"word_segment_ids\": np.array(item[\"word_segment_ids\"], dtype=np.int32),\n",
    "        \"word_attention_mask\": np.array(item[\"word_attention_mask\"], dtype=np.int32),\n",
    "        \"entity_ids\": np.array(item[\"entity_ids\"], dtype=np.int32),\n",
    "        \"entity_position_ids\": np.array(item[\"entity_position_ids\"], dtype=np.int32),\n",
    "        \"entity_segment_ids\": np.array(item[\"entity_segment_ids\"], dtype=np.int32),\n",
    "        \"entity_attention_mask\": np.array(item[\"entity_attention_mask\"], dtype=np.int32),\n",
    "        \"start_positions\": np.array(item[\"start_positions\"], dtype=np.int32),\n",
    "        \"end_positions\": np.array(item[\"end_positions\"], dtype=np.int32),\n",
    "    }\n",
    "\n",
    "    data.append(sample)\n",
    "    #print(sample)\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "print(data[0])\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features = np.array(list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ['word_ids',  'word_segment_ids', 'word_attention_mask',\n",
    "               'entity_ids', 'entity_position_ids', 'entity_segment_ids',\n",
    "               'entity_attention_mask', 'start_positions', 'end_positions']\n",
    "\n",
    "#SQUAD_MINDRECORD_FILE = \"./data/dev_features.mindrecord\"\n",
    "data_set = ds.MindDataset(dataset_file=SQUAD_MINDRECORD_FILE, columns_list=columns_list)\n",
    "count = 0\n",
    "for item in data_set.create_dict_iterator():\n",
    "    #print(item)\n",
    "    count += 1\n",
    "print(\"Got {} samples\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set.batch(2)# , drop_remainder=True\n",
    "data_sample = next(data_set.create_dict_iterator())\n",
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample['entity_position_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample['entity_attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readingcomprehension.models.luke import LukeForReadingComprehension, LukeForReadingComprehensionWithLoss, LukeEntityAwareAttentionModel, LukeSquadCell\n",
    "import mindspore.common.dtype as mstype\n",
    "from model.bert_model import BertConfig\n",
    "from mindspore import context, save_checkpoint\n",
    "from model.luke import LukeModel, EntityAwareEncoder\n",
    "from mindspore import Tensor, context\n",
    "from mindspore import dtype as mstype\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from model.bert_model import BertOutput\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "from mindspore.ops import composite as C\n",
    "import mindspore\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.train.model import Model\n",
    "from tqdm import tqdm\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.model import Model\n",
    "import collections\n",
    "# PYNATIVE_MODE & GRAPH_MODE\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "context.set_context(enable_graph_kernel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def do_train(dataset=None, network=None, load_checkpoint_path=\"\", save_checkpoint_path=\"\", epoch_num=1):\n",
    "#     \"\"\" do train \"\"\"\n",
    "#     if load_checkpoint_path == \"\":\n",
    "#         raise ValueError(\"Pretrain model missed, finetune task must load pretrain model!\")\n",
    "#     steps_per_epoch = dataset.get_dataset_size()\n",
    "#     # optimizer\n",
    "#     if optimizer_cfg.optimizer == 'AdamWeightDecay':\n",
    "#         lr_schedule = BertLearningRate(learning_rate=15e-6,\n",
    "#                                        end_learning_rate=optimizer_cfg.AdamWeightDecay.end_learning_rate,\n",
    "#                                        warmup_steps=int(steps_per_epoch * epoch_num * 0.1),\n",
    "#                                        decay_steps=steps_per_epoch * epoch_num,\n",
    "#                                        power=optimizer_cfg.AdamWeightDecay.power)\n",
    "#         params = network.trainable_params()\n",
    "#         decay_params = list(filter(optimizer_cfg.AdamWeightDecay.decay_filter, params))\n",
    "#         other_params = list(filter(lambda x: not optimizer_cfg.AdamWeightDecay.decay_filter(x), params))\n",
    "#         group_params = [{'params': decay_params, 'weight_decay': optimizer_cfg.AdamWeightDecay.weight_decay},\n",
    "#                         {'params': other_params, 'weight_decay': 0.0}]\n",
    "\n",
    "#         optimizer = AdamWeightDecay(group_params, lr_schedule, eps=optimizer_cfg.AdamWeightDecay.eps)\n",
    "#     elif optimizer_cfg.optimizer == 'Lamb':\n",
    "#         lr_schedule = BertLearningRate(learning_rate=optimizer_cfg.Lamb.learning_rate,\n",
    "#                                        end_learning_rate=optimizer_cfg.Lamb.end_learning_rate,\n",
    "#                                        warmup_steps=int(steps_per_epoch * epoch_num * 0.1),\n",
    "#                                        decay_steps=steps_per_epoch * epoch_num,\n",
    "#                                        power=optimizer_cfg.Lamb.power)\n",
    "#         optimizer = Lamb(network.trainable_params(), learning_rate=lr_schedule)\n",
    "#     elif optimizer_cfg.optimizer == 'Momentum':\n",
    "#         optimizer = Momentum(network.trainable_params(), learning_rate=optimizer_cfg.Momentum.learning_rate,\n",
    "#                              momentum=optimizer_cfg.Momentum.momentum)\n",
    "#     else:\n",
    "#         raise Exception(\"Optimizer not supported. support: [AdamWeightDecay, Lamb, Momentum]\")\n",
    "\n",
    "#     # load checkpoint into network\n",
    "#     ckpt_config = CheckpointConfig(save_checkpoint_steps=steps_per_epoch, keep_checkpoint_max=1)\n",
    "#     ckpoint_cb = ModelCheckpoint(prefix=\"squad\",\n",
    "#                                  directory=None if save_checkpoint_path == \"\" else save_checkpoint_path,\n",
    "#                                  config=ckpt_config)\n",
    "#     param_dict = load_checkpoint(load_checkpoint_path)\n",
    "#     load_param_into_net(network, param_dict)\n",
    "\n",
    "#     update_cell = DynamicLossScaleUpdateCell(loss_scale_value=2 ** 32, scale_factor=2, scale_window=1000)\n",
    "#     netwithgrads = BertSquadCell(network, optimizer=optimizer, scale_update_cell=update_cell)\n",
    "#     model = Model(netwithgrads)\n",
    "#     callbacks = [TimeMonitor(dataset.get_dataset_size()), LossCallBack(dataset.get_dataset_size()), ckpoint_cb]\n",
    "#     model.train(epoch_num, dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.callback import Callback\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.model import Model\n",
    "from mindspore.nn.learning_rate_schedule import LearningRateSchedule, PolynomialDecayLR, WarmUpLR\n",
    "from mindspore.nn.wrap.loss_scale import DynamicLossScaleUpdateCell\n",
    "\n",
    "import collections\n",
    "import time\n",
    "class BertLearningRate(LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Warmup-decay learning rate for Bert network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, end_learning_rate, warmup_steps, decay_steps, power):\n",
    "        super(BertLearningRate, self).__init__()\n",
    "        self.warmup_flag = False\n",
    "        if warmup_steps > 0:\n",
    "            self.warmup_flag = True\n",
    "            self.warmup_lr = WarmUpLR(learning_rate, warmup_steps)\n",
    "        self.decay_lr = PolynomialDecayLR(learning_rate, end_learning_rate, decay_steps, power)\n",
    "        self.warmup_steps = Tensor(np.array([warmup_steps]).astype(np.float32))\n",
    "\n",
    "        self.greater = mindspore.ops.Greater()\n",
    "        self.one = Tensor(np.array([1.0]).astype(np.float32))\n",
    "        self.cast = mindspore.ops.Cast()\n",
    "\n",
    "    def construct(self, global_step):\n",
    "        decay_lr = self.decay_lr(global_step)\n",
    "        if self.warmup_flag:\n",
    "            is_warmup = self.cast(self.greater(self.warmup_steps, global_step), mstype.float32)\n",
    "            warmup_lr = self.warmup_lr(global_step)\n",
    "            lr = (self.one - is_warmup) * decay_lr + is_warmup * warmup_lr\n",
    "        else:\n",
    "            lr = decay_lr\n",
    "        return lr\n",
    "\n",
    "\n",
    "class LossCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Monitor the loss in training.\n",
    "\n",
    "    If the loss is NAN or INF terminating training.\n",
    "\n",
    "    Note:\n",
    "        If per_print_times is 0 do not print loss.\n",
    "\n",
    "    Args:\n",
    "        per_print_times (int): Print loss every times. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, per_print_times=1, rank_ids=0):\n",
    "        super(LossCallBack, self).__init__()\n",
    "        if not isinstance(per_print_times, int) or per_print_times < 0:\n",
    "            raise ValueError(\"print_step must be int and >= 0.\")\n",
    "        self._per_print_times = per_print_times\n",
    "        self.rank_id = rank_ids\n",
    "        self.time_stamp_first = get_ms_timestamp()\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        \"\"\"Monitor the loss in training.\"\"\"\n",
    "        time_stamp_current = get_ms_timestamp()\n",
    "        cb_params = run_context.original_args()\n",
    "        print(\"time: {}, epoch: {}, step: {}, outputs are {}\".format(time_stamp_current - self.time_stamp_first,\n",
    "                                                                     cb_params.cur_epoch_num,\n",
    "                                                                     cb_params.cur_step_num,\n",
    "                                                                     str(cb_params.net_outputs)))\n",
    "        with open(\"./loss_{}.log\".format(self.rank_id), \"a+\") as f:\n",
    "            f.write(\"time: {}, epoch: {}, step: {}, loss: {}\".format(\n",
    "                time_stamp_current - self.time_stamp_first,\n",
    "                cb_params.cur_epoch_num,\n",
    "                cb_params.cur_step_num,\n",
    "                str(cb_params.net_outputs[0].asnumpy())))\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def get_ms_timestamp():\n",
    "    t = time.time()\n",
    "    return int(round(t * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in data_set:\n",
    "    print(len(i))\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch=1\n",
    "\n",
    "luke_config = BertConfig()\n",
    "LUKEModel = LukeForReadingComprehension(luke_config)\n",
    "param_dict = load_checkpoint('./luke-large-qa.ckpt')\n",
    "load_param_into_net(LUKEModel,param_dict)\n",
    "\n",
    "# update_cell = DynamicLossScaleUpdateCell(loss_scale_value=2 ** 32, scale_factor=2, scale_window=1000)\n",
    "\n",
    "lukesquad = LukeForReadingComprehensionWithLoss(LUKEModel)\n",
    "\n",
    "# lr_schedule = BertLearningRate(learning_rate=15e-6,\n",
    "#                                    end_learning_rate=15e-6 * 0,\n",
    "#                                    warmup_steps=int(data_set.get_dataset_size() * epoch * 0.1),\n",
    "#                                    decay_steps=data_set.get_dataset_size() * epoch,\n",
    "#                                    power=1.0)\n",
    "\n",
    "update_cell = DynamicLossScaleUpdateCell(loss_scale_value=2 ** 32, scale_factor=2, scale_window=1000)\n",
    "\n",
    "\n",
    "params = lukesquad.trainable_params()\n",
    "\n",
    "optimizer = mindspore.nn.AdamWeightDecay(params,\n",
    "                                         learning_rate=5e-5, #15e-6\n",
    "                                         beta1=0.9,\n",
    "                                         beta2=0.98,\n",
    "                                         eps=1e-06)\n",
    "\n",
    "# optimizer = mindspore.nn.Adam(params, learning_rate=lr_schedule, eps=1e-8)\n",
    "\n",
    "# lr_schedule\n",
    "# warmup_steps=877\n",
    "num_train_steps=14629\n",
    "warmup_steps = int(epoch * num_train_steps * 0.06)\n",
    "netwithgrads = LukeSquadCell(lukesquad,optimizer=optimizer, scale_update_cell=update_cell)\n",
    "model = Model(netwithgrads)\n",
    "\n",
    "loss_monitor = LossCallBack()\n",
    "model.train(epoch,data_set,callbacks=[loss_monitor],dataset_sink_mode=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_checkpoint(model.train_network.network.net, ckpt_path / Path(\"ft.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
